{
  "id": "data--big-data-the-information-explosion--t-data-bias-when-algorithms-discriminate",
  "version": 1,
  "subject": "Data",
  "subcategory": "Big Data: The Information Explosion",
  "course_id": "data--big-data-the-information-explosion",
  "chapter_id": "data--big-data-the-information-explosion--ch06-challenges-and-limits",
  "title": "Data Bias: When Algorithms Discriminate",
  "emoji": "ğŸ“Š",
  "color": "#2E86C1",
  "description": "A micro-lesson that makes Data Bias: When Algorithms Discriminate usable.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "Amazon built an AI hiring tool. It systematically penalized rÃ©sumÃ©s that contained the word 'women's.'",
      "visual": "ğŸ“‹"
    },
    "buildup": {
      "text": "The algorithm learned from historical hiring data â€” which reflected decades of human bias.",
      "visual": "ğŸ“Š"
    },
    "discovery": {
      "text": "Big data algorithms don't create bias. They amplify bias already baked into historical data.",
      "visual": "ğŸ“¢"
    },
    "twist": {
      "text": "Amazon scrapped the tool, but the lesson stuck: more data doesn't mean less discrimination.",
      "visual": "ğŸ—‘ï¸"
    },
    "climax": {
      "text": "Bias in data now affects criminal sentencing, loan approvals, and medical diagnosis.",
      "visual": "âš–ï¸"
    },
    "punchline": {
      "text": "Algorithms are only as fair as the data they learn from.",
      "visual": "ğŸ¤–"
    }
  },
  "quiz": {
    "question": "Why did Amazon's AI hiring tool discriminate against women?",
    "options": [
      "It was programmed to be biased",
      "It learned from historically biased hiring data",
      "It had a software bug"
    ],
    "correct": 1
  }
}
