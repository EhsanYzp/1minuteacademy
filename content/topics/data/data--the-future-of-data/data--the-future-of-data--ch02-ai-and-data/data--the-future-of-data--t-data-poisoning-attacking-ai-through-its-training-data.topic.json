{
  "id": "data--the-future-of-data--t-data-poisoning-attacking-ai-through-its-training-data",
  "version": 1,
  "subject": "Data",
  "subcategory": "The Future of Data",
  "course_id": "data--the-future-of-data",
  "chapter_id": "data--the-future-of-data--ch02-ai-and-data",
  "title": "Data Poisoning: Attacking AI Through Its Training Data",
  "emoji": "ğŸ”®",
  "color": "#9B59B6",
  "description": "A fast breakdown of Data Poisoning: Attacking AI Through Its Training Data for builders.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "What if someone secretly added misleading examples to an AI's training data? The model would learn to be wrong.",
      "visual": "â˜ ï¸"
    },
    "buildup": {
      "text": "Data poisoning attacks corrupt AI models by injecting malicious or misleading data into training sets.",
      "visual": "ğŸ’‰"
    },
    "discovery": {
      "text": "Researchers showed that poisoning just 3% of training data could make an image classifier misidentify stop signs.",
      "visual": "ğŸ›‘"
    },
    "twist": {
      "text": "As AI training data is scraped from the open internet, poisoning attacks become easier to execute at scale.",
      "visual": "ğŸŒ"
    },
    "climax": {
      "text": "Data integrity is becoming a national security concern as AI is deployed in military and critical infrastructure.",
      "visual": "ğŸ›¡ï¸"
    },
    "punchline": {
      "text": "The easiest way to attack AI isn't hacking the code. It's corrupting the data.",
      "visual": "ğŸ¯"
    }
  },
  "quiz": {
    "question": "What is data poisoning?",
    "options": [
      "Deleting training data",
      "Injecting malicious data to corrupt AI model behavior",
      "Encrypting data incorrectly"
    ],
    "correct": 1
  }
}
