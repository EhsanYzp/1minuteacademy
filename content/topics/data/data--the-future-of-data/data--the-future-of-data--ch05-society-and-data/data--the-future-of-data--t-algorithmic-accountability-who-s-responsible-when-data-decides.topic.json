{
  "id": "data--the-future-of-data--t-algorithmic-accountability-who-s-responsible-when-data-decides",
  "version": 1,
  "subject": "Data",
  "subcategory": "The Future of Data",
  "course_id": "data--the-future-of-data",
  "chapter_id": "data--the-future-of-data--ch05-society-and-data",
  "title": "Algorithmic Accountability: Who's Responsible When Data Decides?",
  "emoji": "ğŸ”®",
  "color": "#9B59B6",
  "description": "A short lesson to help you apply Algorithmic Accountability: Who's Responsible When Data Decides?.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "An algorithm denies your mortgage application. You ask why. The bank says: 'The model decided.' Is that acceptable?",
      "visual": "ğŸ¦"
    },
    "buildup": {
      "text": "Algorithms now make decisions about loans, hiring, parole, and insurance â€” often without human oversight.",
      "visual": "ğŸ¤–"
    },
    "discovery": {
      "text": "The EU's AI Act requires 'explainability' â€” high-risk AI decisions must come with understandable justifications.",
      "visual": "ğŸ“‹"
    },
    "twist": {
      "text": "Many powerful AI models are 'black boxes.' Even their creators can't fully explain why they made a specific decision.",
      "visual": "ğŸ“¦"
    },
    "climax": {
      "text": "The future demands a new kind of accountability: not just for human decisions, but for algorithmic ones.",
      "visual": "âš–ï¸"
    },
    "punchline": {
      "text": "If an algorithm decides your fate, someone must be accountable for how.",
      "visual": "ğŸ‘¤"
    }
  },
  "quiz": {
    "question": "What does the EU's AI Act require for high-risk AI decisions?",
    "options": [
      "That they be made by humans only",
      "Explainability â€” understandable justifications for decisions",
      "That they be free of charge"
    ],
    "correct": 1
  }
}
