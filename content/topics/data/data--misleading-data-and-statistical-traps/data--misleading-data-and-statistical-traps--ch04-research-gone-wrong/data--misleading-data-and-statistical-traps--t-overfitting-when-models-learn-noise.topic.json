{
  "id": "data--misleading-data-and-statistical-traps--t-overfitting-when-models-learn-noise",
  "version": 1,
  "subject": "Data",
  "subcategory": "Misleading Data and Statistical Traps",
  "course_id": "data--misleading-data-and-statistical-traps",
  "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
  "title": "Overfitting: When Models Learn Noise",
  "emoji": "ğŸ­",
  "color": "#E74C3C",
  "description": "A fast breakdown of Overfitting: When Models Learn Noise for builders.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "A stock prediction model achieves 99% accuracy on past data. It loses money the very first day of trading.",
      "visual": "ğŸ“‰"
    },
    "buildup": {
      "text": "Overfitting occurs when a model memorizes the training data instead of learning the underlying patterns.",
      "visual": "ğŸ§ "
    },
    "discovery": {
      "text": "An overfit model captures every random fluctuation as if it's meaningful â€” then fails on new data.",
      "visual": "ğŸ²"
    },
    "twist": {
      "text": "The more complex a model, the easier it overfits. Simplicity often beats sophistication in prediction.",
      "visual": "âœ‚ï¸"
    },
    "climax": {
      "text": "Overfitting is the reason 'past performance doesn't guarantee future results' â€” in investing and in science.",
      "visual": "âš ï¸"
    },
    "punchline": {
      "text": "A model that memorizes yesterday can't predict tomorrow.",
      "visual": "ğŸ“…"
    }
  },
  "quiz": {
    "question": "What is overfitting?",
    "options": [
      "Making a model too simple",
      "A model memorizing noise in training data and failing on new data",
      "Using too much data"
    ],
    "correct": 1
  }
}
