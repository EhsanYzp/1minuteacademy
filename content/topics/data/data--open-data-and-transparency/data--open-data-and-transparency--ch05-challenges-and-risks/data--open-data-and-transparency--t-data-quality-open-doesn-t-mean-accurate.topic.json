{
  "id": "data--open-data-and-transparency--t-data-quality-open-doesn-t-mean-accurate",
  "version": 1,
  "subject": "Data",
  "subcategory": "Open Data and Transparency",
  "course_id": "data--open-data-and-transparency",
  "chapter_id": "data--open-data-and-transparency--ch05-challenges-and-risks",
  "title": "Data Quality: Open Doesn't Mean Accurate",
  "emoji": "ğŸ›ï¸",
  "color": "#3498DB",
  "description": "A micro-lesson that makes Data Quality: Open Doesn't Mean Accurate usable.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "text": "A researcher downloads a government crime dataset and finds 30% of records have missing fields or impossible values.",
      "visual": "ğŸ“Š"
    },
    "buildup": {
      "text": "Open data is often messy â€” inconsistent formats, missing values, outdated records, and coding errors.",
      "visual": "ğŸ—‘ï¸"
    },
    "discovery": {
      "text": "Data cleaning â€” fixing and standardizing messy data â€” typically consumes 80% of any analysis project.",
      "visual": "ğŸ§¹"
    },
    "twist": {
      "text": "Some governments publish data knowing it's low quality, satisfying the 'open' label without being useful.",
      "visual": "ğŸ­"
    },
    "climax": {
      "text": "Open data without quality standards is like a free library where half the books have missing pages.",
      "visual": "ğŸ“š"
    },
    "punchline": {
      "text": "Open bad data is still bad data.",
      "visual": "âš ï¸"
    }
  },
  "quiz": {
    "question": "What percentage of analysis time is typically spent on data cleaning?",
    "options": [
      "About 10%",
      "About 80%",
      "About 50%"
    ],
    "correct": 1
  }
}
