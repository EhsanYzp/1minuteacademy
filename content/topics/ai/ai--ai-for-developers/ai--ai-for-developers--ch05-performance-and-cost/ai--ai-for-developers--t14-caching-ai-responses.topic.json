{
  "id": "ai--ai-for-developers--t14-caching-ai-responses",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI for Developers",
  "course_id": "ai--ai-for-developers",
  "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
  "title": "Caching AI Responses",
  "emoji": "üíª",
  "color": "#EF4444",
  "description": "Cache AI responses to reduce latency and costs dramatically.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "üóÑÔ∏è",
      "text": "An app makes the exact same API call 1,000 times a day. Each call costs $0.03. That's $30/day for the same answer."
    },
    "buildup": {
      "visual": "üîë",
      "text": "If the same input produces the same output, cache it. Use the prompt hash as the cache key and set a TTL based on how fresh the data needs to be."
    },
    "discovery": {
      "visual": "üß†",
      "text": "Semantic caching goes further: use embeddings to find similar (not just identical) queries and return cached responses. A 95% similar question probably has the same answer."
    },
    "twist": {
      "visual": "‚è∞",
      "text": "Caching non-deterministic outputs is tricky. Set temperature to 0 for cacheable calls, or cache the first response and accept slight variation."
    },
    "climax": {
      "visual": "‚ö°",
      "text": "With caching, repeated queries return in milliseconds instead of seconds, and your API bill drops by 50-90%."
    },
    "punchline": {
      "visual": "‚ôªÔ∏è",
      "text": "Don't ask twice what you already know."
    }
  },
  "quiz": {
    "question": "What does semantic caching use to match similar queries?",
    "options": [
      "Exact string matching",
      "Regular expressions",
      "Embeddings to find similarity",
      "Query length comparison"
    ],
    "correct": 2
  }
}
