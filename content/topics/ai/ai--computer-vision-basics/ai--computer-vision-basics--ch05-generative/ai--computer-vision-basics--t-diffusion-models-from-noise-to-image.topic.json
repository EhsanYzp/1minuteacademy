{
  "id": "ai--computer-vision-basics--t-diffusion-models-from-noise-to-image",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Computer Vision Basics",
  "course_id": "ai--computer-vision-basics",
  "chapter_id": "ai--computer-vision-basics--ch05-generative",
  "title": "Diffusion Models: From Noise to Image",
  "emoji": "üëÅÔ∏è",
  "color": "#059669",
  "description": "A quick win: understand Diffusion Models: From Noise to Image.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "Start with pure static. Remove noise step by step. A photo of a mountain appears.",
      "visual": "üì∫"
    },
    "buildup": {
      "text": "Diffusion models learn to reverse a noise-adding process, recovering the original image.",
      "visual": "üîÑ"
    },
    "discovery": {
      "text": "At each step, the model predicts and removes a small amount of noise.",
      "visual": "üßπ"
    },
    "twist": {
      "text": "Diffusion models are slow (many steps) but produce higher quality than GANs with stable training.",
      "visual": "‚è≥"
    },
    "climax": {
      "text": "Stable Diffusion, DALL-E, and Midjourney all use diffusion at their core.",
      "visual": "üé®"
    },
    "punchline": {
      "text": "Destroy it with noise. Reconstruct it with learning.",
      "visual": "‚ú®"
    }
  },
  "quiz": {
    "question": "How do diffusion models generate images?",
    "options": [
      "By gradually removing noise from random static",
      "By copying existing images",
      "By generating pixels left to right"
    ],
    "correct": 0
  }
}
