{
  "id": "ai--computer-vision-basics--t-transfer-learning-reuse-don-t-retrain",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Computer Vision Basics",
  "course_id": "ai--computer-vision-basics",
  "chapter_id": "ai--computer-vision-basics--ch02-cnns",
  "title": "Transfer Learning: Reuse, Don't Retrain",
  "emoji": "ğŸ‘ï¸",
  "color": "#059669",
  "description": "Learn Transfer Learning: Reuse, Don't Retrain in one minute.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "text": "You have 500 images of rare birds. Training from scratch won't work.",
      "visual": "ğŸ¦"
    },
    "buildup": {
      "text": "Transfer learning uses a model pre-trained on millions of images as a starting point.",
      "visual": "ğŸ—ï¸"
    },
    "discovery": {
      "text": "Freeze early layers (they detect edges and textures), fine-tune later layers for your task.",
      "visual": "â„ï¸"
    },
    "twist": {
      "text": "Even a model trained on dogs and cars transfers well to medical images. Features are universal.",
      "visual": "ğŸ¥"
    },
    "climax": {
      "text": "With transfer learning, 500 images can outperform 50,000 from scratch.",
      "visual": "ğŸ“ˆ"
    },
    "punchline": {
      "text": "Don't start from zero. Start from ImageNet.",
      "visual": "ğŸš€"
    }
  },
  "quiz": {
    "question": "Why does transfer learning work across different domains?",
    "options": [
      "Early layer features like edges are universal",
      "All images look the same",
      "The model memorizes all possible images"
    ],
    "correct": 0
  }
}
