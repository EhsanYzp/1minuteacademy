{
  "id": "ai--ai-for-product-teams--t-guardrails-keeping-ai-outputs-safe",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "AI for Product Teams",
  "course_id": "ai--ai-for-product-teams",
  "chapter_id": "ai--ai-for-product-teams--ch02-design",
  "title": "Guardrails: Keeping AI Outputs Safe",
  "emoji": "ğŸ“¦",
  "color": "#0D9488",
  "description": "A micro-lesson that makes Guardrails: Keeping AI Outputs Safe usable.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "Your customer-facing chatbot just recommended a competitor's product. Guardrails would have caught that.",
      "visual": "ğŸš§"
    },
    "buildup": {
      "text": "Guardrails are rules, filters, and checks applied to AI outputs before they reach users.",
      "visual": "ğŸ›¡ï¸"
    },
    "discovery": {
      "text": "Types: topic restrictions, profanity filters, PII detection, factual grounding checks.",
      "visual": "ğŸ“‹"
    },
    "twist": {
      "text": "Too many guardrails make the AI useless ('I can't help with that'). Balance safety and utility.",
      "visual": "âš–ï¸"
    },
    "climax": {
      "text": "Layer guardrails: input validation â†’ model constraints â†’ output filtering â†’ human review.",
      "visual": "ğŸ”§"
    },
    "punchline": {
      "text": "Freedom with fences. Safe enough to ship.",
      "visual": "ğŸ"
    }
  },
  "quiz": {
    "question": "What is a risk of too many guardrails?",
    "options": [
      "The AI becomes too restrictive and refuses valid requests",
      "It becomes more accurate",
      "Users prefer more restrictions"
    ],
    "correct": 0
  }
}
