{
  "id": "ai--nlp-essentials--t-tf-idf-words-that-matter",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "NLP Essentials",
  "course_id": "ai--nlp-essentials",
  "chapter_id": "ai--nlp-essentials--ch01-text-basics",
  "title": "TF-IDF: Words That Matter",
  "emoji": "ğŸ’¬",
  "color": "#D97706",
  "description": "A quick win: understand TF-IDF: Words That Matter.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "The word 'the' appears in every document. It tells you nothing. TF-IDF knows that.",
      "visual": "ğŸ“‰"
    },
    "buildup": {
      "text": "TF-IDF multiplies term frequency (how often) by inverse document frequency (how rare).",
      "visual": "ğŸ§®"
    },
    "discovery": {
      "text": "Common words get downweighted. Rare, distinctive words get boosted.",
      "visual": "ğŸ“ˆ"
    },
    "twist": {
      "text": "TF-IDF is still used in production search engines alongside neural methods.",
      "visual": "ğŸ”"
    },
    "climax": {
      "text": "BM25, the backbone of Elasticsearch, is essentially a tuned TF-IDF variant.",
      "visual": "âš™ï¸"
    },
    "punchline": {
      "text": "Not how often. How distinctive.",
      "visual": "ğŸ’"
    }
  },
  "quiz": {
    "question": "What does inverse document frequency measure?",
    "options": [
      "How rare a word is across all documents",
      "How often a word appears in one document",
      "The length of the document"
    ],
    "correct": 0
  }
}
