{
  "id": "ai--agent-builder-lab--t33-hallucinated-memory",
  "version": 1,
  "subject": "AI",
  "subcategory": "Agent Builder Lab",
  "course_id": "ai--agent-builder-lab",
  "chapter_id": "ai--agent-builder-lab--ch04-memory-and-rag",
  "title": "Hallucinated Memory",
  "emoji": "ğŸ¤–",
  "color": "#EF4444",
  "description": "A micro-lesson that makes Hallucinated Memory usable.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“Œ",
      "text": "The agent says: â€œI remember you canceled.â€ The user says: â€œI didnâ€™t.â€ Now you have a trust problem."
    },
    "buildup": {
      "visual": "ğŸ§­",
      "text": "Memory should be treated as a claim that needs evidenceâ€”not as something the model gets to invent."
    },
    "discovery": {
      "visual": "ğŸ§°",
      "text": "Only write memory after verification (tool result) or explicit user confirmation. Store provenance so you can audit it later."
    },
    "twist": {
      "visual": "ğŸ§±",
      "text": "Hallucinated memory is sneaky because it often sounds reasonableâ€”and nobody notices until it hurts."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Add a memory-write gate: validation rules, safe fields, and a â€œdo not storeâ€ list (PII + guesses)."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Earn memory."
    }
  },
  "quiz": {
    "question": "How do you prevent hallucinated memory?",
    "options": [
      "Turn up temperature",
      "Require evidence/validation before writes",
      "Disable monitoring",
      "Avoid test sets"
    ],
    "correct": 1
  }
}
