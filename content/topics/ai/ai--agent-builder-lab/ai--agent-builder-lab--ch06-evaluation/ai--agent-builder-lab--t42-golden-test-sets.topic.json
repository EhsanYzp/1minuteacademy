{
  "id": "ai--agent-builder-lab--t42-golden-test-sets",
  "version": 1,
  "subject": "AI",
  "subcategory": "Agent Builder Lab",
  "course_id": "ai--agent-builder-lab",
  "chapter_id": "ai--agent-builder-lab--ch06-evaluation",
  "title": "Golden Test Sets",
  "emoji": "ğŸ¤–",
  "color": "#EF4444",
  "description": "A short lesson to help you apply Golden Test Sets.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ§­",
      "text": "It answered correctly yesterday. You changed one prompt. Today itâ€™s wrong. Golden sets catch that."
    },
    "buildup": {
      "visual": "ğŸ§©",
      "text": "A golden set is a fixed list of representative cases you run on every change."
    },
    "discovery": {
      "visual": "ğŸ§©",
      "text": "Curate real examples: common requests, tricky edge cases, and the last 10 bugs you fixed."
    },
    "twist": {
      "visual": "ğŸ•³ï¸",
      "text": "If you only test on new cases, youâ€™ll miss quiet regressions in old flows that still matter to users."
    },
    "climax": {
      "visual": "ğŸ§±",
      "text": "Automate it: run the golden set in CI, diff results, and block deploys when high-impact cases break."
    },
    "punchline": {
      "visual": "âœ¨",
      "text": "Freeze some tests."
    }
  },
  "quiz": {
    "question": "Whatâ€™s the purpose of a golden set?",
    "options": [
      "UI demos",
      "Regression detection",
      "Increasing randomness",
      "Avoiding monitoring"
    ],
    "correct": 1
  }
}
