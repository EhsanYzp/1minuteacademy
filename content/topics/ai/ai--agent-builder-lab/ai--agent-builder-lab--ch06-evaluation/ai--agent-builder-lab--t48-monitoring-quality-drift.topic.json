{
  "id": "ai--agent-builder-lab--t48-monitoring-quality-drift",
  "version": 1,
  "subject": "AI",
  "subcategory": "Agent Builder Lab",
  "course_id": "ai--agent-builder-lab",
  "chapter_id": "ai--agent-builder-lab--ch06-evaluation",
  "title": "Monitoring Quality Drift",
  "emoji": "ü§ñ",
  "color": "#EF4444",
  "description": "A short lesson to help you apply Monitoring Quality Drift.",
  "difficulty": "Premium",
  "published": true,
  "story": {
    "hook": {
      "visual": "üß≠",
      "text": "It was great last month. Now it‚Äôs confusing. Drift happens‚Äîyour job is to catch it early."
    },
    "buildup": {
      "visual": "üß©",
      "text": "Production behavior changes: model updates, new docs, new tools, new users. Monitoring tells you when quality slips."
    },
    "discovery": {
      "visual": "üß©",
      "text": "Track key metrics over time and sample real conversations for review (with privacy controls)."
    },
    "twist": {
      "visual": "üï≥Ô∏è",
      "text": "The scariest drift is quiet drift: nothing ‚Äúbreaks‚Äù, but users slowly lose trust."
    },
    "climax": {
      "visual": "üß±",
      "text": "Set alerts on leading indicators (escalations, retries, tool error rate) so you find issues before Twitter does."
    },
    "punchline": {
      "visual": "‚ú®",
      "text": "Drift happens. Detect it early."
    }
  },
  "quiz": {
    "question": "What is drift monitoring for?",
    "options": [
      "UI polish",
      "Detecting quality changes over time",
      "Avoiding metrics",
      "Replacing test sets"
    ],
    "correct": 1
  }
}
