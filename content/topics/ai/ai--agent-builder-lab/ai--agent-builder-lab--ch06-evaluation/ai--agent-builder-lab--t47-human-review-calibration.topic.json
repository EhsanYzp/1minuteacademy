{
  "id": "ai--agent-builder-lab--t47-human-review-calibration",
  "version": 1,
  "subject": "AI",
  "subcategory": "Agent Builder Lab",
  "course_id": "ai--agent-builder-lab",
  "chapter_id": "ai--agent-builder-lab--ch06-evaluation",
  "title": "Human Review Calibration",
  "emoji": "ðŸ¤–",
  "color": "#EF4444",
  "description": "A micro-lesson that makes Human Review Calibration usable.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ðŸ¤–",
      "text": "A quick win: Human Review Calibration."
    },
    "buildup": {
      "visual": "ðŸ“Œ",
      "text": "If you had to choose one outcome, choose: Align reviewers so scores mean the same thing."
    },
    "discovery": {
      "visual": "ðŸ“Ž",
      "text": "Concrete technique: Run calibration sessions with examples."
    },
    "twist": {
      "visual": "ðŸ§¨",
      "text": "The thing that looks fineâ€¦ until it isnâ€™t: Different reviewers using different standards."
    },
    "climax": {
      "visual": "ðŸ§­",
      "text": "The decision you keep making over and over: Align reviewers so scores mean the same thing."
    },
    "punchline": {
      "visual": "ðŸ§¾",
      "text": "Calibration prevents phantom regressions."
    }
  },
  "quiz": {
    "question": "Why calibrate reviewers?",
    "options": [
      "To slow down shipping",
      "To align scoring standards",
      "To remove rubrics",
      "To hide disagreements"
    ],
    "correct": 1
  }
}
