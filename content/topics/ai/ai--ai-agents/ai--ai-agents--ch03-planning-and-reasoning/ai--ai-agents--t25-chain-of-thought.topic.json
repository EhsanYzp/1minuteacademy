{
  "id": "ai--ai-agents--t25-chain-of-thought",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Agents",
  "course_id": "ai--ai-agents",
  "chapter_id": "ai--ai-agents--ch03-planning-and-reasoning",
  "title": "Chain of Thought",
  "emoji": "ğŸ¤–",
  "color": "#EF4444",
  "description": "How making agents show their work dramatically improves reasoning.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ§ ",
      "text": "Ask a model: 'If I have 23 apples and give away 7, then buy 12 more, how many do I have?' Without chain of thought, it often guesses wrong. With it, accuracy jumps 40%."
    },
    "buildup": {
      "visual": "ğŸ“",
      "text": "Chain of thought (CoT) means prompting the model to reason step by step before giving its final answer. 'Think through this step by step' is the simplest CoT prompt."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "For agents, CoT means the model explains its plan before acting: 'First, I'll search for the user's order. Then I'll check its status. If it's shipped, I'll provide the tracking number.'"
    },
    "twist": {
      "visual": "âš¡",
      "text": "CoT uses more tokens (the reasoning is generated text), but the accuracy improvement usually more than pays for itself. The tradeoff is cost vs reliability."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "In agent systems, CoT serves double duty: it improves reasoning AND provides an audit trail. You can inspect the agent's thought process when debugging."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Thinking out loud isn't just for humans. It makes AI more reliable too."
    }
  },
  "quiz": {
    "question": "What is the main benefit of chain-of-thought prompting for agents?",
    "options": [
      "It makes responses shorter",
      "It improves reasoning accuracy by forcing step-by-step thinking",
      "It eliminates the need for tools",
      "It reduces API costs"
    ],
    "correct": 1
  }
}
