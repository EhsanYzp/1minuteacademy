{
  "id": "ai--ai-agents--t12-short-term-memory",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Agents",
  "course_id": "ai--ai-agents",
  "chapter_id": "ai--ai-agents--ch04-memory",
  "title": "Short-Term Memory",
  "emoji": "ü§ñ",
  "color": "#EF4444",
  "description": "Conversation history and scratchpad within a single session.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "üìù",
      "text": "The agent calls 5 tools and gets 5 results. By the time it reaches tool call 6, has it forgotten what tool call 2 returned? It depends on how you manage memory."
    },
    "buildup": {
      "visual": "üß†",
      "text": "Short-term memory is the agent's working context: conversation history, tool call results, and any intermediate reasoning. It lives in the prompt and grows with each step."
    },
    "discovery": {
      "visual": "üí°",
      "text": "The simplest implementation: append every thought, action, and observation to the message history. The model sees the full trace when deciding the next step."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Short-term memory fills the context window. After 20 tool calls with verbose results, you run out of space. Summarize earlier steps or drop irrelevant ones to stay within limits."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Manage short-term memory actively: keep recent steps in full, summarize older steps, and drop tool results that are no longer relevant."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "An agent that forgets what it did 3 steps ago makes circles. Manage the scratchpad."
    }
  },
  "quiz": {
    "question": "What is the main challenge with agent short-term memory?",
    "options": [
      "LLMs have perfect memory",
      "The growing message history eventually exceeds the context window",
      "Short-term memory is stored in a database",
      "Agents don't need memory"
    ],
    "correct": 1
  }
}
