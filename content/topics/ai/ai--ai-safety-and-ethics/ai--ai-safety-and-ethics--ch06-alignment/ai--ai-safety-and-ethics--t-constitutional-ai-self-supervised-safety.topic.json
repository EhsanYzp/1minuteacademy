{
  "id": "ai--ai-safety-and-ethics--t-constitutional-ai-self-supervised-safety",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "AI Safety & Ethics",
  "course_id": "ai--ai-safety-and-ethics",
  "chapter_id": "ai--ai-safety-and-ethics--ch06-alignment",
  "title": "Constitutional AI: Self-Supervised Safety",
  "emoji": "ğŸ›¡ï¸",
  "color": "#DC2626",
  "description": "A tiny lesson with a big payoff: Constitutional AI: Self-Supervised Safety.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "What if the model could critique its own outputs against a set of principles?",
      "visual": "ğŸ“œ"
    },
    "buildup": {
      "text": "Constitutional AI gives the model a set of rules (a 'constitution') to self-evaluate.",
      "visual": "âš–ï¸"
    },
    "discovery": {
      "text": "The model generates a response, critiques it against the constitution, and revises.",
      "visual": "ğŸ”„"
    },
    "twist": {
      "text": "This reduces the need for expensive human feedback but inherits the model's own biases.",
      "visual": "ğŸª"
    },
    "climax": {
      "text": "It's a scalable approach but still requires human oversight for the constitution itself.",
      "visual": "ğŸ‘¥"
    },
    "punchline": {
      "text": "Rules for the AI, written by humans, enforced by the AI.",
      "visual": "ğŸ“‹"
    }
  },
  "quiz": {
    "question": "How does constitutional AI work?",
    "options": [
      "The model critiques its own outputs against defined principles",
      "It uses a physical constitution",
      "It has no safety rules"
    ],
    "correct": 0
  }
}
