{
  "id": "ai--science-of-ml--t-naive-bayes-probability-to-the-rescue",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "The Science of Machine Learning",
  "course_id": "ai--science-of-ml",
  "chapter_id": "ai--science-of-ml--ch02-supervised",
  "title": "Naive Bayes: Probability to the Rescue",
  "emoji": "ğŸ”¬",
  "color": "#7C3AED",
  "description": "A fast breakdown of Naive Bayes: Probability to the Rescue for builders.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "An email contains 'winner,' 'prize,' and 'click here.' What's the probability it's spam? Very high.",
      "visual": "ğŸ°"
    },
    "buildup": {
      "text": "Naive Bayes uses Bayes' theorem to calculate the probability of each class given the evidence.",
      "visual": "ğŸ“Š"
    },
    "discovery": {
      "text": "It's 'naive' because it assumes features are independent â€” which is usually wrong but works anyway.",
      "visual": "ğŸ¤·"
    },
    "twist": {
      "text": "Despite the wrong assumption, it often beats more complex models on text classification.",
      "visual": "ğŸ†"
    },
    "climax": {
      "text": "Gmail's original spam filter was built on Naive Bayes. Simplicity won.",
      "visual": "ğŸ“§"
    },
    "punchline": {
      "text": "Wrong assumptions, right answers. Classic machine learning.",
      "visual": "ğŸ­"
    }
  },
  "quiz": {
    "question": "Why is Naive Bayes called 'naive'?",
    "options": [
      "It assumes all features are independent of each other",
      "It's too simple to be useful",
      "It was the first algorithm invented"
    ],
    "correct": 0
  }
}
