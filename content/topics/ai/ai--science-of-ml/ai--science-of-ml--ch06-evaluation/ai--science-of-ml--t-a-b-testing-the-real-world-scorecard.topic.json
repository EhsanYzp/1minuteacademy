{
  "id": "ai--science-of-ml--t-a-b-testing-the-real-world-scorecard",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "The Science of Machine Learning",
  "course_id": "ai--science-of-ml",
  "chapter_id": "ai--science-of-ml--ch06-evaluation",
  "title": "A/B Testing: The Real-World Scorecard",
  "emoji": "ğŸ”¬",
  "color": "#7C3AED",
  "description": "A tiny lesson with a big payoff: A/B Testing: The Real-World Scorecard.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "Your model beats the baseline in the lab. But does it actually improve the user experience? A/B test it.",
      "visual": "ğŸ§ª"
    },
    "buildup": {
      "text": "A/B testing shows the old model to half the users and the new model to the other half.",
      "visual": "ğŸ”€"
    },
    "discovery": {
      "text": "You measure real outcomes â€” clicks, purchases, satisfaction â€” not just prediction accuracy.",
      "visual": "ğŸ“ˆ"
    },
    "twist": {
      "text": "Sometimes a more accurate model hurts user experience. People don't always want optimal recommendations.",
      "visual": "ğŸ˜•"
    },
    "climax": {
      "text": "Google runs thousands of A/B tests per year. Every search change is validated this way.",
      "visual": "ğŸ”"
    },
    "punchline": {
      "text": "The only metric that matters is impact in the real world.",
      "visual": "ğŸŒ"
    }
  },
  "quiz": {
    "question": "Why do companies A/B test AI models?",
    "options": [
      "To measure real-world impact, not just lab accuracy",
      "Because lab testing is impossible",
      "To make models train faster"
    ],
    "correct": 0
  }
}
