{
  "id": "ai--science-of-ml--t-cross-validation-trust-but-verify",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "The Science of Machine Learning",
  "course_id": "ai--science-of-ml",
  "chapter_id": "ai--science-of-ml--ch06-evaluation",
  "title": "Cross-Validation: Trust but Verify",
  "emoji": "ğŸ”¬",
  "color": "#7C3AED",
  "description": "A quick, practical guide to Cross-Validation: Trust but Verify.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "Your model scores 99% accuracy. Impressive â€” until you realize it memorized the test answers.",
      "visual": "ğŸ“"
    },
    "buildup": {
      "text": "Cross-validation splits data into multiple folds, training and testing on different subsets each time.",
      "visual": "ğŸ”€"
    },
    "discovery": {
      "text": "By averaging performance across all folds, you get a reliable estimate of real-world accuracy.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "Even cross-validation can mislead if your data has temporal ordering or group structures that leak.",
      "visual": "ğŸ’§"
    },
    "climax": {
      "text": "Proper validation is the difference between a model that works in the lab and one that works in life.",
      "visual": "ğŸŒ"
    },
    "punchline": {
      "text": "Test yourself on the questions you haven't seen. That's the real exam.",
      "visual": "ğŸ“"
    }
  },
  "quiz": {
    "question": "Why is cross-validation more reliable than a single train-test split?",
    "options": [
      "It averages performance across multiple data subsets",
      "It uses more training data overall",
      "It trains the model faster"
    ],
    "correct": 0
  }
}
