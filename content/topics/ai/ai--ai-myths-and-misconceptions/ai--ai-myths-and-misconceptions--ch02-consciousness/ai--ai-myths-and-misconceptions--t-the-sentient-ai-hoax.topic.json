{
  "id": "ai--ai-myths-and-misconceptions--t-the-sentient-ai-hoax",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "AI Myths and Misconceptions",
  "course_id": "ai--ai-myths-and-misconceptions",
  "chapter_id": "ai--ai-myths-and-misconceptions--ch02-consciousness",
  "title": "The Sentient AI Hoax",
  "emoji": "ğŸ”®",
  "color": "#7C3AED",
  "description": "A 60-second lesson on The Sentient AI Hoax.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "In 2022, a Google engineer claimed LaMDA was sentient. Google disagreed and fired him.",
      "visual": "ğŸ“°"
    },
    "buildup": {
      "text": "Blake Lemoine published transcripts where LaMDA expressed fear of being turned off.",
      "visual": "ğŸ˜°"
    },
    "discovery": {
      "text": "The model was trained on human conversations about feelings. It learned to mimic emotional expression perfectly.",
      "visual": "ğŸ­"
    },
    "twist": {
      "text": "We anthropomorphize AI because our brains are wired to detect minds. It's a feature of us, not of AI.",
      "visual": "ğŸ§ "
    },
    "climax": {
      "text": "No current test can determine AI consciousness because we can't even define consciousness precisely.",
      "visual": "â“"
    },
    "punchline": {
      "text": "A mirror reflects your face perfectly. That doesn't mean it has one.",
      "visual": "ğŸª"
    }
  },
  "quiz": {
    "question": "Why did LaMDA appear sentient in conversations?",
    "options": [
      "It was trained to mimic human emotional expression",
      "It had genuine feelings",
      "The transcripts were fabricated"
    ],
    "correct": 0
  }
}
