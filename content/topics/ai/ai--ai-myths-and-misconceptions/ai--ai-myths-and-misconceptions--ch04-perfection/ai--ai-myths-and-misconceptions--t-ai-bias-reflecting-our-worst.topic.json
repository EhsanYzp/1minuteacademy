{
  "id": "ai--ai-myths-and-misconceptions--t-ai-bias-reflecting-our-worst",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "AI Myths and Misconceptions",
  "course_id": "ai--ai-myths-and-misconceptions",
  "chapter_id": "ai--ai-myths-and-misconceptions--ch04-perfection",
  "title": "AI Bias: Reflecting Our Worst",
  "emoji": "ğŸ”®",
  "color": "#7C3AED",
  "description": "One-minute skill: AI Bias: Reflecting Our Worst.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "An AI hiring tool at Amazon penalized resumes containing the word 'women's.' Amazon scrapped it.",
      "visual": "ğŸ“„"
    },
    "buildup": {
      "text": "AI learns from historical data. If that data contains bias, the AI reproduces and amplifies it.",
      "visual": "ğŸ“ˆ"
    },
    "discovery": {
      "text": "Bias isn't a bug â€” it's a mirror. AI reflects the patterns in the data humans created.",
      "visual": "ğŸª"
    },
    "twist": {
      "text": "Fixing bias in AI is hard because it requires agreeing on what fairness means â€” and humans disagree.",
      "visual": "ğŸ¤"
    },
    "climax": {
      "text": "Despite awareness, biased AI systems are still deployed in criminal justice, lending, and healthcare.",
      "visual": "ğŸ›ï¸"
    },
    "punchline": {
      "text": "Garbage in, bias out. The machine learns what we teach it.",
      "visual": "ğŸ“–"
    }
  },
  "quiz": {
    "question": "Why did Amazon's AI hiring tool discriminate against women?",
    "options": [
      "It learned from historical hiring data that reflected existing gender bias",
      "It was intentionally programmed to discriminate",
      "Women submitted fewer resumes to Amazon"
    ],
    "correct": 0
  }
}
