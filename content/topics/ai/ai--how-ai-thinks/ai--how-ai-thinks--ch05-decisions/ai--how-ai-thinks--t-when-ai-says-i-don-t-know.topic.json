{
  "id": "ai--how-ai-thinks--t-when-ai-says-i-don-t-know",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "How AI Thinks",
  "course_id": "ai--how-ai-thinks",
  "chapter_id": "ai--how-ai-thinks--ch05-decisions",
  "title": "When AI Says 'I Don't Know'",
  "emoji": "ðŸ§ ",
  "color": "#7C3AED",
  "description": "One-minute skill: When AI Says 'I Don't Know'.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "A doctor wants AI to admit uncertainty. Most models would rather make something up.",
      "visual": "ðŸ¤–"
    },
    "buildup": {
      "text": "Standard models always produce an output, even when they have zero confidence.",
      "visual": "ðŸŽ°"
    },
    "discovery": {
      "text": "Calibrated models can express uncertainty â€” 'I'm only 40% sure this is benign.'",
      "visual": "ðŸ“Š"
    },
    "twist": {
      "text": "Overconfident AI in healthcare led to wrong diagnoses. Calibration saves lives.",
      "visual": "ðŸ’Š"
    },
    "climax": {
      "text": "Engineers now design systems that flag low-confidence answers for human review.",
      "visual": "ðŸš©"
    },
    "punchline": {
      "text": "The best AI knows what it doesn't know.",
      "visual": "ðŸ§ "
    }
  },
  "quiz": {
    "question": "What is calibration in AI?",
    "options": [
      "Making confidence scores match actual accuracy",
      "Adjusting hardware settings",
      "Retraining the model from scratch"
    ],
    "correct": 0
  }
}
