{
  "id": "ai--model-limitations--t32-ensemble-approaches",
  "version": 1,
  "subject": "AI",
  "subcategory": "Model Limitations",
  "course_id": "ai--model-limitations",
  "chapter_id": "ai--model-limitations--ch06-working-around-limits",
  "title": "Ensemble Approaches",
  "emoji": "üöß",
  "color": "#EF4444",
  "description": "Using multiple models or calls to compensate for individual model weaknesses.",
  "difficulty": "Premium",
  "published": true,
  "story": {
    "hook": {
      "visual": "ü§ù",
      "text": "One model generates the answer. A second model checks it for accuracy. A third model evaluates whether it answered the actual question. Three imperfect models, one reliable system."
    },
    "buildup": {
      "visual": "üîó",
      "text": "Ensemble approaches use multiple models (or multiple calls to the same model) and combine their outputs. If one model hallucinates, the others catch it. If one misinterprets, others compensate."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Ensemble patterns: (1) Generate-then-verify: one model writes, another checks. (2) Majority voting: run the same query 3 times, take the most common answer. (3) Specialisation: different models for different subtasks."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Ensembles multiply cost and latency. Three model calls cost 3x. Design ensembles for high-stakes tasks where accuracy matters more than speed or cost."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "The sweet spot: use a cheap fast model for routine tasks, and an ensemble of capable models for high-stakes decisions. Not every question needs three opinions."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "One model is an opinion. Multiple models are a committee. Committees are slower but make fewer mistakes."
    }
  },
  "quiz": {
    "question": "What is the main tradeoff of ensemble approaches?",
    "options": [
      "They reduce accuracy",
      "They increase cost and latency in exchange for higher reliability",
      "They're always faster than single models",
      "They don't work with LLMs"
    ],
    "correct": 1
  }
}
