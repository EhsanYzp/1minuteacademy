{
  "id": "ai--model-limitations--t03-confidence-without-correctness",
  "version": 1,
  "subject": "AI",
  "subcategory": "Model Limitations",
  "course_id": "ai--model-limitations",
  "chapter_id": "ai--model-limitations--ch01-what-models-cant-do",
  "title": "Confidence Without Correctness",
  "emoji": "ğŸš§",
  "color": "#EF4444",
  "description": "Models sound certain even when they're wrong.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ­",
      "text": "'The capital of Australia is Sydney,' the model states confidently. It's wrong â€” it's Canberra. But the sentence was grammatically perfect and delivered without hesitation."
    },
    "buildup": {
      "visual": "ğŸ“Š",
      "text": "LLMs don't have a reliable confidence signal. They generate text with the same fluency whether the content is correct or fabricated. There's no built-in 'I'm not sure' mechanism."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "This is fundamentally different from humans: a human might pause, say 'I think...' or 'I'm not sure.' An LLM produces equally confident text for facts and fabrications."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Users interpret confident language as correctness. Studies show people trust AI answers more when they sound authoritative â€” even when they're wrong. Confidence is a UX problem, not just a model problem."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Design for this limitation: add verification steps, show sources, use phrases like 'Based on my training data...' and never present AI outputs as authoritative facts."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Confidence â‰  correctness. The model sounds sure because it always sounds sure. Verify everything."
    }
  },
  "quiz": {
    "question": "Why is LLM confidence misleading?",
    "options": [
      "LLMs are always correct",
      "Models generate equally fluent text for correct and incorrect information",
      "Confidence always correlates with accuracy",
      "LLMs explicitly flag uncertainty"
    ],
    "correct": 1
  }
}
