{
  "id": "ai--model-limitations--t01-models-are-not-minds",
  "version": 1,
  "subject": "AI",
  "subcategory": "Model Limitations",
  "course_id": "ai--model-limitations",
  "chapter_id": "ai--model-limitations--ch01-what-models-cant-do",
  "title": "Models Are Not Minds",
  "emoji": "ğŸš§",
  "color": "#EF4444",
  "description": "LLMs predict tokens â€” they don't think or understand.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ§ ",
      "text": "The model writes a poem about grief that makes you cry. It must understand grief, right? No. It predicts which words follow other words. It's never felt anything."
    },
    "buildup": {
      "visual": "ğŸ“‹",
      "text": "LLMs are statistical pattern matchers trained on text. They learn which token is likely to come next given the previous tokens. The output looks like understanding, but the mechanism is pattern completion."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "This distinction matters practically: the model doesn't 'know' your codebase. It generates plausible-sounding code based on patterns. It can't verify truth â€” it can only predict likely text."
    },
    "twist": {
      "visual": "âš¡",
      "text": "The illusion of understanding is powerful. Users confide personal problems to chatbots, trust medical advice from models, and attribute emotions to text generators. Recognizing the illusion is step one."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Use models for what they're good at: pattern-based generation. Don't use them for what requires genuine understanding, verification, or reasoning from first principles."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "It writes like it thinks. It doesn't think. The output is impressive, but the mechanism is pattern matching."
    }
  },
  "quiz": {
    "question": "What is the core mechanism of LLM text generation?",
    "options": [
      "Deep understanding of concepts and reasoning",
      "Predicting the most likely next token based on training patterns",
      "Retrieving answers from a knowledge database",
      "Simulating human consciousness"
    ],
    "correct": 1
  }
}
