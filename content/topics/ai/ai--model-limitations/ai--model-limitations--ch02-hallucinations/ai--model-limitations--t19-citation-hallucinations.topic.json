{
  "id": "ai--model-limitations--t19-citation-hallucinations",
  "version": 1,
  "subject": "AI",
  "subcategory": "Model Limitations",
  "course_id": "ai--model-limitations",
  "chapter_id": "ai--model-limitations--ch02-hallucinations",
  "title": "Citation Hallucinations",
  "emoji": "ğŸš§",
  "color": "#EF4444",
  "description": "When AI invents fake references that look completely real.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“š",
      "text": "A lawyer uses ChatGPT to prepare a legal brief. It cites six relevant cases with real-sounding names, courts, and dates. None of them exist. The lawyer is sanctioned by the judge."
    },
    "buildup": {
      "visual": "ğŸ“–",
      "text": "Citation hallucination: the model generates references that follow the format of real citations (author names, journal titles, years, DOIs) but point to papers, cases, or books that don't exist."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "The model learned the pattern of citations, not the citations themselves. It knows 'Smith et al., 2021, Nature, vol. 589' looks like a valid citation, so it generates plausible ones."
    },
    "twist": {
      "visual": "âš¡",
      "text": "These are extra dangerous because they pass casual verification: the author exists, the journal exists, the date range is reasonable. You have to actually look up the specific reference to discover it's fake."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Never trust AI-generated citations without verifying them. Use RAG with real document sources, or explicitly instruct the model to cite only from provided documents."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "AI writes perfect-looking citations to papers that don't exist. Verify every single one."
    }
  },
  "quiz": {
    "question": "Why are citation hallucinations particularly dangerous?",
    "options": [
      "They're easy to spot",
      "They follow real citation formats with plausible details, making casual verification insufficient",
      "They only occur with small models",
      "They always contain obviously fake names"
    ],
    "correct": 1
  }
}
