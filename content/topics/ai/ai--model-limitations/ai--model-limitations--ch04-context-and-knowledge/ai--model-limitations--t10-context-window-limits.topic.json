{
  "id": "ai--model-limitations--t10-context-window-limits",
  "version": 1,
  "subject": "AI",
  "subcategory": "Model Limitations",
  "course_id": "ai--model-limitations",
  "chapter_id": "ai--model-limitations--ch04-context-and-knowledge",
  "title": "Context Window Limits",
  "emoji": "üöß",
  "color": "#EF4444",
  "description": "The model can only see a limited amount of text at once.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "üìè",
      "text": "You paste a 200-page document into the prompt. The model summarizes the first 10 pages and the last 10 pages. The middle 180 pages might as well not exist."
    },
    "buildup": {
      "visual": "üìä",
      "text": "The context window is the total amount of text the model can process at once: system prompt + conversation history + input + response all share the same limit."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Even with 128K or 1M token windows, models don't attend equally to all positions. Information in the middle of a long context is often missed ‚Äî the 'lost in the middle' phenomenon."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Bigger context windows don't solve the problem ‚Äî they just move the boundary. A model with a 1M token window still struggles with information in the middle of 500K tokens."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Don't rely on large context windows for precise retrieval. Use RAG to find the relevant pieces first, then give the model only what it needs ‚Äî focused context beats massive context."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "The model can see a lot of text. It pays attention to much less. Focus the context, don't flood it."
    }
  },
  "quiz": {
    "question": "What is the 'lost in the middle' phenomenon?",
    "options": [
      "Models process all context positions equally",
      "Models tend to miss information placed in the middle of long contexts, favoring the beginning and end",
      "Context windows are unlimited",
      "Only short contexts have this problem"
    ],
    "correct": 1
  }
}
