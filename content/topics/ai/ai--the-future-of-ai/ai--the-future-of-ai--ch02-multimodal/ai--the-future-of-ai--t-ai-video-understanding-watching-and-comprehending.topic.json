{
  "id": "ai--the-future-of-ai--t-ai-video-understanding-watching-and-comprehending",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "The Future of AI",
  "course_id": "ai--the-future-of-ai",
  "chapter_id": "ai--the-future-of-ai--ch02-multimodal",
  "title": "AI Video Understanding: Watching and Comprehending",
  "emoji": "ğŸ”­",
  "color": "#7C3AED",
  "description": "A 1-minute de-risking session on AI Video Understanding: Watching and Comprehending.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "An AI watches a cooking video and writes a complete recipe with precise timings and quantities.",
      "visual": "ğŸ³"
    },
    "buildup": {
      "text": "Video understanding combines visual perception, temporal reasoning, and language generation.",
      "visual": "ğŸ¬"
    },
    "discovery": {
      "text": "Models like Gemini process hours of video, answering questions about events across the full timeline.",
      "visual": "â±ï¸"
    },
    "twist": {
      "text": "Understanding video requires tracking objects, actions, and context over time â€” much harder than single images.",
      "visual": "ğŸ§©"
    },
    "climax": {
      "text": "Video AI enables automatic surveillance analysis, sports coaching, and accessibility for the visually impaired.",
      "visual": "â™¿"
    },
    "punchline": {
      "text": "First it saw photos. Now it watches movies. It's learning to understand stories.",
      "visual": "ğŸ“º"
    }
  },
  "quiz": {
    "question": "Why is video understanding harder than image understanding for AI?",
    "options": [
      "It requires tracking objects and context across time, not just single frames",
      "Videos have lower resolution than photos",
      "AI can already understand video perfectly"
    ],
    "correct": 0
  }
}
