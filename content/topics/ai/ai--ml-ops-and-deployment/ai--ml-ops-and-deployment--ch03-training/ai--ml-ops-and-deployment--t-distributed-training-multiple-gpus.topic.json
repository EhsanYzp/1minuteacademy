{
  "id": "ai--ml-ops-and-deployment--t-distributed-training-multiple-gpus",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "ML Ops & Deployment",
  "course_id": "ai--ml-ops-and-deployment",
  "chapter_id": "ai--ml-ops-and-deployment--ch03-training",
  "title": "Distributed Training: Multiple GPUs",
  "emoji": "ğŸš€",
  "color": "#4F46E5",
  "description": "A short lesson to help you apply Distributed Training: Multiple GPUs.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "Your model takes 30 days to train on one GPU. On 8 GPUs, it takes 4 days.",
      "visual": "â±ï¸"
    },
    "buildup": {
      "text": "Distributed training splits work across multiple GPUs to reduce training time.",
      "visual": "ğŸ”€"
    },
    "discovery": {
      "text": "Data parallelism: each GPU trains on a different batch, gradients are averaged.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "Communication overhead between GPUs can eat your speedup if batch sizes are too small.",
      "visual": "ğŸ“¡"
    },
    "climax": {
      "text": "Model parallelism splits the model itself across GPUsâ€”needed for models too large for one card.",
      "visual": "ğŸ§©"
    },
    "punchline": {
      "text": "More GPUs, less time. If you do it right.",
      "visual": "âš¡"
    }
  },
  "quiz": {
    "question": "What is data parallelism?",
    "options": [
      "Each GPU trains on a different batch, gradients are averaged",
      "Splitting the model across GPUs",
      "Using CPUs instead of GPUs"
    ],
    "correct": 0
  }
}
