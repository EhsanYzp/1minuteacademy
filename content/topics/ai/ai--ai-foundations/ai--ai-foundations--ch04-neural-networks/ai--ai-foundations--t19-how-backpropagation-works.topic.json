{
  "id": "ai--ai-foundations--t19-how-backpropagation-works",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch04-neural-networks",
  "title": "How Backpropagation Works",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "The algorithm that lets neural networks learn from mistakes.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”„",
      "text": "The network predicted 'cat' but the image was a truck. How does it know which of its millions of weights to blame?"
    },
    "buildup": {
      "visual": "ğŸ“",
      "text": "Backpropagation computes how much each weight contributed to the error, working backward from output to input using the chain rule of calculus."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Each weight gets a gradient: 'if I increase this weight slightly, the error goes up by this much.' Then you nudge every weight in the direction that reduces error."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Backprop is efficient â€” it reuses intermediate calculations. Without it, computing gradients for millions of weights would be impossibly slow."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Repeat this forward pass â†’ compute error â†’ backward pass â†’ update weights cycle thousands of times, and the network converges on good weights."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Backprop: make a prediction, measure the mistake, trace the blame, adjust. Repeat until smart."
    }
  },
  "quiz": {
    "question": "What does backpropagation calculate?",
    "options": [
      "The optimal number of layers",
      "How much each weight contributed to the prediction error",
      "The ideal learning rate",
      "Which training examples to use"
    ],
    "correct": 1
  }
}
