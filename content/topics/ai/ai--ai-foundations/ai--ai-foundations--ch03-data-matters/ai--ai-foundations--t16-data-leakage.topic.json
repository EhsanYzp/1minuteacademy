{
  "id": "ai--ai-foundations--t16-data-leakage",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch03-data-matters",
  "title": "Data Leakage",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "The silent bug that makes your model look brilliant â€” until production.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ•µï¸",
      "text": "Your model hits 99.5% accuracy in testing and 70% in production. It's not degrading â€” it was never that good. Something leaked."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "Data leakage means information from the future or the test set accidentally bleeds into training. The model uses it as a shortcut."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Classic example: predicting hospital readmissions. The dataset included 'discharge summary' text â€” which only exists after the patient leaves. The model used future data."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Leakage is tricky to detect because the model performs great in testing. You only catch it when real-world performance tanks or when someone audits the features."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "For every feature, ask: 'Would I have this information at prediction time in production?' If no, drop it."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If your model seems too good to be true, it probably learned the answer key by accident."
    }
  },
  "quiz": {
    "question": "What is data leakage?",
    "options": [
      "When the dataset is too small",
      "When future or test information leaks into training",
      "When training takes too long",
      "When the model has too many parameters"
    ],
    "correct": 1
  }
}
