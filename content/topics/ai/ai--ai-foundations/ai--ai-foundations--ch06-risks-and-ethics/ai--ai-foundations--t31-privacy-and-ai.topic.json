{
  "id": "ai--ai-foundations--t31-privacy-and-ai",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch06-risks-and-ethics",
  "title": "Privacy and AI",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "What happens to your data when AI systems use it.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”",
      "text": "You upload a selfie to a fun aging app. Three months later, your face is in a facial recognition training set you never consented to."
    },
    "buildup": {
      "visual": "ğŸ“‹",
      "text": "AI models need data to train, and that data often includes personal information â€” faces, medical records, browsing history, conversations."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Even 'anonymized' data can be re-identified. Researchers deanonymized Netflix viewing records by cross-referencing with public IMDB reviews."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Models can memorize training data. Researchers have extracted verbatim personal information from large language models that was in their training corpus."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Read the terms of service. Prefer tools that don't train on your data. Support regulations that give you control over how your data is used."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If you're not paying for the AI product, your data is probably the product."
    }
  },
  "quiz": {
    "question": "Why is 'anonymized' data not always safe for AI training?",
    "options": [
      "Anonymization is illegal",
      "It can be re-identified by cross-referencing other data sources",
      "Anonymized data is always too small to be useful",
      "Models can't learn from anonymized data"
    ],
    "correct": 1
  }
}
