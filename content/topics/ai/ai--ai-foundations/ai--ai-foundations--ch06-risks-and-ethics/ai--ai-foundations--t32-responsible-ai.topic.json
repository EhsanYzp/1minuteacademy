{
  "id": "ai--ai-foundations--t32-responsible-ai",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch06-risks-and-ethics",
  "title": "Responsible AI",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "Building AI systems that are fair, transparent, and accountable.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "âš–ï¸",
      "text": "A loan-approval AI rejects applicants from certain zip codes at 3x the rate. Nobody intended discrimination â€” the model found a profitable shortcut."
    },
    "buildup": {
      "visual": "ğŸ›¡ï¸",
      "text": "Responsible AI means designing systems that are fair (don't discriminate), transparent (explain decisions), and accountable (someone is responsible when things go wrong)."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Google's Model Cards and Microsoft's Responsible AI Standard are frameworks that document a model's capabilities, limitations, and intended use â€” before deployment."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Responsible AI isn't just ethics â€” it's risk management. Biased models create lawsuits, regulatory fines, and brand damage. Fairness is also good business."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Build responsible AI by auditing data for bias, testing across demographic groups, documenting limitations, and keeping a human in the loop for high-stakes decisions."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If you can't explain why the model decided something, you're not ready to deploy it."
    }
  },
  "quiz": {
    "question": "What is a key component of responsible AI?",
    "options": [
      "Making models as large as possible",
      "Auditing for fairness and documenting limitations",
      "Removing humans from all decision loops",
      "Prioritizing speed over accuracy"
    ],
    "correct": 1
  }
}
