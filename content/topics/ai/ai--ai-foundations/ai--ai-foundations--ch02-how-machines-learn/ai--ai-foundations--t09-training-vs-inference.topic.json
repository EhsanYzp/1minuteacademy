{
  "id": "ai--ai-foundations--t09-training-vs-inference",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch02-how-machines-learn",
  "title": "Training vs Inference",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "Two phases of every ML system and why both matter.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ‹ï¸",
      "text": "Training a model is like studying for an exam. Inference is taking the exam. Very different effort, very different cost."
    },
    "buildup": {
      "visual": "ğŸ“š",
      "text": "During training, the model processes your dataset many times, adjusting its internal weights to reduce errors. This is computationally expensive and can take hours, days, or weeks."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Inference is when the trained model handles new inputs in real time â€” a user uploads a photo and gets a classification in milliseconds."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Training costs dominate upfront, but inference costs dominate at scale. A model serving a million users per day can outspend its training budget in weeks."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Optimizing training gets you a better model. Optimizing inference keeps your cloud bill sane. You need both."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Train once (expensive), serve forever (cheap per call â€” until you multiply by millions)."
    }
  },
  "quiz": {
    "question": "What happens during inference?",
    "options": [
      "The model learns from new data",
      "The model applies what it learned to new inputs",
      "The model's weights are updated",
      "The model retrains on live data"
    ],
    "correct": 1
  }
}
