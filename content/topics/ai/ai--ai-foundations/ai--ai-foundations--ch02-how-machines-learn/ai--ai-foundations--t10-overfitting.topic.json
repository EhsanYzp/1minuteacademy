{
  "id": "ai--ai-foundations--t10-overfitting",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Foundations",
  "course_id": "ai--ai-foundations",
  "chapter_id": "ai--ai-foundations--ch02-how-machines-learn",
  "title": "Overfitting",
  "emoji": "ğŸ“˜",
  "color": "#EF4444",
  "description": "When your model memorizes instead of learning.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“",
      "text": "Your model gets 99% accuracy on training data and 60% on new data. Something went very wrong."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "Overfitting means the model memorized the training examples â€” including the noise â€” instead of learning the underlying pattern."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Imagine memorizing every answer on a practice test instead of understanding the material. You ace the practice test and bomb the real one."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Bigger models overfit more easily because they have enough capacity to memorize. More data, regularization, or simpler architectures can help."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Always check performance on held-out data the model never trained on. That gap between train and test accuracy is your overfitting signal."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "A model that memorizes is impressive in the lab and useless in production."
    }
  },
  "quiz": {
    "question": "What is a sign of overfitting?",
    "options": [
      "Low accuracy on both training and test data",
      "High accuracy on training data, low on test data",
      "Equal accuracy on training and test data",
      "The model takes too long to train"
    ],
    "correct": 1
  }
}
