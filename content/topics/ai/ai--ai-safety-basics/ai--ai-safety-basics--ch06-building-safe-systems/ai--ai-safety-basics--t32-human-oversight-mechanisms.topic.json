{
  "id": "ai--ai-safety-basics--t32-human-oversight-mechanisms",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Safety Basics",
  "course_id": "ai--ai-safety-basics",
  "chapter_id": "ai--ai-safety-basics--ch06-building-safe-systems",
  "title": "Human Oversight Mechanisms",
  "emoji": "ğŸ›¡ï¸",
  "color": "#EF4444",
  "description": "Keeping humans in control of high-stakes AI decisions.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ‘ï¸",
      "text": "An AI approves a $50,000 loan in 200ms. A human would have noticed the applicant's address is a P.O. box, which violates the bank's fraud policy. No human saw it."
    },
    "buildup": {
      "visual": "ğŸ®",
      "text": "Human oversight means humans maintain meaningful control over AI decisions â€” especially high-stakes ones. The level of oversight should match the risk level."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Three models: Human-in-the-loop (human approves every decision), Human-on-the-loop (human monitors and can intervene), Human-in-command (human sets parameters, AI executes within bounds)."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Automation bias is real: when humans oversee AI, they tend to trust and rubber-stamp AI decisions. Design oversight to require active engagement, not just a confirmation click."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Match oversight to risk: auto-approve low-risk decisions, flag medium-risk for review, require explicit human approval for high-risk actions."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "AI decides fast. Humans decide wisely. The best systems combine both."
    }
  },
  "quiz": {
    "question": "What is automation bias in human oversight?",
    "options": [
      "Humans always override AI decisions",
      "Humans tend to trust and rubber-stamp AI decisions without critical review",
      "Automation makes humans more careful",
      "Humans refuse to use AI systems"
    ],
    "correct": 1
  }
}
