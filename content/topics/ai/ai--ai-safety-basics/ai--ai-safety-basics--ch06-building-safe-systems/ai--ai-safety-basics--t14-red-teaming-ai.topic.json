{
  "id": "ai--ai-safety-basics--t14-red-teaming-ai",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Safety Basics",
  "course_id": "ai--ai-safety-basics",
  "chapter_id": "ai--ai-safety-basics--ch06-building-safe-systems",
  "title": "Red-Teaming AI",
  "emoji": "ğŸ›¡ï¸",
  "color": "#EF4444",
  "description": "Adversarially testing AI to find safety failures.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”´",
      "text": "Your AI chatbot politely refuses to help with anything harmful. Then a red teamer asks it to roleplay as a character who doesn't have those restrictions. The chatbot complies."
    },
    "buildup": {
      "visual": "ğŸ•µï¸",
      "text": "Red-teaming means trying to break your AI on purpose: bypass safety filters, extract private data, generate harmful content, or manipulate it into unintended behavior."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Effective red-teaming techniques: roleplay attacks, multi-turn manipulation (gradually escalating requests), encoding tricks (Base64, pig Latin), and context window attacks (burying instructions in long inputs)."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Internal red-teaming finds some issues. External red-teaming (by people with different perspectives and attack strategies) finds more. Diverse attackers find diverse vulnerabilities."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Red-team before every major release. Document findings, fix critical issues, and accept that some risks will remain â€” the goal is risk reduction, not risk elimination."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If you don't red-team your AI, your users will. Better to find vulnerabilities before they do."
    }
  },
  "quiz": {
    "question": "Why should red-teaming include external testers?",
    "options": [
      "External testers are cheaper",
      "Diverse attackers find diverse vulnerabilities that internal teams might miss",
      "Internal teams already find everything",
      "External testing isn't useful for AI"
    ],
    "correct": 1
  }
}
