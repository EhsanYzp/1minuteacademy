{
  "id": "ai--ai-safety-basics--t04-training-data-bias",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Safety Basics",
  "course_id": "ai--ai-safety-basics",
  "chapter_id": "ai--ai-safety-basics--ch02-bias-and-fairness",
  "title": "Training Data Bias",
  "emoji": "ğŸ›¡ï¸",
  "color": "#EF4444",
  "description": "How biased data creates biased models.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“Š",
      "text": "A facial recognition system is 99% accurate on light-skinned faces and 65% accurate on dark-skinned faces. The model isn't racist â€” but the training data was overwhelmingly light-skinned."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "Training data reflects the world it was collected from â€” and that world has biases. If historical hiring data shows fewer women in engineering, the model learns that pattern."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Types of data bias: representation bias (some groups underrepresented), measurement bias (data collected differently for different groups), historical bias (past discrimination encoded as patterns)."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Simply removing protected attributes (gender, race) doesn't fix bias. The model infers them from proxies: zip code correlates with race, name correlates with gender. Debiasing is harder than it sounds."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Audit training data before training: check representation across groups, look for proxy variables, and test model performance on each subgroup separately."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "The model can only be as fair as the data it learns from. Fix the data first."
    }
  },
  "quiz": {
    "question": "Why doesn't removing protected attributes (gender, race) from data eliminate bias?",
    "options": [
      "It always eliminates bias completely",
      "The model can infer protected attributes from proxy variables like zip code or name",
      "Protected attributes aren't related to bias",
      "Models don't learn from data"
    ],
    "correct": 1
  }
}
