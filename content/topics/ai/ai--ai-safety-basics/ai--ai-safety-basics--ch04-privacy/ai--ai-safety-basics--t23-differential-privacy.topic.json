{
  "id": "ai--ai-safety-basics--t23-differential-privacy",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Safety Basics",
  "course_id": "ai--ai-safety-basics",
  "chapter_id": "ai--ai-safety-basics--ch04-privacy",
  "title": "Differential Privacy",
  "emoji": "ğŸ›¡ï¸",
  "color": "#EF4444",
  "description": "Mathematical guarantees that individual data can't be extracted from AI models.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”¢",
      "text": "A researcher extracts verbatim training data from GPT-2 â€” including phone numbers and email addresses. The data was supposed to be 'learned,' not memorized."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "Differential privacy adds mathematical noise to training so that no individual data point significantly affects the model. Formally: the model's output is nearly identical whether or not any single person's data was included."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "The privacy parameter Îµ (epsilon) controls the tradeoff: smaller Îµ = more privacy but less utility. Larger Îµ = better model but weaker privacy guarantees."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Differential privacy during training is expensive â€” it requires more data, more compute, and produces slightly less capable models. Most production LLMs don't use it, relying instead on data filtering."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "For applications with strict privacy requirements (healthcare, finance), differential privacy provides provable guarantees. For others, data sanitisation and access controls may suffice."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If you want mathematical certainty that your AI can't leak individual data, differential privacy is the only game in town."
    }
  },
  "quiz": {
    "question": "What does the privacy parameter Îµ (epsilon) control?",
    "options": [
      "The model's learning rate",
      "The tradeoff between privacy strength and model utility",
      "The number of training epochs",
      "The model's vocabulary size"
    ],
    "correct": 1
  }
}
