{
  "id": "ai--ai-safety-basics--t10-pii-and-ai",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Safety Basics",
  "course_id": "ai--ai-safety-basics",
  "chapter_id": "ai--ai-safety-basics--ch04-privacy",
  "title": "PII and AI",
  "emoji": "ğŸ›¡ï¸",
  "color": "#EF4444",
  "description": "How personal data leaks through AI systems.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”“",
      "text": "A user asks your AI: 'What's the email address for John Smith in accounting?' The model trained on company emails helpfully provides it. John never consented to his email being shared this way."
    },
    "buildup": {
      "visual": "ğŸ“‹",
      "text": "PII (Personally Identifiable Information) can leak through: model memorization (the model memorized training data), RAG retrieval (the knowledge base contains PII), and conversation history (shared between users)."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Prevent leaks at each layer: redact PII from training data, filter PII from RAG chunks before injection, and never share conversation history between different users."
    },
    "twist": {
      "visual": "âš¡",
      "text": "LLMs can infer PII even when it's removed. Given enough context ('the CEO who lives in Austin and drives a Tesla'), the model can identify a specific person. Redaction isn't always enough."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Apply the principle of least privilege to data: only include the data the AI actually needs. Don't feed it employee databases, customer lists, or internal communications unless necessary."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Every piece of data you feed the AI is data the AI might share. Minimize exposure."
    }
  },
  "quiz": {
    "question": "How can LLMs leak PII even when explicit PII is removed?",
    "options": [
      "They can't â€” redaction always works",
      "Models can infer identity from contextual details even without explicit identifiers",
      "PII leaks only happen with old models",
      "LLMs don't process personal data"
    ],
    "correct": 1
  }
}
