{
  "id": "ai--prompt-engineering--t11-chain-of-thought",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch03-advanced-techniques",
  "title": "Chain of Thought",
  "emoji": "‚úèÔ∏è",
  "color": "#EF4444",
  "description": "Make the model show its reasoning to get better answers.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "üîó",
      "text": "Ask: 'If a train leaves at 9am going 60mph and another at 10am going 90mph, when do they meet?' The model guesses wrong. Add 'think step by step' and it nails it."
    },
    "buildup": {
      "visual": "üß†",
      "text": "Chain-of-thought (CoT) prompting tells the model to write out its reasoning before giving the final answer. This intermediate text helps the model 'think' more carefully."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Google's 2022 paper showed CoT dramatically improved math and logic performance. The model isn't smarter ‚Äî it's just using its own output as scratch paper."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "CoT uses more tokens and costs more money. For simple tasks like classification, it's overkill. Save it for reasoning-heavy problems."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "When accuracy matters more than speed, ask for reasoning first, answer second. It's the single highest-impact technique for hard problems."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "Show your work ‚Äî the advice your teacher gave you works for AI too."
    }
  },
  "quiz": {
    "question": "How does chain-of-thought prompting improve results?",
    "options": [
      "By reducing the number of tokens used",
      "By making the model write reasoning steps before the final answer",
      "By fine-tuning the model on math problems",
      "By limiting the model's vocabulary"
    ],
    "correct": 1
  }
}
