{
  "id": "ai--prompt-engineering--t32-cost-optimization",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch07-prompt-ops",
  "title": "Cost Optimization",
  "emoji": "‚úèÔ∏è",
  "color": "#EF4444",
  "description": "Spend less on API calls without sacrificing quality.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "üìâ",
      "text": "Your monthly LLM bill jumped from $200 to $8,000 when your app went viral. Every token costs money. Optimization is no longer optional."
    },
    "buildup": {
      "visual": "üßÆ",
      "text": "The biggest cost levers: token count (shorter prompts), model choice (GPT-3.5 vs GPT-4), caching (avoid redundant calls), and batching (process multiple items per call)."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Route simple tasks (classification, yes/no) to cheaper models. Save expensive models for complex reasoning. A routing layer can cut costs by 50% with no quality loss on easy tasks."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Aggressive cost-cutting can degrade quality silently. Monitor output quality metrics alongside cost. Saving $5K that causes a 10% quality drop might not be worth it."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Measure cost per successful task, not cost per API call. A cheaper model that fails 30% of the time costs more than an expensive one that gets it right."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "Optimize for cost per correct answer. That's the metric that actually matters."
    }
  },
  "quiz": {
    "question": "What's the most effective way to reduce LLM costs at scale?",
    "options": [
      "Use the cheapest model for everything",
      "Route tasks to appropriately-sized models and cache repeated queries",
      "Reduce output quality across the board",
      "Only use free API tiers"
    ],
    "correct": 1
  }
}
