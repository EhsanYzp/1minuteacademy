{
  "id": "ai--prompt-engineering--t-guardrails-keeping-outputs-safe",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch06-advanced",
  "title": "Guardrails: Keeping Outputs Safe",
  "emoji": "âœï¸",
  "color": "#7C3AED",
  "description": "A short lesson to help you apply Guardrails: Keeping Outputs Safe.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "The model recommends a medication dosage. One wrong digit could hurt someone.",
      "visual": "ğŸ’Š"
    },
    "buildup": {
      "text": "Guardrails are rules that validate and filter model outputs before reaching users.",
      "visual": "ğŸš§"
    },
    "discovery": {
      "text": "Types: regex checks, classifier filters, schema validation, and human-in-the-loop.",
      "visual": "ğŸ›¡ï¸"
    },
    "twist": {
      "text": "Guardrails catch known failure modes. Unknown ones still slip throughâ€”plan for that.",
      "visual": "ğŸ•³ï¸"
    },
    "climax": {
      "text": "Layer defenses: prompt rules + output validation + monitoring + escalation path.",
      "visual": "ğŸ§…"
    },
    "punchline": {
      "text": "Trust the model to help. Trust guardrails to catch.",
      "visual": "ğŸ¤"
    }
  },
  "quiz": {
    "question": "What do output guardrails do?",
    "options": [
      "Validate and filter model outputs before users see them",
      "Speed up the model",
      "Replace the need for prompts"
    ],
    "correct": 0
  }
}
