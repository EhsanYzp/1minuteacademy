{
  "id": "ai--prompt-engineering--t19-max-tokens-and-stop-sequences",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch04-output-control",
  "title": "Max Tokens & Stop Sequences",
  "emoji": "‚úèÔ∏è",
  "color": "#EF4444",
  "description": "Tell the model when to stop talking.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "üõë",
      "text": "You want a one-sentence answer. The model writes four paragraphs. You wanted a haiku; it gave you an essay."
    },
    "buildup": {
      "visual": "‚öôÔ∏è",
      "text": "max_tokens caps the response length. Set it to 50 for short answers, 2000 for detailed ones. The model stops when it hits the limit, even mid-sentence."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Stop sequences are custom triggers: tell the model to stop when it generates 'END' or a newline. Useful for structured extraction where you know the exact terminator."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Setting max_tokens too low truncates useful answers. Setting it too high wastes money on padding. Match it to the expected output length with a small buffer."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Combine prompt instructions ('answer in one sentence') with max_tokens as a safety net. The prompt guides intent; max_tokens enforces the hard limit."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "Tell it how long to talk in the prompt. Set a hard stop in the API. Both."
    }
  },
  "quiz": {
    "question": "What does a stop sequence do?",
    "options": [
      "Stops the model from training",
      "Tells the model to stop generating when it produces a specific string",
      "Pauses the API for a set duration",
      "Prevents the model from using certain words"
    ],
    "correct": 1
  }
}
