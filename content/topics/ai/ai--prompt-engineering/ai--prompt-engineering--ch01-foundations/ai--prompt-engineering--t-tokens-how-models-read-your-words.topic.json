{
  "id": "ai--prompt-engineering--t-tokens-how-models-read-your-words",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch01-foundations",
  "title": "Tokens: How Models Read Your Words",
  "emoji": "âœï¸",
  "color": "#7C3AED",
  "description": "A micro-lesson that makes Tokens: How Models Read Your Words usable.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "text": "Your prompt fits on one screen, but the API says 'too many tokens.' What?",
      "visual": "ğŸ”¢"
    },
    "buildup": {
      "text": "Models don't read wordsâ€”they read tokens. One word can be 1â€“4 tokens.",
      "visual": "ğŸ§±"
    },
    "discovery": {
      "text": "English averages ~1.3 tokens per word. Code and non-Latin text use more.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "Your prompt AND the reply share the same token budget. Long prompts = short answers.",
      "visual": "ğŸ“"
    },
    "climax": {
      "text": "Use a tokenizer tool to count tokens before sending expensive API calls.",
      "visual": "ğŸ§®"
    },
    "punchline": {
      "text": "You pay per token. Count them.",
      "visual": "ğŸ’°"
    }
  },
  "quiz": {
    "question": "Why do long prompts sometimes produce short answers?",
    "options": [
      "Prompt and reply share the same token budget",
      "The model gets bored",
      "The API limits word count"
    ],
    "correct": 0
  }
}
