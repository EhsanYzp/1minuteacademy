{
  "id": "ai--prompt-engineering--t05-zero-shot-prompting",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch01-prompt-basics",
  "title": "Zero-Shot Prompting",
  "emoji": "‚úèÔ∏è",
  "color": "#EF4444",
  "description": "Getting answers without providing any examples.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ü™Ç",
      "text": "You ask: 'Classify this review as positive or negative: The food was cold and the waiter was rude.' The model nails it without a single example. How?"
    },
    "buildup": {
      "visual": "üß†",
      "text": "Zero-shot means asking the model to perform a task it was never explicitly shown during prompting. It relies on patterns absorbed during pre-training."
    },
    "discovery": {
      "visual": "üí°",
      "text": "For common tasks like sentiment analysis, summarization, or translation, zero-shot often works because the model has seen millions of similar examples in training."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Zero-shot fails on niche or ambiguous tasks. 'Classify this support ticket by urgency tier' breaks if the model doesn't know your tier definitions."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Start with zero-shot. If the results are close but inconsistent, add examples (few-shot). Don't jump to complexity before testing the simple path."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "Try it with no examples first. You'll be surprised how often that's enough."
    }
  },
  "quiz": {
    "question": "When does zero-shot prompting work best?",
    "options": [
      "On highly niche domain tasks",
      "On common tasks the model encountered during pre-training",
      "Only with very small models",
      "When the prompt contains many examples"
    ],
    "correct": 1
  }
}
