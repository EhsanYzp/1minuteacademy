{
  "id": "ai--prompt-engineering--t24-code-generation-prompts",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch05-real-world-patterns",
  "title": "Code Generation Prompts",
  "emoji": "âœï¸",
  "color": "#EF4444",
  "description": "Get the model to write code that actually runs.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ’»",
      "text": "You ask for 'a Python function to process CSV data' and get something that imports a library that doesn't exist. Code prompts need more structure."
    },
    "buildup": {
      "visual": "ğŸ“‹",
      "text": "Specify: language, runtime version, allowed libraries, input/output types, error handling expectations, and edge cases. 'Write a Python 3.11 function using only standard library that takes a list of dicts and returns CSV bytes.'"
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Including a function signature or docstring in the prompt constrains the output. The model completes what you start, which keeps it on track."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Generated code often looks correct but has subtle bugs â€” off-by-one errors, missing edge cases, deprecated API calls. Always run the code and test edge cases before trusting it."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Pair code generation with 'also write 3 unit tests for edge cases.' The model catches some of its own mistakes when forced to test."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Generated code is a first draft. Read it, run it, test it â€” then ship it."
    }
  },
  "quiz": {
    "question": "What's a key risk with AI-generated code?",
    "options": [
      "It always runs perfectly",
      "It may contain subtle bugs despite looking correct",
      "It can't use standard libraries",
      "It only works in Python"
    ],
    "correct": 1
  }
}
