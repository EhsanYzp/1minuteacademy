{
  "id": "ai--prompt-engineering--t27-iterating-on-prompts",
  "version": 1,
  "subject": "AI",
  "subcategory": "Prompt Engineering",
  "course_id": "ai--prompt-engineering",
  "chapter_id": "ai--prompt-engineering--ch06-debugging-prompts",
  "title": "Iterating on Prompts",
  "emoji": "âœï¸",
  "color": "#EF4444",
  "description": "The systematic way to improve prompts through testing.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”„",
      "text": "You tweak the prompt 15 times by feel and it gets worse. Prompt iteration without a system is just random walking."
    },
    "buildup": {
      "visual": "ğŸ“Š",
      "text": "Create a test set: 10â€“20 representative inputs with expected outputs. Run your prompt against all of them. Measure accuracy before and after each change."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Change one thing at a time. If you rewrite the role, format, and constraints simultaneously, you can't tell which change helped (or hurt)."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Sometimes the first version was nearly right and you're just missing a single constraint. Small, targeted edits beat full rewrites."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Keep a changelog of prompt versions with their scores. 'v3: added format example â†’ accuracy 72% â†’ 85%.' This history prevents you from repeating failed experiments."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Prompt engineering is experimental science. Hypothesis, test, measure, iterate."
    }
  },
  "quiz": {
    "question": "What's the best practice when iterating on prompts?",
    "options": [
      "Rewrite the entire prompt each time",
      "Change one thing at a time and measure the effect",
      "Use a different model for each iteration",
      "Trust your gut without testing"
    ],
    "correct": 1
  }
}
