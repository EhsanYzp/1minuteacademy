{
  "id": "ai--generative-ai--t-image-to-image-editing-with-ai",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Generative AI",
  "course_id": "ai--generative-ai",
  "chapter_id": "ai--generative-ai--ch03-image",
  "title": "Image-to-Image: Editing with AI",
  "emoji": "ğŸ¨",
  "color": "#DB2777",
  "description": "A quick, practical guide to Image-to-Image: Editing with AI.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "Upload a sketch. The model turns it into a photorealistic scene.",
      "visual": "ğŸ–Œï¸"
    },
    "buildup": {
      "text": "Image-to-image starts from a partially noised input image instead of pure noise.",
      "visual": "ğŸ”„"
    },
    "discovery": {
      "text": "The denoising strength controls how much the model changes: low = minor edits, high = full redraw.",
      "visual": "ğŸšï¸"
    },
    "twist": {
      "text": "Inpainting masks specific regions for editing while keeping the rest untouched.",
      "visual": "ğŸ­"
    },
    "climax": {
      "text": "ControlNet adds structural guidance: edges, poses, and depth maps constrain the output.",
      "visual": "ğŸ“"
    },
    "punchline": {
      "text": "Edit images with words and masks. No Photoshop needed.",
      "visual": "âœ¨"
    }
  },
  "quiz": {
    "question": "What does ControlNet provide?",
    "options": [
      "Structural guidance like edges and poses for image generation",
      "Text-only prompting",
      "Faster training"
    ],
    "correct": 0
  }
}
