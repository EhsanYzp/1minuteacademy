{
  "id": "ai--ai-product-design--t23-source-attribution",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Product Design",
  "course_id": "ai--ai-product-design",
  "chapter_id": "ai--ai-product-design--ch03-trust-and-transparency",
  "title": "Source Attribution",
  "emoji": "ğŸ¨",
  "color": "#EF4444",
  "description": "Showing users where the AI's information came from.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“",
      "text": "'According to your company's HR policy...' says the AI. The user clicks the citation â€” it links to the actual policy document, page 14. Trust skyrockets."
    },
    "buildup": {
      "visual": "ğŸ”—",
      "text": "Source attribution means showing which documents, data points, or knowledge the AI used to generate its response. It makes outputs verifiable."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "In RAG systems, display the retrieved chunks alongside the answer. Link to source documents. Highlight which parts of the response correspond to which source."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Attribution can be wrong â€” the AI might cite a document but actually hallucinate the specific claim. Verify that cited sources actually support the stated claims, don't just trust the link."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Good attribution: clickable source links, relevant quotes from source documents, and clear labelling when no source was found for a claim."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Show your work. Citations turn an AI claim into a verifiable statement."
    }
  },
  "quiz": {
    "question": "What is a risk of AI source attribution?",
    "options": [
      "Users might check the sources",
      "The AI might cite a source that doesn't actually support the claim",
      "Sources are always perfectly matched",
      "Attribution makes responses slower"
    ],
    "correct": 1
  }
}
