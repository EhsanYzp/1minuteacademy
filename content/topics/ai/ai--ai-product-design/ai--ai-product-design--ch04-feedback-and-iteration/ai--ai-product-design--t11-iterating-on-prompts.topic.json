{
  "id": "ai--ai-product-design--t11-iterating-on-prompts",
  "version": 1,
  "subject": "AI",
  "subcategory": "AI Product Design",
  "course_id": "ai--ai-product-design",
  "chapter_id": "ai--ai-product-design--ch04-feedback-and-iteration",
  "title": "Iterating on Prompts",
  "emoji": "ğŸ¨",
  "color": "#EF4444",
  "description": "Systematic prompt improvement based on user data.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”„",
      "text": "You've tweaked the system prompt 47 times based on individual complaints. Each fix breaks something else. You need a system, not a whack-a-mole approach."
    },
    "buildup": {
      "visual": "ğŸ“‹",
      "text": "Systematic iteration: (1) Collect failing queries, (2) Categorize failure types, (3) Fix the most common category, (4) Run full eval to check for regressions, (5) Deploy if improved overall."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Keep a prompt changelog: what you changed, why, and what the eval scores were before and after. This prevents circular changes where you revert improvements from last month."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Prompt changes have diminishing returns. After 5â€“10 iterations, you hit a ceiling. Further improvement usually requires better retrieval, better data, or a better model â€” not a better prompt."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Version your prompts like code. Test changes against a full eval set. Don't fix individual complaints â€” fix categories of failures."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Fix failure categories, not individual queries. And know when the prompt isn't the bottleneck anymore."
    }
  },
  "quiz": {
    "question": "What indicates you've hit the ceiling on prompt improvement?",
    "options": [
      "The first prompt change didn't work",
      "After 5-10 iterations, eval scores stop improving significantly",
      "Users stop giving feedback",
      "The model refuses to follow instructions"
    ],
    "correct": 1
  }
}
