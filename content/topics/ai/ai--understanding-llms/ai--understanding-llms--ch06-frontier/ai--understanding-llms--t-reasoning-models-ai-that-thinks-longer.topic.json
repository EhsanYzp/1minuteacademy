{
  "id": "ai--understanding-llms--t-reasoning-models-ai-that-thinks-longer",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Understanding Large Language Models",
  "course_id": "ai--understanding-llms",
  "chapter_id": "ai--understanding-llms--ch06-frontier",
  "title": "Reasoning Models: AI That Thinks Longer",
  "emoji": "ğŸ§ ",
  "color": "#7C3AED",
  "description": "A 1-minute de-risking session on Reasoning Models: AI That Thinks Longer.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "What if AI could pause and think for minutes before answering, like a human solving a hard problem?",
      "visual": "ğŸ¤”"
    },
    "buildup": {
      "text": "Reasoning models like o1 use extended chain-of-thought before producing a final answer.",
      "visual": "ğŸ”—"
    },
    "discovery": {
      "text": "They break complex problems into sub-problems and verify each step internally.",
      "visual": "âœ…"
    },
    "twist": {
      "text": "More thinking time costs more compute and money. Reasoning has a literal price.",
      "visual": "ğŸ’¸"
    },
    "climax": {
      "text": "On PhD-level science and math, reasoning models dramatically outperform standard LLMs.",
      "visual": "ğŸ“"
    },
    "punchline": {
      "text": "Sometimes the best answer just takes longer to find.",
      "visual": "â³"
    }
  },
  "quiz": {
    "question": "How do reasoning models like o1 improve accuracy?",
    "options": [
      "By using extended chain-of-thought to break down complex problems",
      "By accessing larger training datasets at inference time",
      "By running on faster hardware"
    ],
    "correct": 0
  }
}
