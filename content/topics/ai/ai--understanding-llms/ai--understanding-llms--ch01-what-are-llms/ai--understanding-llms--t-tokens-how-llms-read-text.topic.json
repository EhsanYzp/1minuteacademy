{
  "id": "ai--understanding-llms--t-tokens-how-llms-read-text",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Understanding Large Language Models",
  "course_id": "ai--understanding-llms",
  "chapter_id": "ai--understanding-llms--ch01-what-are-llms",
  "title": "Tokens: How LLMs Read Text",
  "emoji": "ğŸ§ ",
  "color": "#7C3AED",
  "description": "A tiny lesson with a big payoff: Tokens: How LLMs Read Text.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "LLMs don't read words. They read tokens â€” and 'unhappiness' is three tokens, not one.",
      "visual": "âœ‚ï¸"
    },
    "buildup": {
      "text": "A tokenizer splits text into subword pieces: 'un', 'happi', 'ness'.",
      "visual": "ğŸ§±"
    },
    "discovery": {
      "text": "Common words get one token. Rare words get split. Numbers and code tokenize unpredictably.",
      "visual": "ğŸ”¤"
    },
    "twist": {
      "text": "The word 'the' is one token but 'cryptocurrency' might be three. Token count â‰  word count.",
      "visual": "ğŸ“"
    },
    "climax": {
      "text": "Token limits define how much context an LLM can process at once â€” its working memory.",
      "visual": "ğŸ§ "
    },
    "punchline": {
      "text": "To an LLM, you're not words. You're token soup.",
      "visual": "ğŸœ"
    }
  },
  "quiz": {
    "question": "Why does 'unhappiness' become multiple tokens?",
    "options": [
      "Tokenizers split text into subword pieces for efficiency",
      "The model can only read one letter at a time",
      "Long words are always removed"
    ],
    "correct": 0
  }
}
