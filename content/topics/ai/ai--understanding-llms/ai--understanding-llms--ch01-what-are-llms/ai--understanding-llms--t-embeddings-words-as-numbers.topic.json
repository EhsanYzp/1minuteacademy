{
  "id": "ai--understanding-llms--t-embeddings-words-as-numbers",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Understanding Large Language Models",
  "course_id": "ai--understanding-llms",
  "chapter_id": "ai--understanding-llms--ch01-what-are-llms",
  "title": "Embeddings: Words as Numbers",
  "emoji": "ğŸ§ ",
  "color": "#7C3AED",
  "description": "A 60-second lesson on Embeddings: Words as Numbers.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "To an LLM, the word 'king' is a list of 4,096 numbers. And 'queen' is nearby in that space.",
      "visual": "ğŸ‘‘"
    },
    "buildup": {
      "text": "Embeddings convert tokens into high-dimensional vectors that capture meaning.",
      "visual": "ğŸ“"
    },
    "discovery": {
      "text": "Similar words cluster together. 'Happy' and 'joyful' are close; 'happy' and 'wrench' are far.",
      "visual": "ğŸ—ºï¸"
    },
    "twist": {
      "text": "King - Man + Woman â‰ˆ Queen. The math of embeddings captures analogies.",
      "visual": "ğŸ§®"
    },
    "climax": {
      "text": "Every sentence becomes a cloud of points in a space with thousands of dimensions.",
      "visual": "â˜ï¸"
    },
    "punchline": {
      "text": "Meaning is geometry in disguise.",
      "visual": "ğŸ“Š"
    }
  },
  "quiz": {
    "question": "What do word embeddings capture?",
    "options": [
      "Semantic relationships as positions in high-dimensional space",
      "The exact dictionary definition of each word",
      "The number of letters in each word"
    ],
    "correct": 0
  }
}
