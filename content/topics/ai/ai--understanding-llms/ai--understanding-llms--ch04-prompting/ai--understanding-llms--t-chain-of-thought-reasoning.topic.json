{
  "id": "ai--understanding-llms--t-chain-of-thought-reasoning",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Understanding Large Language Models",
  "course_id": "ai--understanding-llms",
  "chapter_id": "ai--understanding-llms--ch04-prompting",
  "title": "Chain-of-Thought Reasoning",
  "emoji": "ğŸ§ ",
  "color": "#7C3AED",
  "description": "A short lesson to help you apply Chain-of-Thought Reasoning.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "Ask an LLM a math problem directly: wrong. Ask it to show its work: correct. Why?",
      "visual": "ğŸ§®"
    },
    "buildup": {
      "text": "Chain-of-thought prompting asks the model to reason through intermediate steps.",
      "visual": "ğŸªœ"
    },
    "discovery": {
      "text": "By generating step-by-step reasoning, the model avoids shortcuts that lead to errors.",
      "visual": "âœ…"
    },
    "twist": {
      "text": "The model isn't actually 'thinking.' It generates tokens that look like reasoning, and they help.",
      "visual": "ğŸ¤”"
    },
    "climax": {
      "text": "This technique improves accuracy on math, logic, and multi-step problems dramatically.",
      "visual": "ğŸ“ˆ"
    },
    "punchline": {
      "text": "Even AI works better when it shows its work.",
      "visual": "ğŸ“"
    }
  },
  "quiz": {
    "question": "Why does chain-of-thought prompting improve accuracy?",
    "options": [
      "Step-by-step reasoning helps the model avoid shortcuts",
      "It makes the model run faster",
      "It accesses a different part of the model"
    ],
    "correct": 0
  }
}
