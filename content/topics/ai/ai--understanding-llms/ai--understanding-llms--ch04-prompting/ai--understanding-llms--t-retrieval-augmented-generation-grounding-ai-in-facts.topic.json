{
  "id": "ai--understanding-llms--t-retrieval-augmented-generation-grounding-ai-in-facts",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Understanding Large Language Models",
  "course_id": "ai--understanding-llms",
  "chapter_id": "ai--understanding-llms--ch04-prompting",
  "title": "Retrieval-Augmented Generation: Grounding AI in Facts",
  "emoji": "ğŸ§ ",
  "color": "#7C3AED",
  "description": "Learn Retrieval-Augmented Generation: Grounding AI in Facts in one minute.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "What if the AI could look up facts before answering instead of relying on memory? That's RAG.",
      "visual": "ğŸ“š"
    },
    "buildup": {
      "text": "RAG retrieves relevant documents from a database and feeds them to the LLM as context.",
      "visual": "ğŸ”"
    },
    "discovery": {
      "text": "This grounds responses in actual sources, dramatically reducing hallucinations on factual questions.",
      "visual": "ğŸ“Œ"
    },
    "twist": {
      "text": "The retrieval step can fail â€” pulling irrelevant documents leads to confidently wrong answers anyway.",
      "visual": "âŒ"
    },
    "climax": {
      "text": "RAG has become the standard architecture for enterprise AI chatbots that need reliable information.",
      "visual": "ğŸ¢"
    },
    "punchline": {
      "text": "Don't trust your memory. Look it up. Good advice for humans and AI.",
      "visual": "ğŸ§ "
    }
  },
  "quiz": {
    "question": "How does RAG reduce AI hallucinations?",
    "options": [
      "It retrieves relevant documents to ground answers in actual sources",
      "It prevents the model from generating any text",
      "It makes the model smaller and faster"
    ],
    "correct": 0
  }
}
