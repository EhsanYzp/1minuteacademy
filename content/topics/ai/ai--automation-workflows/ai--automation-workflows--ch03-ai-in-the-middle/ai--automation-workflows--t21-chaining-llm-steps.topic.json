{
  "id": "ai--automation-workflows--t21-chaining-llm-steps",
  "version": 1,
  "subject": "AI",
  "subcategory": "Automation Workflows",
  "course_id": "ai--automation-workflows",
  "chapter_id": "ai--automation-workflows--ch03-ai-in-the-middle",
  "title": "Chaining LLM Steps",
  "emoji": "âš™ï¸",
  "color": "#EF4444",
  "description": "Passing output from one AI step as input to the next.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”—",
      "text": "Step 1: Extract key points from a document. Step 2: Translate the key points to Spanish. Step 3: Generate a summary tweet. Each step's output feeds the next step's input."
    },
    "buildup": {
      "visual": "â›“ï¸",
      "text": "LLM chaining: connecting multiple AI calls where each call's output becomes the next call's input. The chain transforms data step by step, with each step focused on one task."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Chaining benefits: each step has a focused prompt (better accuracy), intermediate outputs can be validated, and individual steps can be swapped or upgraded independently."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Chains amplify errors: if step 1 makes a mistake, step 2 works with wrong input, and step 3 compounds it. Always validate intermediate outputs, especially after extraction or classification steps."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Chain design: keep steps independent (each step should work with clean input), validate between steps, and log intermediate outputs for debugging."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "One AI call for one task. Chain them for complex tasks. Validate between each link."
    }
  },
  "quiz": {
    "question": "What is the main risk of chaining multiple LLM steps?",
    "options": [
      "Chains are always slower than single calls",
      "Errors compound â€” a mistake in an early step affects all subsequent steps",
      "LLMs can't produce output that other LLMs can read",
      "Chaining is not technically possible"
    ],
    "correct": 1
  }
}
