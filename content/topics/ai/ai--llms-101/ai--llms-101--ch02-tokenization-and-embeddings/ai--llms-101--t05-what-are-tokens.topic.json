{
  "id": "ai--llms-101--t05-what-are-tokens",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch02-tokenization-and-embeddings",
  "title": "What Are Tokens?",
  "emoji": "üß†",
  "color": "#EF4444",
  "description": "The atomic units that LLMs actually read and write.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "visual": "üß±",
      "text": "You write 'unhappiness' as one word. The model sees it as three pieces: 'un', 'happiness', and maybe a variant. Models don't read words ‚Äî they read tokens."
    },
    "buildup": {
      "visual": "‚úÇÔ∏è",
      "text": "Tokenization breaks text into sub-word chunks. Common words like 'the' are single tokens. Rare words get split into pieces. 'Tokenization' might become 'token' + 'ization.'"
    },
    "discovery": {
      "visual": "üí°",
      "text": "English averages about 1.3 tokens per word. Code is more expensive ‚Äî a single Python function might use 50 tokens for 20 'words.' Token count determines cost and context usage."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Tokenizers are language-biased. English gets efficient single tokens. Languages like Japanese or Arabic often use 2‚Äì3x more tokens for the same meaning, making them more expensive."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "Always check your token count before sending long prompts. Tools like tiktoken (OpenAI) let you count tokens programmatically."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "The model sees tokens, not words. If you don't think in tokens, you'll be surprised by the bill."
    }
  },
  "quiz": {
    "question": "Why does tokenization matter for LLM users?",
    "options": [
      "It only matters for model developers",
      "It determines cost, context window usage, and how the model processes text",
      "It has no practical impact",
      "It only affects image models"
    ],
    "correct": 1
  }
}
