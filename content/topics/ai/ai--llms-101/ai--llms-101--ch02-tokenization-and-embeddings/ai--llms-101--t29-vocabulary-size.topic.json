{
  "id": "ai--llms-101--t29-vocabulary-size",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch02-tokenization-and-embeddings",
  "title": "Vocabulary Size",
  "emoji": "üß†",
  "color": "#EF4444",
  "description": "Why the size of a model's vocabulary matters for performance and efficiency.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "üìö",
      "text": "GPT-4 has a vocabulary of ~100,000 tokens. Some models use 32,000. Why does it matter, and who picks the number?"
    },
    "buildup": {
      "visual": "‚öñÔ∏è",
      "text": "A larger vocabulary means common words and phrases get single tokens, so less computation per sentence. A smaller vocabulary means less memory and simpler training, but more tokens per sentence."
    },
    "discovery": {
      "visual": "üí°",
      "text": "Vocabulary is built before training using algorithms like BPE (Byte Pair Encoding). The algorithm merges the most frequent character pairs until it reaches the target vocab size."
    },
    "twist": {
      "visual": "‚ö°",
      "text": "Vocabulary size affects multilingual performance dramatically. English-centric vocabularies split Chinese or Arabic words into many tokens, making the model slower and less effective for those languages."
    },
    "climax": {
      "visual": "üèÅ",
      "text": "The right vocabulary is a tradeoff: large enough to be efficient for your target languages, small enough to keep the embedding matrix manageable."
    },
    "punchline": {
      "visual": "üé¨",
      "text": "A model's vocabulary is its alphabet. Pick the wrong one and it stutters in half the world's languages."
    }
  },
  "quiz": {
    "question": "What is a key tradeoff when increasing a model's vocabulary size?",
    "options": [
      "Larger vocab increases speed but decreases accuracy",
      "Larger vocab reduces tokens per sentence but increases memory usage",
      "Larger vocab makes training faster",
      "Vocabulary size has no impact on multilingual performance"
    ],
    "correct": 1
  }
}
