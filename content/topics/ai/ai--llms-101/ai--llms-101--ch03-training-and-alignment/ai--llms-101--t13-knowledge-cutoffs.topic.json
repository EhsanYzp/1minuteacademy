{
  "id": "ai--llms-101--t13-knowledge-cutoffs",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch03-training-and-alignment",
  "title": "Knowledge Cutoffs",
  "emoji": "ğŸ§ ",
  "color": "#EF4444",
  "description": "Why LLMs don't know what happened yesterday.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ“…",
      "text": "You ask the model who won yesterday's election and it says 'I don't have information after October 2023.' It's not being coy â€” it literally can't know."
    },
    "buildup": {
      "visual": "ğŸ§Š",
      "text": "Every LLM has a knowledge cutoff: the date when its training data ends. Anything after that date doesn't exist in the model's weights."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "The model might still generate text about post-cutoff events â€” but it's hallucinating. It's pattern-matching from pre-cutoff data, not reporting facts."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Some products (ChatGPT with browsing, Perplexity) work around this by fetching live data and injecting it into the prompt. The model itself doesn't know â€” it's reading fresh context you gave it."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Always check the model's knowledge cutoff for time-sensitive questions. Use retrieval-augmented generation (RAG) to supply current information when needed."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "The model's world froze on its training date. Everything after that is someone else's job to provide."
    }
  },
  "quiz": {
    "question": "What is a knowledge cutoff?",
    "options": [
      "A limit on how many tokens the model can process",
      "The date after which the model has no training data",
      "A safety filter that blocks certain topics",
      "The maximum number of questions you can ask"
    ],
    "correct": 1
  }
}
