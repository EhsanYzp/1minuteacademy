{
  "id": "ai--llms-101--t10-fine-tuning",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch03-training-and-alignment",
  "title": "Fine-Tuning",
  "emoji": "ğŸ§ ",
  "color": "#EF4444",
  "description": "Specializing a general model for your specific task.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ¯",
      "text": "The base model knows everything about language but nothing about your company's support policies. Fine-tuning bridges that gap."
    },
    "buildup": {
      "visual": "ğŸ”§",
      "text": "Fine-tuning continues training on a smaller, task-specific dataset. Show the model hundreds or thousands of examples of your task, and it adapts its weights to perform better on that domain."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "A hospital fine-tuned a model on radiology reports and got 40% better accuracy than the general model. Domain-specific data matters â€” a lot."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Fine-tuning can cause 'catastrophic forgetting' â€” the model gets great at your task but loses general capabilities. It's a tradeoff, not a free upgrade."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Fine-tune when prompting alone doesn't work and you have enough quality training examples (typically hundreds to thousands). It's a scalpel, not a sledgehammer."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Fine-tuning makes a generalist into a specialist. But specialists forget what they stopped practicing."
    }
  },
  "quiz": {
    "question": "When should you consider fine-tuning an LLM?",
    "options": [
      "Before trying prompt engineering",
      "When prompting alone doesn't achieve the needed quality and you have domain-specific data",
      "For every new use case",
      "Only when the model is too small"
    ],
    "correct": 1
  }
}
