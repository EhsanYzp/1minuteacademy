{
  "id": "ai--llms-101--t27-the-pace-of-change",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch06-limits-and-gotchas",
  "title": "The Pace of Change",
  "emoji": "ğŸ§ ",
  "color": "#EF4444",
  "description": "How to build when the ground shifts every six months.",
  "difficulty": "Premium",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸŒªï¸",
      "text": "You ship an app on GPT-4. Three months later, GPT-4o is out â€” cheaper, faster, multimodal. Six months later, a new leader emerges. How do you build for this?"
    },
    "buildup": {
      "visual": "ğŸ—ï¸",
      "text": "The LLM landscape changes faster than any previous technology stack. New models, new capabilities, new pricing, new APIs â€” every quarter."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Abstract the model behind an interface. Your app calls a 'completion service' that wraps the API. Swapping GPT-4 for Claude is a config change, not a rewrite."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Teams that hard-code to a specific model and its quirks end up rewriting when the model changes. Model-agnostic architecture isn't premature â€” it's survival."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Build portable: model abstraction layer, standardized prompt templates, model-agnostic eval sets, and provider-neutral logging. The model is a replaceable component."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "The only constant in LLMs is change. Build for swap-ability, not permanence."
    }
  },
  "quiz": {
    "question": "Why should LLM applications abstract the model behind an interface?",
    "options": [
      "To make the code more complex",
      "To enable easy model swapping as the landscape changes rapidly",
      "To hide the model from users",
      "To reduce the context window"
    ],
    "correct": 1
  }
}
