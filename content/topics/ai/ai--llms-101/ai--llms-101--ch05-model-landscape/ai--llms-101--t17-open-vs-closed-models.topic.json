{
  "id": "ai--llms-101--t17-open-vs-closed-models",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch05-model-landscape",
  "title": "Open vs Closed Models",
  "emoji": "ğŸ§ ",
  "color": "#EF4444",
  "description": "Tradeoffs between open-source and proprietary LLMs.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ”“",
      "text": "Llama 3 is free to download. GPT-4 costs per token and lives on OpenAI's servers. Which is actually cheaper? It depends."
    },
    "buildup": {
      "visual": "ğŸ“Š",
      "text": "Closed models (GPT-4, Claude) are accessed via API â€” no hosting, no infrastructure, pay per call. Open models (Llama, Mistral) are free to download but you pay for GPU hosting."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "At low volume, APIs are cheaper â€” no infrastructure to manage. At high volume, self-hosted open models can be 5â€“10x cheaper per token once you amortize GPU costs."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Open models give you full control: fine-tune, modify, run offline, keep data private. But you own the ops: scaling, monitoring, updates. That's a real engineering burden."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Start with APIs for speed and flexibility. Evaluate self-hosting when volume justifies the infrastructure investment or data privacy requires it."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Open isn't free (you pay in ops). Closed isn't locked (you pay in tokens). Choose your tradeoff."
    }
  },
  "quiz": {
    "question": "When do open-source models become more cost-effective than API-based ones?",
    "options": [
      "Always",
      "At high enough volume to justify self-hosting infrastructure",
      "Never â€” APIs are always cheaper",
      "Only when the model is smaller than 1B parameters"
    ],
    "correct": 1
  }
}
