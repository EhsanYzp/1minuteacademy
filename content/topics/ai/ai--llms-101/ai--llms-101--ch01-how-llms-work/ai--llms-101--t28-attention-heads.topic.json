{
  "id": "ai--llms-101--t28-attention-heads",
  "version": 1,
  "subject": "AI",
  "subcategory": "LLMs 101",
  "course_id": "ai--llms-101",
  "chapter_id": "ai--llms-101--ch01-how-llms-work",
  "title": "Attention Heads",
  "emoji": "ğŸ§ ",
  "color": "#EF4444",
  "description": "How multi-head attention lets models focus on many patterns simultaneously.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "visual": "ğŸ‘€",
      "text": "When you read 'The bank was steep,' how do you know it's a riverbank, not a financial bank? Your brain uses context clues â€” and so does an LLM, through attention heads."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "A transformer doesn't use one attention mechanism â€” it uses dozens running in parallel. Each 'head' learns to focus on different relationships: one tracks grammar, another coreference, another semantic similarity."
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Multi-head attention means the model can simultaneously attend to the subject of a sentence, its tone, its topic, and its grammatical structure. Each head specialises organically during training."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Researchers found that some heads are so specialised you can name them: 'induction heads' copy patterns, 'previous-token heads' look one step back. Not all heads are equally useful â€” some can be pruned with little quality loss."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Attention heads are why transformers can handle complex, long-range dependencies. They're the reason 'it' on page 5 can correctly refer to 'quantum entanglement' on page 1."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "Many eyes see more than one. Attention heads let the model look at everything at once, from every angle."
    }
  },
  "quiz": {
    "question": "What is the purpose of multi-head attention in transformers?",
    "options": [
      "To process tokens one at a time",
      "To let multiple attention mechanisms focus on different relationships simultaneously",
      "To reduce the model's parameter count",
      "To speed up tokenization"
    ],
    "correct": 1
  }
}
