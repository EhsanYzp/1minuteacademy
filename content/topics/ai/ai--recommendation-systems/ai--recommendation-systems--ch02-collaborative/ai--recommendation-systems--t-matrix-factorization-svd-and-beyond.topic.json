{
  "id": "ai--recommendation-systems--t-matrix-factorization-svd-and-beyond",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Recommendation Systems",
  "course_id": "ai--recommendation-systems",
  "chapter_id": "ai--recommendation-systems--ch02-collaborative",
  "title": "Matrix Factorization: SVD and Beyond",
  "emoji": "ğŸ¯",
  "color": "#7C3AED",
  "description": "A micro-lesson that makes Matrix Factorization: SVD and Beyond usable.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "The Netflix Prize was won by decomposing a giant matrix into two smaller ones. Elegant.",
      "visual": "ğŸ†"
    },
    "buildup": {
      "text": "Matrix factorization decomposes the user-item matrix into user factors and item factors.",
      "visual": "ğŸ§®"
    },
    "discovery": {
      "text": "Each user and item gets a latent vector. Their dot product predicts the rating.",
      "visual": "ğŸ“"
    },
    "twist": {
      "text": "These latent factors capture hidden concepts: genre preferences, complexity, moodâ€”without labeling.",
      "visual": "ğŸ”®"
    },
    "climax": {
      "text": "SVD, ALS, and NMF are variants. ALS scales well with parallelism for big data.",
      "visual": "ğŸ“ˆ"
    },
    "punchline": {
      "text": "Compress the matrix. Discover hidden tastes.",
      "visual": "ğŸ’"
    }
  },
  "quiz": {
    "question": "What do latent factors in matrix factorization represent?",
    "options": [
      "Hidden concepts like genre or mood preferences",
      "Explicit user ratings",
      "Item prices"
    ],
    "correct": 0
  }
}
