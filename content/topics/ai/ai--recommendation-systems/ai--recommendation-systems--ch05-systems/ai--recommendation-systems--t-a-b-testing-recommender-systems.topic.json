{
  "id": "ai--recommendation-systems--t-a-b-testing-recommender-systems",
  "version": 1,
  "subject": "AI & Agents",
  "subcategory": "Recommendation Systems",
  "course_id": "ai--recommendation-systems",
  "chapter_id": "ai--recommendation-systems--ch05-systems",
  "title": "A/B Testing Recommender Systems",
  "emoji": "ğŸ¯",
  "color": "#7C3AED",
  "description": "Learn A/B Testing Recommender Systems in one minute.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "text": "The new algorithm improves click rate by 5%. But users watch shorter videos. Is that better?",
      "visual": "ğŸ“Š"
    },
    "buildup": {
      "text": "A/B tests compare recommendation algorithms by splitting users into control and treatment groups.",
      "visual": "ğŸ”€"
    },
    "discovery": {
      "text": "Track multiple metrics: clicks, dwell time, diversity, returns, and long-term retention.",
      "visual": "ğŸ“‹"
    },
    "twist": {
      "text": "Short-term engagement gains can hurt long-term retention. Measure both time horizons.",
      "visual": "ğŸ“…"
    },
    "climax": {
      "text": "Run tests for at least 2 weeks to account for day-of-week effects and novelty bias.",
      "visual": "ğŸ“†"
    },
    "punchline": {
      "text": "One metric lies. Multiple metrics tell the truth.",
      "visual": "ğŸ“"
    }
  },
  "quiz": {
    "question": "Why should you track multiple metrics in recommendation A/B tests?",
    "options": [
      "Improving one metric can hurt another important metric",
      "One metric is always sufficient",
      "Multiple metrics are confusing"
    ],
    "correct": 0
  }
}
