{
  "id": "ai--evaluation-and-testing--t06-faithfulness-and-groundedness",
  "version": 1,
  "subject": "AI",
  "subcategory": "Evaluation & Testing",
  "course_id": "ai--evaluation-and-testing",
  "chapter_id": "ai--evaluation-and-testing--ch02-metrics",
  "title": "Faithfulness & Groundedness",
  "emoji": "ğŸ§ª",
  "color": "#EF4444",
  "description": "Measuring whether the model sticks to provided context.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "visual": "âš“",
      "text": "Your RAG system retrieves a chunk saying 'Plan A costs $29/month.' The model's answer says '$29/month for Plan A and $49/month for Plan B.' Where did Plan B come from? The model hallucinated it."
    },
    "buildup": {
      "visual": "ğŸ”",
      "text": "Faithfulness measures whether every claim in the answer is supported by the provided context. Groundedness asks: can each statement be traced back to a source?"
    },
    "discovery": {
      "visual": "ğŸ’¡",
      "text": "Evaluation approach: break the answer into individual claims, then check each claim against the context. Claim: '$29/month for Plan A' â†’ supported. Claim: '$49/month for Plan B' â†’ not supported."
    },
    "twist": {
      "visual": "âš¡",
      "text": "Models are most unfaithful when the context is incomplete â€” they fill gaps with plausible-sounding information from training data. The most dangerous hallucinations are the ones that sound right."
    },
    "climax": {
      "visual": "ğŸ",
      "text": "Measure faithfulness on every RAG evaluation. It's the most important metric for factual accuracy in grounded generation systems."
    },
    "punchline": {
      "visual": "ğŸ¬",
      "text": "If the model says something the context doesn't, that's a hallucination. Faithfulness catches it."
    }
  },
  "quiz": {
    "question": "What does faithfulness measure in a RAG system?",
    "options": [
      "How fast the model generates",
      "Whether every claim in the answer is supported by the provided context",
      "How many chunks were retrieved",
      "Whether the user is satisfied"
    ],
    "correct": 1
  }
}
