{
  "id": "cybersecurity--cybersecurity-law-and-ethics--t-autonomous-weapons-the-ethics-of-lethal-ai",
  "version": 1,
  "subject": "Cybersecurity",
  "subcategory": "Cybersecurity Law & Ethics",
  "course_id": "cybersecurity--cybersecurity-law-and-ethics",
  "chapter_id": "cybersecurity--cybersecurity-law-and-ethics--ch06-the-future-of-cyber-governance",
  "title": "Autonomous Weapons: The Ethics of Lethal AI",
  "emoji": "‚öñÔ∏è",
  "color": "#1ABC9C",
  "description": "A 1-minute de-risking session on Autonomous Weapons: The Ethics of Lethal AI.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "A drone identifies, targets, and kills a human being without person making the decision. This technology already exists.",
      "visual": "üéØ"
    },
    "buildup": {
      "text": "Lethal autonomous weapons systems (LAWS) can select and engage targets without human intervention. Dozens of.",
      "visual": "ü§ñ"
    },
    "discovery": {
      "text": "The UN has debated autonomous weapons since 2014. Over 30 countries call for a ban. Major powers resist restrictions.",
      "visual": "üí°"
    },
    "twist": {
      "text": "In 2021, a UN report suggested a Turkish drone autonomously attacked soldiers in Libya without orders ‚Äì potentially.",
      "visual": "üì∞"
    },
    "climax": {
      "text": "If machines decide who lives and dies, who is accountable? The programmer? The commander? The algorithm?",
      "visual": "‚öñÔ∏è"
    },
    "punchline": {
      "text": "The machine decided to kill. Nobody gave the order.",
      "visual": "‚ùì"
    }
  },
  "quiz": {
    "question": "What is the core ethical problem with autonomous weapons?",
    "options": [
      "They're too expensive for most countries",
      "No human makes the kill decision, creating an accountability gap",
      "They're not accurate enough"
    ],
    "correct": 1
  }
}
