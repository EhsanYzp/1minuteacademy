{
  "id": "cybersecurity--cybersecurity-law-and-ethics--t-ai-governance-regulating-intelligent-machines",
  "version": 1,
  "subject": "Cybersecurity",
  "subcategory": "Cybersecurity Law & Ethics",
  "course_id": "cybersecurity--cybersecurity-law-and-ethics",
  "chapter_id": "cybersecurity--cybersecurity-law-and-ethics--ch06-the-future-of-cyber-governance",
  "title": "AI Governance: Regulating Intelligent Machines",
  "emoji": "âš–ï¸",
  "color": "#1ABC9C",
  "description": "A 1-minute de-risking session on AI Governance: Regulating Intelligent Machines.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "text": "An AI denies your loan application. You ask why. Nobody can explain it â€” not even the engineers who built it.",
      "visual": "ğŸ¤–"
    },
    "buildup": {
      "text": "The EU AI Act classifies AI systems by risk level: unacceptable (banned), high-risk (regulated), and minimal.",
      "visual": "ğŸ“Š"
    },
    "discovery": {
      "text": "High-risk AI in hiring, lending, and law enforcement must be transparent, auditable, and explainable under the EU.",
      "visual": "ğŸ’¡"
    },
    "twist": {
      "text": "Amazon scrapped an AI hiring tool that discriminated against women. It learned bias from 10 years of.",
      "visual": "ğŸ“‰"
    },
    "climax": {
      "text": "AI governance must balance innovation with accountability. Unregulated AI can scale bias, discrimination, and errors.",
      "visual": "âš–ï¸"
    },
    "punchline": {
      "text": "The AI learned from the past. The past was biased.",
      "visual": "ğŸ”„"
    }
  },
  "quiz": {
    "question": "Why did Amazon scrap its AI hiring tool?",
    "options": [
      "It was too slow to process applications",
      "It discriminated against women because it learned from biased historical hiring data",
      "It was too expensive to maintain"
    ],
    "correct": 1
  }
}
