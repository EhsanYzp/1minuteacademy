{
  "id": "philosophy--philosophy-of-mind--t-the-chinese-room",
  "version": 1,
  "subject": "Philosophy",
  "subcategory": "Philosophy of Mind",
  "course_id": "philosophy--philosophy-of-mind",
  "chapter_id": "philosophy--philosophy-of-mind--ch05-ai-minds",
  "title": "The Chinese Room",
  "emoji": "ğŸ§ ",
  "color": "#7E22CE",
  "description": "A fast breakdown of The Chinese Room for builders.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "John Searle imagined a man in a room following rules to produce Chinese characters. Does he understand Chinese?",
      "visual": "ğŸ€„"
    },
    "buildup": {
      "text": "The man receives Chinese input, follows an English rulebook, and outputs perfect Chinese responses.",
      "visual": "ğŸ“–"
    },
    "discovery": {
      "text": "To the outside world, the room speaks Chinese. But the man inside understands nothing. He's just following rules.",
      "visual": "ğŸ¤·"
    },
    "twist": {
      "text": "Searle's point: computers follow rules like the man. Processing symbols isn't the same as understanding them.",
      "visual": "ğŸ’»"
    },
    "climax": {
      "text": "AI critics love this argument. AI supporters say the room as a whole understands, even if the man doesn't.",
      "visual": "ğŸ”„"
    },
    "punchline": {
      "text": "Following the rules isn't the same as getting it.",
      "visual": "ğŸ“"
    }
  },
  "quiz": {
    "question": "What does the Chinese Room argument claim?",
    "options": [
      "Manipulating symbols doesn't equal understanding",
      "Computers truly understand language",
      "Chinese is harder than English"
    ],
    "correct": 0
  }
}
