{
  "id": "philosophy--ethics-and-morality--t-the-ethics-of-ai",
  "version": 1,
  "subject": "Philosophy",
  "subcategory": "Ethics & Morality",
  "course_id": "philosophy--ethics-and-morality",
  "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
  "title": "The Ethics of AI",
  "emoji": "‚öñÔ∏è",
  "color": "#7E22CE",
  "description": "One-minute skill: The Ethics of AI.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "A self-driving car must choose: hit one pedestrian or swerve into a wall, killing the passenger.",
      "visual": "üöó"
    },
    "buildup": {
      "text": "AI systems make decisions that used to require moral judgment. But they follow code, not conscience.",
      "visual": "ü§ñ"
    },
    "discovery": {
      "text": "Bias in training data means AI can discriminate by race, gender, or income ‚Äî at massive scale.",
      "visual": "üìä"
    },
    "twist": {
      "text": "Who's responsible when AI causes harm? The programmer? The company? The algorithm itself?",
      "visual": "‚ùì"
    },
    "climax": {
      "text": "As AI grows more powerful, the ethical stakes rise. Philosophy is no longer optional for engineers.",
      "visual": "‚ö°"
    },
    "punchline": {
      "text": "We taught machines to think. Not yet to care.",
      "visual": "üíî"
    }
  },
  "quiz": {
    "question": "What is a major ethical concern with AI decision-making?",
    "options": [
      "Bias in training data can cause discrimination at scale",
      "AI is always perfectly fair",
      "Only humans make mistakes"
    ],
    "correct": 0
  }
}
