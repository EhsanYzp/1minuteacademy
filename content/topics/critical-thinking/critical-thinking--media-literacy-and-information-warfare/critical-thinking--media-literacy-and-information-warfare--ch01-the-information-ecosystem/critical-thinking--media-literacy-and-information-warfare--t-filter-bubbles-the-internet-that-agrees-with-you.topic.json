{
  "id": "critical-thinking--media-literacy-and-information-warfare--t-filter-bubbles-the-internet-that-agrees-with-you",
  "version": 1,
  "subject": "Critical Thinking",
  "subcategory": "Media Literacy & Information Warfare",
  "course_id": "critical-thinking--media-literacy-and-information-warfare",
  "chapter_id": "critical-thinking--media-literacy-and-information-warfare--ch01-the-information-ecosystem",
  "title": "Filter Bubbles: The Internet That Agrees with You",
  "emoji": "ğŸ“°",
  "color": "#C0392B",
  "description": "A 60-second lesson on Filter Bubbles: The Internet That Agrees with You.",
  "difficulty": "Intermediate",
  "published": true,
  "story": {
    "hook": {
      "text": "Two people Google the same topic. They get completely different results.",
      "visual": "ğŸ”"
    },
    "buildup": {
      "text": "Pariser coined 'filter bubble' in 2011: algorithms curate content based on your past behavior, creating a sealed worldview.",
      "visual": "ğŸ«§"
    },
    "discovery": {
      "text": "You don't see content that challenges you. You see content that confirms you. It's confirmation bias automated at scale.",
      "visual": "ğŸ¤–"
    },
    "twist": {
      "text": "Social media isn't showing you 'the world.' It's showing you a world designed to keep you engaged â€“ often through.",
      "visual": "ğŸ˜¤"
    },
    "climax": {
      "text": "Breaking the bubble: follow people you disagree with, use incognito mode, and deliberately seek opposing viewpoints.",
      "visual": "ğŸ”“"
    },
    "punchline": {
      "text": "If your feed always agrees with you, the algorithm is doing the thinking.",
      "visual": "ğŸ¤–"
    }
  },
  "quiz": {
    "question": "What creates a filter bubble?",
    "options": [
      "Users choose to only see certain content",
      "Algorithms curate content based on past behavior, hiding opposing views",
      "Internet censorship by governments"
    ],
    "correct": 1
  }
}
