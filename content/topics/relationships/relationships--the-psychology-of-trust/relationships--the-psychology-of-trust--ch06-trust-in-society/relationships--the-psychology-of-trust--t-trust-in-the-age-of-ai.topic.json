{
  "id": "relationships--the-psychology-of-trust--t-trust-in-the-age-of-ai",
  "version": 1,
  "subject": "Relationships",
  "subcategory": "The Psychology of Trust",
  "course_id": "relationships--the-psychology-of-trust",
  "chapter_id": "relationships--the-psychology-of-trust--ch06-trust-in-society",
  "title": "Trust in the Age of AI",
  "emoji": "ğŸ”",
  "color": "#E74C8B",
  "description": "A tiny lesson with a big payoff: Trust in the Age of AI.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "You're talking to a chatbot. It sounds human. It gives great advice. Do you trust it? Should you?",
      "visual": "ğŸ¤–"
    },
    "buildup": {
      "text": "AI systems can now mimic trust signals â€” empathy, consistency, reliability â€” without actually possessing any of them.",
      "visual": "ğŸ“‹"
    },
    "discovery": {
      "text": "Studies show people trust AI recommendations as much as human advice in many domains â€” sometimes more.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "AI can't betray you intentionally. But it can be wrong, biased, or manipulated â€” and you'd never know.",
      "visual": "âš ï¸"
    },
    "climax": {
      "text": "Trusting AI requires a new literacy: understanding what it can do, what it can't, and what it pretends to.",
      "visual": "ğŸ“š"
    },
    "punchline": {
      "text": "AI mimics trust signals without having them. New literacy is required.",
      "visual": "ğŸ¤–"
    }
  },
  "quiz": {
    "question": "Why is trusting AI uniquely challenging?",
    "options": [
      "AI is always wrong",
      "AI mimics trust signals without possessing them",
      "AI can't communicate"
    ],
    "correct": 1
  }
}
