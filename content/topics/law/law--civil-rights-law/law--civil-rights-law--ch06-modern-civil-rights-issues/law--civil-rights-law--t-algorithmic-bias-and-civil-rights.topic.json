{
  "id": "law--civil-rights-law--t-algorithmic-bias-and-civil-rights",
  "version": 1,
  "subject": "Law",
  "subcategory": "Civil Rights Law",
  "course_id": "law--civil-rights-law",
  "chapter_id": "law--civil-rights-law--ch06-modern-civil-rights-issues",
  "title": "Algorithmic Bias and Civil Rights",
  "emoji": "‚úä",
  "color": "#C0392B",
  "description": "A quick, practical guide to Algorithmic Bias and Civil Rights.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "An AI rejects your loan application. It can't explain why. But it rejected far more Black applicants than white ones.",
      "visual": "ü§ñ"
    },
    "buildup": {
      "text": "Algorithms used in hiring, lending, and policing can embed and amplify racial and gender biases from training data.",
      "visual": "üìä"
    },
    "discovery": {
      "text": "Disparate impact theory may apply: if an algorithm disproportionately harms a protected group, it could be illegal.",
      "visual": "‚öñÔ∏è"
    },
    "twist": {
      "text": "But proving bias in a black-box algorithm is very hard. Traditional legal frameworks struggle with opaque AI.",
      "visual": "üîç"
    },
    "climax": {
      "text": "Cities like New York now require bias audits for AI hiring tools. The EU's AI Act takes an even broader approach.",
      "visual": "üìú"
    },
    "punchline": {
      "text": "Bias doesn't need intent. When code discriminates, the law must adapt.",
      "visual": "‚öñÔ∏è"
    }
  },
  "quiz": {
    "question": "What legal theory might apply to biased algorithms?",
    "options": [
      "Strict liability",
      "Disparate impact",
      "Contributory negligence"
    ],
    "correct": 1
  }
}
