{
  "id": "ethics--famous-ethical-dilemmas--t-ai-hiring-bias",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "Famous Ethical Dilemmas",
  "course_id": "ethics--famous-ethical-dilemmas",
  "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
  "title": "AI Hiring Bias",
  "emoji": "ğŸ¤”",
  "color": "#E11D48",
  "description": "A short lesson to help you apply AI Hiring Bias.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "Amazon built an AI to screen job applicants. It taught itself that women were less qualified than men.",
      "visual": "ğŸ¤–"
    },
    "buildup": {
      "text": "The AI was trained on ten years of rÃ©sumÃ©sâ€”mostly from men, because tech was dominated by men.",
      "visual": "ğŸ“„"
    },
    "discovery": {
      "text": "The algorithm learned to penalize rÃ©sumÃ©s containing the word 'women's,' like 'women's chess club.'",
      "visual": "â™Ÿï¸"
    },
    "twist": {
      "text": "Amazon scrapped the tool, but other companies use similar AI hiring systemsâ€”often without checking for bias.",
      "visual": "ğŸ¢"
    },
    "climax": {
      "text": "AI doesn't eliminate human bias. It scales itâ€”making discrimination faster, cheaper, and harder to see.",
      "visual": "ğŸ“ˆ"
    },
    "punchline": {
      "text": "Biased data in, biased decisions out. AI just automates it.",
      "visual": "ğŸ”„"
    }
  },
  "quiz": {
    "question": "Why did Amazon's AI hiring tool discriminate against women?",
    "options": [
      "It was trained on ten years of male-dominated rÃ©sumÃ© data and learned to replicate that bias",
      "The programmers deliberately coded it to prefer male candidates",
      "Women submitted fewer applications so the AI had less data about them"
    ],
    "correct": 0
  }
}
