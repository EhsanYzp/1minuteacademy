{
  "id": "ethics--famous-ethical-dilemmas--t-facial-recognition-in-public",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "Famous Ethical Dilemmas",
  "course_id": "ethics--famous-ethical-dilemmas",
  "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
  "title": "Facial Recognition in Public",
  "emoji": "ğŸ¤”",
  "color": "#E11D48",
  "description": "A 1-minute de-risking session on Facial Recognition in Public.",
  "difficulty": "Advanced",
  "published": true,
  "story": {
    "hook": {
      "text": "London police used facial recognition at a protest. It flagged 104 people. 102 were false matches.",
      "visual": "ğŸ“¸"
    },
    "buildup": {
      "text": "Facial recognition can identify anyone from a camera feedâ€”shoplifters, terrorists, or peaceful protestors.",
      "visual": "ğŸ‘ï¸"
    },
    "discovery": {
      "text": "The technology is up to 100 times more likely to misidentify Black and Asian faces than white ones.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "China uses it to track Uyghur Muslims. Russia uses it to identify protesters. The tool is neutral; intent isn't.",
      "visual": "ğŸŒ"
    },
    "climax": {
      "text": "Once you allow cameras to identify everyone everywhere, anonymity in public spaces disappears forever.",
      "visual": "ğŸš¶"
    },
    "punchline": {
      "text": "A face is not a fingerprint. You can't leave it at home.",
      "visual": "ğŸ "
    }
  },
  "quiz": {
    "question": "What is a documented bias in facial recognition technology?",
    "options": [
      "It is equally accurate across all racial and ethnic groups",
      "It is up to 100 times more likely to misidentify Black and Asian faces than white ones",
      "It can only identify people who have been previously photographed by police"
    ],
    "correct": 1
  }
}
