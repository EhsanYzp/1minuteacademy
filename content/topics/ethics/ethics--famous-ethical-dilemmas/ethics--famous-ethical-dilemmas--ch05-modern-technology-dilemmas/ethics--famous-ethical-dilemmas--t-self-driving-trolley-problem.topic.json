{
  "id": "ethics--famous-ethical-dilemmas--t-self-driving-trolley-problem",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "Famous Ethical Dilemmas",
  "course_id": "ethics--famous-ethical-dilemmas",
  "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
  "title": "Self-Driving Trolley Problem",
  "emoji": "ü§î",
  "color": "#E11D48",
  "description": "A short lesson to help you apply Self-Driving Trolley Problem.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "A self-driving car must choose: swerve and kill the passenger, or go straight and kill the pedestrian.",
      "visual": "üöó"
    },
    "buildup": {
      "text": "The classic trolley problem is no longer hypothetical. Engineers must program these decisions into cars.",
      "visual": "üíª"
    },
    "discovery": {
      "text": "MIT's Moral Machine asked millions of people to choose. Preferences varied wildly by culture and country.",
      "visual": "üåç"
    },
    "twist": {
      "text": "Everyone wants self-driving cars that protect pedestrians‚Äîbut nobody wants to ride in one that sacrifices them.",
      "visual": "ü§∑"
    },
    "climax": {
      "text": "We're asking engineers to encode morality into algorithms. Philosophy never solved this‚Äîwhy would code?",
      "visual": "üßë‚Äçüíª"
    },
    "punchline": {
      "text": "Philosophers debated for centuries. Now programmers have a deadline.",
      "visual": "‚è≥"
    }
  },
  "quiz": {
    "question": "What did MIT's Moral Machine study reveal about self-driving car ethics?",
    "options": [
      "There is universal global agreement on how self-driving cars should handle moral dilemmas",
      "Most people prefer self-driving cars that always protect the passenger at any cost",
      "People's moral preferences varied significantly by culture and country"
    ],
    "correct": 2
  }
}
