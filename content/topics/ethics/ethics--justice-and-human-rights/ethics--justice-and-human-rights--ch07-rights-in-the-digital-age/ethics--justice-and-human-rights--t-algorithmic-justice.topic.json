{
  "id": "ethics--justice-and-human-rights--t-algorithmic-justice",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "Justice & Human Rights",
  "course_id": "ethics--justice-and-human-rights",
  "chapter_id": "ethics--justice-and-human-rights--ch07-rights-in-the-digital-age",
  "title": "Algorithmic Justice",
  "emoji": "âš”ï¸",
  "color": "#B45309",
  "description": "Learn Algorithmic Justice in one minute.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "A US algorithm scored Black defendants as higher risk than white defendants who had worse criminal records.",
      "visual": "ğŸ¤–"
    },
    "buildup": {
      "text": "Courts, banks, and employers use algorithms to make decisions. They're supposed to be objective. They're not.",
      "visual": "ğŸ’»"
    },
    "discovery": {
      "text": "Algorithms learn from historical data. If that data reflects racism, the algorithm automates it at scale.",
      "visual": "ğŸ“Š"
    },
    "twist": {
      "text": "Amazon built a hiring AI that penalized rÃ©sumÃ©s with the word 'women's.' It learned bias from past hiring data.",
      "visual": "ğŸ“„"
    },
    "climax": {
      "text": "Automated decisions feel neutral, but they can embed prejudice in code and scale it to millions without accountability.",
      "visual": "âš ï¸"
    },
    "punchline": {
      "text": "Bias doesn't disappear when you automate it. It scales.",
      "visual": "ğŸ“ˆ"
    }
  },
  "quiz": {
    "question": "Why do algorithms often produce biased results?",
    "options": [
      "They are deliberately programmed to discriminate",
      "They learn patterns from historically biased data",
      "They're too simple to handle complex decisions"
    ],
    "correct": 1
  }
}
