{
  "id": "ethics--ai-and-technology-ethics--t-self-driving-car-dilemmas",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "AI & Technology Ethics",
  "course_id": "ethics--ai-and-technology-ethics",
  "chapter_id": "ethics--ai-and-technology-ethics--ch03-autonomous-systems",
  "title": "Self-Driving Car Dilemmas",
  "emoji": "ü§ñ",
  "color": "#0891B2",
  "description": "A fast breakdown of Self-Driving Car Dilemmas for builders.",
  "difficulty": "Beginner",
  "published": true,
  "story": {
    "hook": {
      "text": "A self-driving car must swerve. Left hits an elderly man. Right hits a child. Straight kills the passenger.",
      "visual": "üöó"
    },
    "buildup": {
      "text": "MIT's Moral Machine asked millions of people worldwide how autonomous cars should handle fatal crashes.",
      "visual": "üåç"
    },
    "discovery": {
      "text": "Answers varied wildly by culture. Some prioritized the young, others the many, others the law-abiding.",
      "visual": "üìä"
    },
    "twist": {
      "text": "Real crashes aren't neat trolley problems. The car has milliseconds and imperfect sensor data.",
      "visual": "‚ö°"
    },
    "climax": {
      "text": "No manufacturer will sell a car that's programmed to kill its owner. The market vetoes the moral answer.",
      "visual": "üí∞"
    },
    "punchline": {
      "text": "The trolley problem got wheels. And a price tag.",
      "visual": "üè∑Ô∏è"
    }
  },
  "quiz": {
    "question": "What did MIT's Moral Machine project reveal about autonomous vehicle ethics?",
    "options": [
      "Everyone agrees the passenger should be sacrificed",
      "Moral preferences for crash outcomes vary significantly across cultures",
      "Self-driving cars never face ethical dilemmas"
    ],
    "correct": 1
  }
}
