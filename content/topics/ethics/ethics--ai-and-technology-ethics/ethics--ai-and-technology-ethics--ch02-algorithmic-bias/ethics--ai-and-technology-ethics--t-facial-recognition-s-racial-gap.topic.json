{
  "id": "ethics--ai-and-technology-ethics--t-facial-recognition-s-racial-gap",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "AI & Technology Ethics",
  "course_id": "ethics--ai-and-technology-ethics",
  "chapter_id": "ethics--ai-and-technology-ethics--ch02-algorithmic-bias",
  "title": "Facial Recognition's Racial Gap",
  "emoji": "ğŸ¤–",
  "color": "#0891B2",
  "description": "Learn Facial Recognition's Racial Gap in one minute.",
  "is_free": false,
  "published": true,
  "story": {
    "hook": {
      "text": "A Black man was arrested in Detroit for a crime he didn't commit. A facial recognition AI said he did it.",
      "visual": "ğŸ‘¤"
    },
    "buildup": {
      "text": "MIT researcher Joy Buolamwini found facial recognition had error rates 35% higher for dark-skinned women.",
      "visual": "ğŸ“‰"
    },
    "discovery": {
      "text": "Training datasets were overwhelmingly white and male. The AI literally couldn't see diversity.",
      "visual": "ğŸ“¸"
    },
    "twist": {
      "text": "Companies claimed their tech was 99% accurateâ€”but only tested it on the faces it already knew best.",
      "visual": "ğŸ¯"
    },
    "climax": {
      "text": "Several cities banned police use of facial recognition. Others doubled down and expanded it.",
      "visual": "ğŸš”"
    },
    "punchline": {
      "text": "If the machine can't see you clearly, it shouldn't judge you.",
      "visual": "ğŸ‘ï¸"
    }
  },
  "quiz": {
    "question": "What did Joy Buolamwini's research reveal about facial recognition?",
    "options": [
      "It works equally well for all demographics",
      "It has significantly higher error rates for dark-skinned women",
      "It is more accurate than human identification in all cases"
    ],
    "correct": 1
  }
}
