{
  "id": "ethics--ai-and-technology-ethics--t-bias-in-hiring-algorithms",
  "version": 1,
  "subject": "Ethics",
  "subcategory": "AI & Technology Ethics",
  "course_id": "ethics--ai-and-technology-ethics",
  "chapter_id": "ethics--ai-and-technology-ethics--ch02-algorithmic-bias",
  "title": "Bias in Hiring Algorithms",
  "emoji": "ğŸ¤–",
  "color": "#0891B2",
  "description": "Learn Bias in Hiring Algorithms in one minute.",
  "is_free": true,
  "published": true,
  "story": {
    "hook": {
      "text": "Amazon built an AI recruiter. It learned to penalize any resume that mentioned 'women's' anything.",
      "visual": "ğŸ“„"
    },
    "buildup": {
      "text": "The AI was trained on 10 years of hiring dataâ€”from a company that had mostly hired men.",
      "visual": "ğŸ‘”"
    },
    "discovery": {
      "text": "Machine learning mirrors its training data. Feed it biased history and it produces biased futures.",
      "visual": "ğŸª"
    },
    "twist": {
      "text": "Amazon scrapped the tool, but hundreds of companies still use AI hiring with less scrutiny.",
      "visual": "ğŸ—‘ï¸"
    },
    "climax": {
      "text": "The AI wasn't sexist on purpose. It just learned that male resumes got hired. Pattern matched.",
      "visual": "ğŸ”„"
    },
    "punchline": {
      "text": "Garbage in, discrimination out. Data has no conscience.",
      "visual": "ğŸ—ƒï¸"
    }
  },
  "quiz": {
    "question": "Why did Amazon's AI recruiting tool discriminate against women?",
    "options": [
      "It was trained on historically biased hiring data",
      "Engineers intentionally coded gender preferences",
      "Women submitted fewer applications"
    ],
    "correct": 0
  }
}
