{
  "categoryId": "philosophy",
  "subject": "Philosophy",
  "courseId": "philosophy--ethics-and-morality",
  "courseTitle": "Ethics & Morality",
  "emoji": "âš–ï¸",
  "color": "#7E22CE",
  "requireAuthoredStory": true,
  "chapters": [
    { "id": "philosophy--ethics-and-morality--ch01-foundations", "title": "Foundations of Ethics", "position": 1 },
    { "id": "philosophy--ethics-and-morality--ch02-consequentialism", "title": "Consequentialism", "position": 2 },
    { "id": "philosophy--ethics-and-morality--ch03-duty-and-rules", "title": "Duty & Rules", "position": 3 },
    { "id": "philosophy--ethics-and-morality--ch04-virtue-ethics", "title": "Virtue Ethics", "position": 4 },
    { "id": "philosophy--ethics-and-morality--ch05-moral-dilemmas", "title": "Moral Dilemmas", "position": 5 },
    { "id": "philosophy--ethics-and-morality--ch06-applied-ethics", "title": "Applied Ethics", "position": 6 }
  ],
  "topics": [
    {
      "chapter_id": "philosophy--ethics-and-morality--ch01-foundations",
      "title": "What Is Ethics?",
      "story": {
        "hook": { "text": "You find a wallet with $500 and an ID inside. Nobody's watching. What should you do?", "visual": "ğŸ‘›" },
        "buildup": { "text": "Ethics is the study of what's right and wrong â€” and more importantly, why.", "visual": "ğŸ“˜" },
        "discovery": { "text": "It's not about following laws. Laws can be unjust. Ethics asks what we ought to do regardless.", "visual": "âš–ï¸" },
        "twist": { "text": "Different ethical systems give different answers to the same question â€” and all seem reasonable.", "visual": "ğŸ”€" },
        "climax": { "text": "Ethics doesn't give easy answers. It gives you better questions to ask before you act.", "visual": "ğŸ¤”" },
        "punchline": { "text": "Doing the right thing starts with asking what 'right' means.", "visual": "ğŸ’¡" }
      },
      "quiz": {
        "question": "How does ethics differ from law?",
        "options": ["Ethics asks what we ought to do, even if laws disagree", "Ethics only applies to religious people", "Ethics and law are identical"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch01-foundations",
      "title": "Moral Relativism",
      "story": {
        "hook": { "text": "In some cultures, arranged marriage is moral. In others, it's oppressive. Who's right?", "visual": "ğŸŒ" },
        "buildup": { "text": "Moral relativism says there are no universal truths. Right and wrong depend on culture or context.", "visual": "ğŸ”„" },
        "discovery": { "text": "The Greek historian Herodotus noticed different peoples had incompatible customs â€” and each was certain.", "visual": "ğŸ“œ" },
        "twist": { "text": "But if morality is relative, you can't condemn slavery or genocide. They were 'normal' somewhere.", "visual": "ğŸš¨" },
        "climax": { "text": "Most philosophers reject extreme relativism but accept that culture shapes moral intuitions.", "visual": "ğŸ§­" },
        "punchline": { "text": "If everything is relative, nothing is wrong.", "visual": "â“" }
      },
      "quiz": {
        "question": "What is the main problem with extreme moral relativism?",
        "options": ["It makes it impossible to condemn any practice", "It leads to too many rules", "It only works in democracies"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch01-foundations",
      "title": "Moral Realism",
      "story": {
        "hook": { "text": "Torturing children for fun is wrong â€” not just in your culture, but everywhere, always.", "visual": "ğŸš«" },
        "buildup": { "text": "Moral realists say some moral facts exist independently of what anyone thinks or feels.", "visual": "ğŸ”ï¸" },
        "discovery": { "text": "Just as gravity exists whether you believe in it or not, cruelty is wrong whether a culture accepts it.", "visual": "ğŸ" },
        "twist": { "text": "The hard part is proving it. You can measure gravity. How do you measure a moral fact?", "visual": "ğŸ“" },
        "climax": { "text": "Moral realism feels intuitively right but remains philosophically difficult to defend completely.", "visual": "ğŸ§©" },
        "punchline": { "text": "Some things feel universally wrong. Proving why is harder.", "visual": "ğŸ”’" }
      },
      "quiz": {
        "question": "What do moral realists believe?",
        "options": ["Some moral truths exist independently of opinion", "Morality is always relative", "Only science can determine right and wrong"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch01-foundations",
      "title": "The Is-Ought Problem",
      "story": {
        "hook": { "text": "Nature is violent. Animals kill to survive. Does that mean humans should too?", "visual": "ğŸ¦" },
        "buildup": { "text": "David Hume noticed you can't logically jump from 'this is how things are' to 'this is how they should be.'", "visual": "ğŸ”" },
        "discovery": { "text": "Facts describe the world. Values prescribe behavior. They're different kinds of statements.", "visual": "ğŸ“Š" },
        "twist": { "text": "People constantly smuggle 'oughts' into 'is' claims. 'Natural' doesn't mean 'good.'", "visual": "ğŸ­" },
        "climax": { "text": "Hume's insight remains a foundation of moral philosophy. You can't derive ethics from biology alone.", "visual": "ğŸ§¬" },
        "punchline": { "text": "What is and what ought to be are different questions.", "visual": "â†”ï¸" }
      },
      "quiz": {
        "question": "What is Hume's is-ought problem?",
        "options": ["You can't derive moral rules from factual descriptions", "Science can solve all moral questions", "Morality is based on natural law"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch01-foundations",
      "title": "Where Morality Comes From",
      "story": {
        "hook": { "text": "Are we born with a moral sense, or do we learn right from wrong entirely through culture?", "visual": "ğŸ‘¶" },
        "buildup": { "text": "Evolutionary psychologists say cooperation and fairness gave our ancestors a survival advantage.", "visual": "ğŸ§¬" },
        "discovery": { "text": "Even toddlers show a sense of fairness. Babies prefer puppets that help over those that hinder.", "visual": "ğŸ§¸" },
        "twist": { "text": "But culture shapes which moral instincts get amplified and which get suppressed.", "visual": "ğŸŒ" },
        "climax": { "text": "Morality seems partly wired in, partly learned. Nature provides the seed; culture shapes the tree.", "visual": "ğŸŒ±" },
        "punchline": { "text": "We're born ready for morality, not born moral.", "visual": "ğŸ§’" }
      },
      "quiz": {
        "question": "What do studies of babies suggest about morality?",
        "options": ["Humans are born with basic moral instincts", "Morality is entirely cultural", "Babies have no preferences at all"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch02-consequentialism",
      "title": "The Greatest Good",
      "story": {
        "hook": { "text": "What if the right action is simply whichever one makes the most people happy?", "visual": "ğŸ˜Š" },
        "buildup": { "text": "That's utilitarianism â€” the most influential form of consequentialism.", "visual": "ğŸ“Š" },
        "discovery": { "text": "Jeremy Bentham proposed it in the 1780s: maximize pleasure, minimize pain, for the greatest number.", "visual": "âš–ï¸" },
        "twist": { "text": "But it has a dark side. If harvesting one person's organs saves five, utilitarianism might approve.", "visual": "ğŸ˜°" },
        "climax": { "text": "The results matter most, not intentions. A good heart that causes harm is still morally wrong.", "visual": "ğŸ’”" },
        "punchline": { "text": "The greatest good sounds simple. It isn't.", "visual": "ğŸ¯" }
      },
      "quiz": {
        "question": "What does utilitarianism say is the right action?",
        "options": ["The one that produces the most overall happiness", "The one that follows duty", "The one that builds character"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch02-consequentialism",
      "title": "Bentham's Happiness Calculus",
      "story": {
        "hook": { "text": "Jeremy Bentham tried to turn morality into math. He wanted a formula for happiness.", "visual": "ğŸ§®" },
        "buildup": { "text": "His felicific calculus measured pleasure by intensity, duration, certainty, and nearness.", "visual": "ğŸ“" },
        "discovery": { "text": "Add up all the pleasure, subtract all the pain, and the action with the highest score wins.", "visual": "â•" },
        "twist": { "text": "It sounds elegant but fails in practice. How do you compare the joy of music to the relief of hunger?", "visual": "ğŸµ" },
        "climax": { "text": "Bentham's calculus was never usable, but it forced people to take consequences seriously.", "visual": "ğŸ“" },
        "punchline": { "text": "You can't calculate happiness. But you can count it.", "visual": "ğŸ”¢" }
      },
      "quiz": {
        "question": "What was Bentham's felicific calculus designed to measure?",
        "options": ["The total pleasure and pain of an action", "The virtue of a person", "The fairness of a law"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch02-consequentialism",
      "title": "Mill's Refinement",
      "story": {
        "hook": { "text": "Is a game of checkers as valuable as reading Shakespeare? Bentham said yes. Mill said absolutely not.", "visual": "â™Ÿï¸" },
        "buildup": { "text": "John Stuart Mill argued that pleasures differ in quality, not just quantity.", "visual": "ğŸ“š" },
        "discovery": { "text": "Higher pleasures â€” intellect, art, deep relationships â€” outweigh lower ones like simple amusement.", "visual": "ğŸ­" },
        "twist": { "text": "Critics asked: who decides which pleasures are higher? That sounds like elitism in disguise.", "visual": "ğŸ‘‘" },
        "climax": { "text": "Mill replied: anyone who has experienced both will prefer the higher. The test is experience itself.", "visual": "âš–ï¸" },
        "punchline": { "text": "Better to be Socrates unhappy than a fool satisfied.", "visual": "ğŸ¤”" }
      },
      "quiz": {
        "question": "How did Mill differ from Bentham on pleasure?",
        "options": ["Mill said some pleasures are qualitatively superior", "Mill rejected pleasure entirely", "Mill said all pleasures are equal"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch02-consequentialism",
      "title": "The Problem with Measuring Happiness",
      "story": {
        "hook": { "text": "How happy is a free concert in the park? Now multiply that by ten thousand attendees.", "visual": "ğŸ¶" },
        "buildup": { "text": "Utilitarianism needs us to add up happiness. But happiness is deeply personal and hard to compare.", "visual": "ğŸ“Š" },
        "discovery": { "text": "Economists tried with 'utility' â€” abstract units of satisfaction. But utility can't be observed.", "visual": "ğŸ“ˆ" },
        "twist": { "text": "Worse, people adapt. A raise feels great for a month, then becomes your new normal.", "visual": "ğŸ”" },
        "climax": { "text": "If we can't reliably measure happiness, the foundation of utilitarianism starts to crack.", "visual": "ğŸšï¸" },
        "punchline": { "text": "You can't maximize what you can't measure.", "visual": "ğŸ“" }
      },
      "quiz": {
        "question": "Why is measuring happiness a problem for utilitarianism?",
        "options": ["Happiness is subjective and hard to compare across people", "Happiness doesn't exist", "Only economists can measure it"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch02-consequentialism",
      "title": "Effective Altruism",
      "story": {
        "hook": { "text": "Peter Singer asked: if a child is drowning and you can save them, are you obligated to act?", "visual": "ğŸŒŠ" },
        "buildup": { "text": "Most people say yes. Singer then asked: what about children dying of poverty far away?", "visual": "ğŸŒ" },
        "discovery": { "text": "Effective altruism applies utilitarian logic: donate where each dollar saves the most lives.", "visual": "ğŸ’°" },
        "twist": { "text": "Critics say it turns morality into cold math. Should you skip your friend's birthday to donate more?", "visual": "ğŸ‚" },
        "climax": { "text": "EA has moved billions toward global health, but the tension between logic and humanity remains.", "visual": "â¤ï¸" },
        "punchline": { "text": "Doing the most good is harder than doing good.", "visual": "ğŸ¯" }
      },
      "quiz": {
        "question": "What does effective altruism prioritize?",
        "options": ["Directing resources where they do the most measurable good", "Donating to the nearest cause", "Volunteering over donating"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch03-duty-and-rules",
      "title": "Kant's Categorical Imperative",
      "story": {
        "hook": { "text": "Kant said lying is always wrong â€” even if a murderer asks where your friend is hiding.", "visual": "ğŸšª" },
        "buildup": { "text": "His categorical imperative demands: act only by rules you'd want everyone to follow.", "visual": "ğŸ“œ" },
        "discovery": { "text": "If lying became universal, trust would collapse and lying itself would become pointless.", "visual": "ğŸ”—" },
        "twist": { "text": "The rigidity bothers many. Surely context matters? Kant insisted: duty is duty, no exceptions.", "visual": "ğŸ—¿" },
        "climax": { "text": "Kantian ethics gave us the idea that some actions are wrong regardless of their consequences.", "visual": "âš–ï¸" },
        "punchline": { "text": "Act as if your choice became a law for everyone.", "visual": "ğŸŒ" }
      },
      "quiz": {
        "question": "What does Kant's categorical imperative require?",
        "options": ["Act only by rules you'd want everyone to follow", "Always maximize happiness", "Follow your culture's norms"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch03-duty-and-rules",
      "title": "The Golden Rule",
      "story": {
        "hook": { "text": "Treat others as you'd want to be treated. Nearly every civilization invented this rule.", "visual": "ğŸŒ" },
        "buildup": { "text": "Confucius, Jesus, Hillel, and the Buddha all taught versions of it independently.", "visual": "ğŸ“¿" },
        "discovery": { "text": "It works because it forces empathy â€” you must imagine yourself in the other person's position.", "visual": "ğŸ”„" },
        "twist": { "text": "But it fails when preferences differ. A masochist following the Golden Rule would harm others.", "visual": "ğŸ˜¬" },
        "climax": { "text": "The Platinum Rule improves it: treat others as they want to be treated, not as you would.", "visual": "âœ¨" },
        "punchline": { "text": "Good rules sometimes need better rules.", "visual": "ğŸ“" }
      },
      "quiz": {
        "question": "What is a common criticism of the Golden Rule?",
        "options": ["It assumes everyone has the same preferences", "It's too hard to follow", "It was only invented once"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch03-duty-and-rules",
      "title": "Rights-Based Ethics",
      "story": {
        "hook": { "text": "You can't torture one person even if it would save a hundred. That's a rights-based claim.", "visual": "ğŸ›¡ï¸" },
        "buildup": { "text": "John Locke argued that people have natural rights â€” life, liberty, and property â€” just by being human.", "visual": "ğŸ“œ" },
        "discovery": { "text": "Rights act as moral shields. They protect individuals from being sacrificed for the greater good.", "visual": "ğŸ”’" },
        "twist": { "text": "But rights can conflict. Your right to free speech may clash with someone else's right to safety.", "visual": "âš”ï¸" },
        "climax": { "text": "Every modern constitution is built on rights-based ethics. The argument is about which rights matter most.", "visual": "ğŸ›ï¸" },
        "punchline": { "text": "Rights are the walls that protect the individual.", "visual": "ğŸ§±" }
      },
      "quiz": {
        "question": "What function do rights serve in ethics?",
        "options": ["They protect individuals from being sacrificed for the group", "They maximize happiness", "They enforce cultural norms"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch03-duty-and-rules",
      "title": "Deontology in Practice",
      "story": {
        "hook": { "text": "A doctor has five dying patients and one healthy visitor. Should she harvest the visitor's organs?", "visual": "ğŸ¥" },
        "buildup": { "text": "A utilitarian might say yes â€” five lives outweigh one. A deontologist says absolutely not.", "visual": "ğŸš«" },
        "discovery": { "text": "Deontology judges actions by their nature, not their outcomes. Using a person as a means is always wrong.", "visual": "âš–ï¸" },
        "twist": { "text": "But rigid rules can lead to absurd results. Must you return a borrowed knife to a raging madman?", "visual": "ğŸ”ª" },
        "climax": { "text": "Real-life ethics often blends duty and consequences. Pure deontology is a compass, not a map.", "visual": "ğŸ§­" },
        "punchline": { "text": "Some lines shouldn't be crossed, no matter the math.", "visual": "ğŸš§" }
      },
      "quiz": {
        "question": "Why would a deontologist refuse to harvest one person's organs to save five?",
        "options": ["Using someone merely as a means is always wrong", "The math doesn't work out", "Organ donation is illegal"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch03-duty-and-rules",
      "title": "When Rules Conflict",
      "story": {
        "hook": { "text": "You promised to keep a secret. Then you learn the secret could save someone's life.", "visual": "ğŸ¤«" },
        "buildup": { "text": "Duty-based ethics says keep your promises. It also says protect human life. Now what?", "visual": "âš–ï¸" },
        "discovery": { "text": "W. D. Ross proposed 'prima facie' duties â€” moral obligations that hold unless overridden by a stronger duty.", "visual": "ğŸ“‹" },
        "twist": { "text": "There's no master ranking of duties. You must use judgment, and reasonable people may disagree.", "visual": "ğŸ¤”" },
        "climax": { "text": "Ross admitted ethics can't be turned into an algorithm. Moral wisdom is about weighing, not calculating.", "visual": "ğŸ§ " },
        "punchline": { "text": "Rules guide us. Judgment finishes the job.", "visual": "ğŸ" }
      },
      "quiz": {
        "question": "What did W. D. Ross call duties that can be overridden by stronger ones?",
        "options": ["Prima facie duties", "Categorical imperatives", "Natural rights"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch04-virtue-ethics",
      "title": "Aristotle's Golden Mean",
      "story": {
        "hook": { "text": "Courage isn't the absence of fear. It's the sweet spot between cowardice and recklessness.", "visual": "ğŸ¯" },
        "buildup": { "text": "Aristotle said every virtue sits between two extremes â€” too much and too little.", "visual": "âš–ï¸" },
        "discovery": { "text": "Generosity lies between stinginess and wastefulness. Honesty between secrecy and bluntness.", "visual": "ğŸŒ¡ï¸" },
        "twist": { "text": "The exact midpoint differs for each person and situation. There's no universal formula.", "visual": "ğŸ”§" },
        "climax": { "text": "Finding the golden mean requires practice and wisdom. Virtue isn't a rule â€” it's a skill.", "visual": "ğŸ‹ï¸" },
        "punchline": { "text": "Virtue is a habit, not a single act.", "visual": "ğŸ”" }
      },
      "quiz": {
        "question": "What is Aristotle's golden mean?",
        "options": ["The balance point between two extremes of character", "The average of all moral opinions", "A mathematical formula for happiness"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch04-virtue-ethics",
      "title": "Character Over Actions",
      "story": {
        "hook": { "text": "Utilitarianism asks 'what should I do?' Virtue ethics asks 'what kind of person should I be?'", "visual": "ğŸª" },
        "buildup": { "text": "The focus shifts from individual acts to character. A honest person makes honest choices naturally.", "visual": "ğŸ’" },
        "discovery": { "text": "Aristotle believed good character develops through habit. Do courageous things and courage grows.", "visual": "ğŸŒ±" },
        "twist": { "text": "Critics ask: what about situations where a good person does something terrible? Character isn't enough.", "visual": "â“" },
        "climax": { "text": "Virtue ethicists reply: no system is perfect. But building character prepares you for what rules can't cover.", "visual": "ğŸ›¡ï¸" },
        "punchline": { "text": "Be the right person and the right acts follow.", "visual": "ğŸ§­" }
      },
      "quiz": {
        "question": "What does virtue ethics focus on, unlike utilitarianism?",
        "options": ["Who you are, not just what you do", "Calculating consequences", "Following universal rules"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch04-virtue-ethics",
      "title": "The Virtues Across Cultures",
      "story": {
        "hook": { "text": "Aristotle valued courage. Confucius valued filial piety. The Buddha valued compassion.", "visual": "ğŸŒ" },
        "buildup": { "text": "Different cultures emphasize different virtues, yet remarkable overlaps appear.", "visual": "ğŸ”„" },
        "discovery": { "text": "Honesty, justice, courage, and kindness show up in nearly every moral tradition on Earth.", "visual": "ğŸŒ" },
        "twist": { "text": "But priorities differ. Western ethics prizes autonomy. East Asian ethics prizes harmony and duty.", "visual": "âš–ï¸" },
        "climax": { "text": "The universal core suggests something shared in human nature. The variation reflects cultural needs.", "visual": "ğŸ§¬" },
        "punchline": { "text": "Different gardens, similar flowers.", "visual": "ğŸŒ¸" }
      },
      "quiz": {
        "question": "Which virtues appear across most cultures?",
        "options": ["Honesty, justice, courage, and kindness", "Only courage and strength", "Wealth and power"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch04-virtue-ethics",
      "title": "Moral Exemplars",
      "story": {
        "hook": { "text": "When you think of a good person, a face comes to mind. That face teaches more than any rulebook.", "visual": "ğŸ‘¤" },
        "buildup": { "text": "Virtue ethics says we learn morality by watching exemplars â€” people who embody the virtues.", "visual": "ğŸŒŸ" },
        "discovery": { "text": "Gandhi, Mandela, and Malala didn't follow an algorithm. They lived with integrity under pressure.", "visual": "âœŠ" },
        "twist": { "text": "But exemplars are human. Gandhi had flaws. Does that undermine the approach?", "visual": "ğŸª" },
        "climax": { "text": "No one is perfect, but aspiring toward excellence is itself a virtue. The ideal guides, not dictates.", "visual": "ğŸ§­" },
        "punchline": { "text": "We learn goodness from people, not textbooks.", "visual": "ğŸ“–" }
      },
      "quiz": {
        "question": "How do virtue ethicists say we learn morality?",
        "options": ["By observing and imitating moral exemplars", "By memorizing rules", "By studying consequences"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch04-virtue-ethics",
      "title": "Can Virtue Be Taught?",
      "story": {
        "hook": { "text": "Socrates asked this question 2,400 years ago. We still don't have a clear answer.", "visual": "ğŸ›ï¸" },
        "buildup": { "text": "Aristotle said yes â€” virtue is a habit formed through practice, like learning an instrument.", "visual": "ğŸ»" },
        "discovery": { "text": "Modern research supports this. Children who practice empathy develop stronger moral reasoning.", "visual": "ğŸ§’" },
        "twist": { "text": "But environment matters enormously. Poverty, trauma, and injustice can derail moral development.", "visual": "ğŸŒ§ï¸" },
        "climax": { "text": "Virtue can be nurtured but not guaranteed. The conditions for moral growth aren't equally available.", "visual": "ğŸŒ±" },
        "punchline": { "text": "Character is built, but the materials aren't free.", "visual": "ğŸ§±" }
      },
      "quiz": {
        "question": "What did Aristotle believe about teaching virtue?",
        "options": ["It can be developed through practice and habit", "It's entirely genetic", "It requires divine intervention"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch05-moral-dilemmas",
      "title": "The Trolley Problem",
      "story": {
        "hook": { "text": "A runaway trolley is heading for five people. You can pull a lever to divert it â€” killing one instead.", "visual": "ğŸšƒ" },
        "buildup": { "text": "Most people pull the lever. Five lives saved for one lost seems like simple math.", "visual": "ğŸ”¢" },
        "discovery": { "text": "But change the scenario: push a stranger off a bridge to stop the trolley. Now most people refuse.", "visual": "ğŸŒ‰" },
        "twist": { "text": "The math is identical â€” one dies, five live. Yet physically pushing someone feels fundamentally different.", "visual": "ğŸ¤š" },
        "climax": { "text": "Philippa Foot designed this to show that moral intuitions aren't consistent â€” and that matters.", "visual": "ğŸ§ " },
        "punchline": { "text": "Same math. Different answer. That's the problem.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "What does the trolley problem reveal?",
        "options": ["Our moral intuitions are inconsistent", "Math always determines ethics", "People are naturally selfish"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch05-moral-dilemmas",
      "title": "The Drowning Child",
      "story": {
        "hook": { "text": "You walk past a pond. A child is drowning. You can easily save them. Are you morally required to act?", "visual": "ğŸŒŠ" },
        "buildup": { "text": "Almost everyone says yes. Letting the child die when you can help is monstrous.", "visual": "âœ…" },
        "discovery": { "text": "Peter Singer then asks: children die daily from preventable causes. Why don't we feel the same urgency?", "visual": "ğŸŒ" },
        "twist": { "text": "Distance shouldn't matter morally. A child in another country is equally real and equally dying.", "visual": "âœˆï¸" },
        "climax": { "text": "Singer argues we're morally obligated to give until it hurts. Few actually do â€” and that's the dilemma.", "visual": "ğŸ’¸" },
        "punchline": { "text": "The child in the pond is everywhere.", "visual": "ğŸ‘¶" }
      },
      "quiz": {
        "question": "What is Singer's main argument in the drowning child thought experiment?",
        "options": ["Distance shouldn't change our moral obligations", "We should only help people nearby", "Charity is always optional"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch05-moral-dilemmas",
      "title": "Lying to Save a Life",
      "story": {
        "hook": { "text": "A killer asks if your friend is hiding inside. Should you lie?", "visual": "ğŸšª" },
        "buildup": { "text": "Most people say obviously yes. But Kant said no â€” lying is always wrong, even here.", "visual": "ğŸ“œ" },
        "discovery": { "text": "His reasoning: if lying became universal, no one would believe anyone and communication collapses.", "visual": "ğŸ”‡" },
        "twist": { "text": "Critics say Kant's rigidity costs lives. Surely morality must be flexible enough to save your friend.", "visual": "ğŸ”“" },
        "climax": { "text": "This dilemma exposes the limits of rule-based ethics. Sometimes the right thing breaks a rule.", "visual": "ğŸ’”" },
        "punchline": { "text": "Rules that can't bend sometimes break people.", "visual": "âš¡" }
      },
      "quiz": {
        "question": "Why did Kant believe lying is always wrong?",
        "options": ["If everyone lied, trust and communication would collapse", "Because God forbids it", "Because lies always cause more harm"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch05-moral-dilemmas",
      "title": "The Repugnant Conclusion",
      "story": {
        "hook": { "text": "Would a world of ten billion barely happy people be better than one billion very happy people?", "visual": "ğŸŒ" },
        "buildup": { "text": "Derek Parfit showed that total utilitarianism leads to this: more people at a lower quality wins.", "visual": "ğŸ“‰" },
        "discovery": { "text": "As long as each life is barely worth living, adding more lives increases total happiness.", "visual": "â•" },
        "twist": { "text": "Parfit called this 'the repugnant conclusion' because it offends our deepest intuitions about quality.", "visual": "ğŸ˜–" },
        "climax": { "text": "No philosopher has fully solved it. It haunts population ethics, climate policy, and future planning.", "visual": "ğŸŒ«ï¸" },
        "punchline": { "text": "More happiness or better happiness? You can't have both.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "What is Parfit's 'repugnant conclusion'?",
        "options": ["A huge population barely worth living beats a small happy one", "Happiness is impossible to achieve", "Ethics should ignore population size"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch05-moral-dilemmas",
      "title": "Moral Luck",
      "story": {
        "hook": { "text": "Two drivers text while driving. One arrives safely. The other hits a child. Same action, different blame.", "visual": "ğŸ“±" },
        "buildup": { "text": "Thomas Nagel called this 'moral luck' â€” factors beyond your control affecting your moral standing.", "visual": "ğŸ²" },
        "discovery": { "text": "We judge the unlucky driver far more harshly, even though both took the same reckless risk.", "visual": "âš–ï¸" },
        "twist": { "text": "It goes deeper. Your upbringing, genes, and circumstances shape your character â€” and you didn't choose those.", "visual": "ğŸ§¬" },
        "climax": { "text": "If so much of morality depends on luck, can we fairly praise or blame anyone for anything?", "visual": "ğŸ¤·" },
        "punchline": { "text": "Luck shouldn't matter morally. But it does.", "visual": "ğŸ€" }
      },
      "quiz": {
        "question": "What did Thomas Nagel mean by 'moral luck'?",
        "options": ["Uncontrollable factors that affect moral judgment", "Being born into a good family", "Winning the lottery and donating it"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
      "title": "Animal Rights",
      "story": {
        "hook": { "text": "A pig is as smart as a three-year-old child. Does it deserve moral consideration?", "visual": "ğŸ·" },
        "buildup": { "text": "Jeremy Bentham asked the key question: 'Can they suffer?' Not 'Can they reason?' or 'Can they talk?'", "visual": "ğŸ’¬" },
        "discovery": { "text": "Peter Singer argues that ignoring animal suffering is 'speciesism' â€” bias based purely on species.", "visual": "ğŸ¾" },
        "twist": { "text": "But drawing the line is hard. Do insects count? Bacteria? Where does moral consideration start?", "visual": "ğŸœ" },
        "climax": { "text": "Factory farming causes immense suffering. The ethical case against it grows stronger every decade.", "visual": "ğŸ­" },
        "punchline": { "text": "The question isn't can they think. It's can they suffer.", "visual": "â¤ï¸" }
      },
      "quiz": {
        "question": "What criterion did Bentham suggest for moral consideration?",
        "options": ["The capacity to suffer", "The ability to reason", "The ability to communicate"],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
      "title": "The Ethics of Punishment",
      "story": {
        "hook": { "text": "A man steals bread to feed his starving family. Should he go to prison?", "visual": "ğŸ" },
        "buildup": { "text": "Retributivists say yes â€” crime deserves punishment, regardless of the reason.", "visual": "âš–ï¸" },
        "discovery": { "text": "Consequentialists ask: does punishment actually reduce future crime? If not, it's just revenge.", "visual": "ğŸ”®" },
        "twist": { "text": "Restorative justice tries a third path â€” healing victims and reintegrating offenders into society.", "visual": "ğŸ¤" },
        "climax": { "text": "The prison system in most countries is neither purely retributive nor purely rehabilitative. It's a mess.", "visual": "ğŸšï¸" },
        "punchline": { "text": "We punish to balance scales. We're bad at holding the scale.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "What does restorative justice focus on?",
        "options": ["Healing victims and reintegrating offenders", "Maximum punishment", "Isolating all criminals permanently"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
      "title": "Is War Ever Just?",
      "story": {
        "hook": { "text": "World War II stopped the Holocaust. But it killed seventy million people. Was it justified?", "visual": "âš”ï¸" },
        "buildup": { "text": "Just War Theory sets strict conditions: the cause must be just, war must be a last resort, and civilians spared.", "visual": "ğŸ“œ" },
        "discovery": { "text": "Augustine and Aquinas developed these rules. A war can be moral if it prevents greater evil.", "visual": "ğŸ›¡ï¸" },
        "twist": { "text": "But 'last resort' is subjective. Governments claim necessity while alternatives may still exist.", "visual": "ğŸ­" },
        "climax": { "text": "Pacifists reject all war. Realists say morality doesn't apply in conflict. Most people land in between.", "visual": "ğŸ•Šï¸" },
        "punchline": { "text": "War is sometimes necessary. It's never good.", "visual": "ğŸ–¤" }
      },
      "quiz": {
        "question": "What does Just War Theory require?",
        "options": ["Just cause, last resort, and civilian protection", "Total victory at any cost", "Unanimous global agreement before fighting"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
      "title": "The Ethics of AI",
      "story": {
        "hook": { "text": "A self-driving car must choose: hit one pedestrian or swerve into a wall, killing the passenger.", "visual": "ğŸš—" },
        "buildup": { "text": "AI systems make decisions that used to require moral judgment. But they follow code, not conscience.", "visual": "ğŸ¤–" },
        "discovery": { "text": "Bias in training data means AI can discriminate by race, gender, or income â€” at massive scale.", "visual": "ğŸ“Š" },
        "twist": { "text": "Who's responsible when AI causes harm? The programmer? The company? The algorithm itself?", "visual": "â“" },
        "climax": { "text": "As AI grows more powerful, the ethical stakes rise. Philosophy is no longer optional for engineers.", "visual": "âš¡" },
        "punchline": { "text": "We taught machines to think. Not yet to care.", "visual": "ğŸ’”" }
      },
      "quiz": {
        "question": "What is a major ethical concern with AI decision-making?",
        "options": ["Bias in training data can cause discrimination at scale", "AI is always perfectly fair", "Only humans make mistakes"],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "philosophy--ethics-and-morality--ch06-applied-ethics",
      "title": "Climate Ethics",
      "story": {
        "hook": { "text": "Future generations will suffer from our carbon emissions. But they don't exist yet. Do they have rights?", "visual": "ğŸŒ¡ï¸" },
        "buildup": { "text": "Climate change raises a unique moral challenge: the people most harmed are those not yet born.", "visual": "ğŸ‘¶" },
        "discovery": { "text": "Some argue we owe future people the same consideration as present ones. Discounting them is unjust.", "visual": "âš–ï¸" },
        "twist": { "text": "The poorest countries suffer most from emissions they didn't produce. Geography becomes moral destiny.", "visual": "ğŸŒ" },
        "climax": { "text": "Climate ethics asks: who pays, how much, and for whom? No framework has a satisfying answer yet.", "visual": "ğŸ’°" },
        "punchline": { "text": "The hardest part is caring about people you'll never meet.", "visual": "ğŸŒ±" }
      },
      "quiz": {
        "question": "Why is climate change an especially difficult ethical issue?",
        "options": ["It harms future generations who can't advocate for themselves", "It only affects wealthy nations", "It has no moral dimensions"],
        "correct": 0
      },
      "is_free": false
    }
  ]
}
