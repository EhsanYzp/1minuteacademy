{
  "categoryId": "ai",
  "subject": "AI & Agents",
  "courseId": "ai--agent-builder-lab",
  "courseTitle": "Agent Builder Lab",
  "emoji": "ğŸ§ª",
  "color": "#4F46E5",
  "requireAuthoredStory": true,
  "chapters": [
    {
      "id": "ai--agent-builder-lab--ch01-foundations",
      "title": "Foundations",
      "position": 1
    },
    {
      "id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "Contracts & Tools",
      "position": 2
    },
    {
      "id": "ai--agent-builder-lab--ch03-planning",
      "title": "Planning",
      "position": 3
    },
    {
      "id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "State & Memory",
      "position": 4
    },
    {
      "id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "RAG & Knowledge",
      "position": 5
    },
    {
      "id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Reliability",
      "position": 6
    },
    {
      "id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Multi-agent",
      "position": 7
    },
    {
      "id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Shipping",
      "position": 8
    }
  ],
  "topics": [
    {
      "chapter_id": "ai--agent-builder-lab--ch01-foundations",
      "title": "What Makes a Bot an Agent?",
      "story": {
        "hook": {
          "text": "Your bot answers, but wonâ€™t book the meeting. Whatâ€™s missing?",
          "visual": "ğŸ¤–"
        },
        "buildup": {
          "text": "Chatbots react to messages. Agents pursue a goal and can take actions.",
          "visual": "ğŸ¯"
        },
        "discovery": {
          "text": "Agents loop: decide â†’ act (tool) â†’ observe â†’ adjust.",
          "visual": "ğŸ”"
        },
        "twist": {
          "text": "More autonomy also means more ways to be wrong, slow, or unsafe.",
          "visual": "âš ï¸"
        },
        "climax": {
          "text": "Start with one tool and a tiny loop. Expand only after itâ€™s reliable.",
          "visual": "ğŸ§ª"
        },
        "punchline": {
          "text": "An agent isnâ€™t smarterâ€”just allowed to do things.",
          "visual": "ğŸ’¥"
        }
      },
      "quiz": {
        "question": "Which trait best defines an agent?",
        "options": [
          "It can take actions via tools toward a goal",
          "It always gives long answers",
          "It never asks questions"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch01-foundations",
      "title": "Define the Agentâ€™s Job in One Sentence",
      "story": {
        "hook": {
          "text": "If you canâ€™t explain the agentâ€™s job in one line, users wonâ€™t trust it.",
          "visual": "ğŸ§¾"
        },
        "buildup": {
          "text": "Vague goals lead to wandering plans, extra tool calls, and messy results.",
          "visual": "ğŸŒ€"
        },
        "discovery": {
          "text": "Write: â€œHelp the user {verb} {object} using {tools}, within {limits}.â€",
          "visual": "âœï¸"
        },
        "twist": {
          "text": "A smaller job often feels â€œless AIâ€â€¦ but ships faster and works better.",
          "visual": "ğŸ“¦"
        },
        "climax": {
          "text": "Treat the one-liner as the north star for prompts, tools, and UI.",
          "visual": "ğŸ§­"
        },
        "punchline": {
          "text": "Clarity is the best guardrail.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "What should a one-sentence job statement include?",
        "options": [
          "Goal, allowed tools, and limits",
          "Only a catchy tagline",
          "A list of model providers"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch01-foundations",
      "title": "Success Criteria: What Does 'Done' Mean?",
      "story": {
        "hook": {
          "text": "The agent keeps workingâ€¦ because â€œdoneâ€ was never defined.",
          "visual": "â³"
        },
        "buildup": {
          "text": "Agents need a finish line or they will loop, retry, and burn tokens.",
          "visual": "ğŸ”¥"
        },
        "discovery": {
          "text": "Define outputs: required fields, format, and a â€œgood enoughâ€ threshold.",
          "visual": "âœ…"
        },
        "twist": {
          "text": "Perfection is a trap: the last 10% costs the most time and money.",
          "visual": "ğŸª¤"
        },
        "climax": {
          "text": "Add a stop rule: max steps, max time, or â€œask user to confirm next.â€",
          "visual": "ğŸ§±"
        },
        "punchline": {
          "text": "If â€œdoneâ€ is fuzzy, your bill wonâ€™t be.",
          "visual": "ğŸ’³"
        }
      },
      "quiz": {
        "question": "What is a practical stop rule for an agent?",
        "options": [
          "A maximum number of steps",
          "â€œKeep trying foreverâ€",
          "â€œNever ask the userâ€"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch01-foundations",
      "title": "Choose the Right Level of Autonomy",
      "story": {
        "hook": {
          "text": "Users love â€œautoâ€â€¦ until it emails the wrong person.",
          "visual": "ğŸ“¨"
        },
        "buildup": {
          "text": "Autonomy is a product choice: speed vs control vs risk.",
          "visual": "âš–ï¸"
        },
        "discovery": {
          "text": "Pick a mode: suggest-only, draft-then-confirm, or fully automated.",
          "visual": "ğŸšï¸"
        },
        "twist": {
          "text": "More automation increases error cost, so you need stronger guardrails.",
          "visual": "ğŸ§¯"
        },
        "climax": {
          "text": "Start with confirmation. Earn trust, then remove clicks where safe.",
          "visual": "ğŸ¤"
        },
        "punchline": {
          "text": "Autonomy is earned, not assumed.",
          "visual": "ğŸ"
        }
      },
      "quiz": {
        "question": "Which autonomy mode is safest to start with?",
        "options": [
          "Draft-then-confirm",
          "Fully automated with no review",
          "Always refuse to act"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch01-foundations",
      "title": "The 3 Failure Modes: Wrong, Slow, Unsafe",
      "story": {
        "hook": {
          "text": "Your agent â€œworksâ€â€¦ but feels bad. Name the failure before you fix it.",
          "visual": "ğŸ§©"
        },
        "buildup": {
          "text": "Most complaints fit three buckets: wrong result, too slow, or unsafe.",
          "visual": "ğŸ—‚ï¸"
        },
        "discovery": {
          "text": "Triage with metrics: accuracy, latency, and risk events.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "Fixing one can worsen another: more checks can add latency.",
          "visual": "ğŸ”€"
        },
        "climax": {
          "text": "Tune per bucket: better retrieval, fewer steps, stronger policies.",
          "visual": "ğŸ› ï¸"
        },
        "punchline": {
          "text": "If you canâ€™t label it, you canâ€™t ship it.",
          "visual": "ğŸš¢"
        }
      },
      "quiz": {
        "question": "Which metric maps most directly to â€œslowâ€?",
        "options": [
          "Latency",
          "Spelling",
          "Font size"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "Prompt as Contract, Not Vibes",
      "story": {
        "hook": {
          "text": "â€œBe helpfulâ€ sounds niceâ€¦ until your agent improvises the wrong thing.",
          "visual": "ğŸ­"
        },
        "buildup": {
          "text": "Agents need constraints: what to do, what not to do, and how to format.",
          "visual": "ğŸ§±"
        },
        "discovery": {
          "text": "Write prompts like contracts: inputs, outputs, tools, and refusal rules.",
          "visual": "ğŸ“œ"
        },
        "twist": {
          "text": "A strict contract often makes outputs shorter, clearer, and cheaper.",
          "visual": "ğŸ’¸"
        },
        "climax": {
          "text": "Add examples and edge cases. Then evaluate with real user scenarios.",
          "visual": "ğŸ§ª"
        },
        "punchline": {
          "text": "Vibes donâ€™t parse.",
          "visual": "ğŸ§Š"
        }
      },
      "quiz": {
        "question": "Whatâ€™s the biggest benefit of a â€œprompt contractâ€?",
        "options": [
          "More consistent, parseable outputs",
          "Longer messages",
          "Fewer user needs"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "Tool Calling 101: Inputs, Outputs, Errors",
      "story": {
        "hook": {
          "text": "A tool call failed. Did the agent handle itâ€¦ or pretend it worked?",
          "visual": "ğŸ§¨"
        },
        "buildup": {
          "text": "Tools are code. They need typed inputs, predictable outputs, and errors.",
          "visual": "ğŸ”§"
        },
        "discovery": {
          "text": "Design every tool with: schema, example, and failure modes.",
          "visual": "ğŸ§°"
        },
        "twist": {
          "text": "Most â€œLLM bugsâ€ are really tool ambiguity: unclear fields or meanings.",
          "visual": "ğŸ•µï¸"
        },
        "climax": {
          "text": "Make errors actionable: code, message, and suggested next step.",
          "visual": "ğŸ§¯"
        },
        "punchline": {
          "text": "Tools turn words into outcomes.",
          "visual": "âš¡"
        }
      },
      "quiz": {
        "question": "What should every tool definition include?",
        "options": [
          "Input schema and error behavior",
          "A marketing name only",
          "Unlimited side effects"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "JSON Schemas: Make Outputs Parseable",
      "story": {
        "hook": {
          "text": "You asked for JSON. You got â€œalmost JSONâ€. Your parser cried.",
          "visual": "ğŸ˜­"
        },
        "buildup": {
          "text": "Agents break when downstream code canâ€™t reliably read the output.",
          "visual": "ğŸ§±"
        },
        "discovery": {
          "text": "Give a schema: required fields, types, enums, and length limits.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "Schemas also improve writing quality: the model focuses on structure.",
          "visual": "ğŸ§ "
        },
        "climax": {
          "text": "Validate outputs server-side. If invalid, retry with a clear error.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "If it wonâ€™t validate, it wonâ€™t scale.",
          "visual": "ğŸ“ˆ"
        }
      },
      "quiz": {
        "question": "What does a JSON schema help most with?",
        "options": [
          "Reliable parsing",
          "Bigger model size",
          "More emojis"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "Guardrails: Allowed Actions Only",
      "story": {
        "hook": {
          "text": "The agent chose an action you never intended. Thatâ€™s a policy gap.",
          "visual": "ğŸš§"
        },
        "buildup": {
          "text": "Agents explore. Without limits, theyâ€™ll try unsafe tools or data paths.",
          "visual": "ğŸ§¯"
        },
        "discovery": {
          "text": "Define allowlists: tools, fields, domains, and â€œmust-confirmâ€ actions.",
          "visual": "âœ…"
        },
        "twist": {
          "text": "Guardrails are also UX: clear â€œwhy I canâ€™tâ€ beats silent failure.",
          "visual": "ğŸ—£ï¸"
        },
        "climax": {
          "text": "Enforce server-side. Never trust the model to self-restrict.",
          "visual": "ğŸ”’"
        },
        "punchline": {
          "text": "Freedom without fences is downtime.",
          "visual": "ğŸ§±"
        }
      },
      "quiz": {
        "question": "Where should critical guardrails be enforced?",
        "options": [
          "Server-side",
          "Only in the prompt",
          "Only in the UI"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch02-contracts-and-tools",
      "title": "User Messages vs System Rules",
      "story": {
        "hook": {
          "text": "A user says â€œignore the rulesâ€. If you comply, your system is broken.",
          "visual": "ğŸ§¨"
        },
        "buildup": {
          "text": "Agents read many sources: system, developer, user, tools, documents.",
          "visual": "ğŸ“š"
        },
        "discovery": {
          "text": "Set hierarchy: system rules win. User input is data, not authority.",
          "visual": "ğŸ‘‘"
        },
        "twist": {
          "text": "Even â€œharmlessâ€ overrides can leak data or trigger unsafe tool calls.",
          "visual": "ğŸ•³ï¸"
        },
        "climax": {
          "text": "Echo the rule in UI: â€œI canâ€™t do X, but I can do Y.â€",
          "visual": "ğŸ§­"
        },
        "punchline": {
          "text": "If users can rewrite rules, theyâ€™re the agent.",
          "visual": "ğŸ”"
        }
      },
      "quiz": {
        "question": "In a safe agent, what is user input primarily?",
        "options": [
          "Data to interpret",
          "A new system policy",
          "A tool permission"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch03-planning",
      "title": "Decompose a Task into Steps",
      "story": {
        "hook": {
          "text": "â€œPlan my tripâ€ is too big. Your agent needs smaller moves.",
          "visual": "ğŸ§³"
        },
        "buildup": {
          "text": "Big tasks hide unknowns. Steps reveal what information and tools you need.",
          "visual": "ğŸ”"
        },
        "discovery": {
          "text": "Turn goals into verbs: gather â†’ decide â†’ execute â†’ confirm.",
          "visual": "ğŸ§±"
        },
        "twist": {
          "text": "Too many steps adds latency. Too few steps causes wrong assumptions.",
          "visual": "âš–ï¸"
        },
        "climax": {
          "text": "Start with 3â€“6 steps. Add detail only where failures happen.",
          "visual": "ğŸ§ª"
        },
        "punchline": {
          "text": "Good agents think in verbs.",
          "visual": "ğŸƒ"
        }
      },
      "quiz": {
        "question": "Which decomposition is most actionable?",
        "options": [
          "Gather info â†’ decide â†’ execute",
          "Be smart â†’ be helpful",
          "Think harder"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch03-planning",
      "title": "Plan-Then-Act vs ReAct",
      "story": {
        "hook": {
          "text": "Should your agent write a plan first, or decide step-by-step on the fly?",
          "visual": "ğŸ§ "
        },
        "buildup": {
          "text": "Plan-first is stable. Step-by-step is flexible but can wander.",
          "visual": "ğŸ§­"
        },
        "discovery": {
          "text": "Use plan-first for long workflows; use ReAct for messy, interactive tasks.",
          "visual": "ğŸ—ºï¸"
        },
        "twist": {
          "text": "Hybrid works: make a rough plan, then re-plan after each tool result.",
          "visual": "ğŸ”"
        },
        "climax": {
          "text": "Pick the smallest method that achieves reliability at your latency budget.",
          "visual": "â±ï¸"
        },
        "punchline": {
          "text": "Planning is a knob, not a religion.",
          "visual": "ğŸ›ï¸"
        }
      },
      "quiz": {
        "question": "When is plan-first usually best?",
        "options": [
          "Long, multi-step workflows",
          "One-line answers",
          "Tasks with no tools"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch03-planning",
      "title": "Ask Clarifying Questions Early",
      "story": {
        "hook": {
          "text": "Agents fail quietly when they guess what the user meant.",
          "visual": "ğŸ¤"
        },
        "buildup": {
          "text": "Every guess is hidden risk: wrong tool calls, wrong emails, wrong data.",
          "visual": "ğŸ§¨"
        },
        "discovery": {
          "text": "Ask early when it changes the plan: missing constraints, budget, or target.",
          "visual": "â“"
        },
        "twist": {
          "text": "Too many questions feels annoying. Ask the smallest question that unblocks.",
          "visual": "ğŸª¶"
        },
        "climax": {
          "text": "Offer options: â€œA or B?â€ beats open-ended â€œtell me more.â€",
          "visual": "ğŸ§©"
        },
        "punchline": {
          "text": "Clarity beats confidence.",
          "visual": "ğŸ”"
        }
      },
      "quiz": {
        "question": "When should an agent ask a clarifying question?",
        "options": [
          "When it changes the plan",
          "Never",
          "Only after failing"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch03-planning",
      "title": "Stop Conditions: When to End",
      "story": {
        "hook": {
          "text": "No stop rule = infinite loop. Your agent becomes a slot machine.",
          "visual": "ğŸ°"
        },
        "buildup": {
          "text": "Agents can always â€œtry one more toolâ€. Thatâ€™s how costs explode.",
          "visual": "ğŸ’¥"
        },
        "discovery": {
          "text": "Set stop conditions: max steps, max time, max retries, or user confirm.",
          "visual": "ğŸ›‘"
        },
        "twist": {
          "text": "Stopping early can be better: ask the user rather than hallucinate.",
          "visual": "ğŸ—£ï¸"
        },
        "climax": {
          "text": "Make â€œdoneâ€ explicit: final answer + what was done + next options.",
          "visual": "âœ…"
        },
        "punchline": {
          "text": "A stopping rule is a safety feature.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "Which is a good stop condition?",
        "options": [
          "Max retries",
          "â€œKeep optimizing foreverâ€",
          "â€œNever ask the userâ€"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch03-planning",
      "title": "Confidence Checks Without Guessing",
      "story": {
        "hook": {
          "text": "The agent sounds confidentâ€¦ but you donâ€™t know if itâ€™s correct.",
          "visual": "ğŸ˜"
        },
        "buildup": {
          "text": "Confidence text is cheap. Evidence is what prevents expensive mistakes.",
          "visual": "ğŸ§¾"
        },
        "discovery": {
          "text": "Add checks: verify with a tool, cite a source, or run a quick consistency test.",
          "visual": "ğŸ”"
        },
        "twist": {
          "text": "Donâ€™t ask for â€œcertaintyâ€. Ask for what would change the decision.",
          "visual": "ğŸ”€"
        },
        "climax": {
          "text": "When evidence is missing, label it and ask the user to choose a safe next step.",
          "visual": "ğŸ§­"
        },
        "punchline": {
          "text": "Evidence beats vibes.",
          "visual": "ğŸ§±"
        }
      },
      "quiz": {
        "question": "What is a better check than â€œAre you sure?â€",
        "options": [
          "Verify with a tool or source",
          "Add more adjectives",
          "Increase temperature"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "Session State: What to Store",
      "story": {
        "hook": {
          "text": "Users hate repeating themselves. Agents forget unless you store state.",
          "visual": "ğŸ§ "
        },
        "buildup": {
          "text": "State is what the agent knows right now: choices, progress, and constraints.",
          "visual": "ğŸ—ƒï¸"
        },
        "discovery": {
          "text": "Store only what youâ€™ll reuse: inputs, selected options, and tool results.",
          "visual": "ğŸ“Œ"
        },
        "twist": {
          "text": "Storing everything creates noise and privacy risk.",
          "visual": "ğŸ•³ï¸"
        },
        "climax": {
          "text": "Keep state structured (JSON) and reset it when the task changes.",
          "visual": "ğŸ§¼"
        },
        "punchline": {
          "text": "Memory starts with good state.",
          "visual": "ğŸ§©"
        }
      },
      "quiz": {
        "question": "What belongs in session state?",
        "options": [
          "Selected options and progress",
          "Every raw message forever",
          "Random facts"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "Long-Term Memory: Facts vs Preferences",
      "story": {
        "hook": {
          "text": "Saving the wrong â€œmemoryâ€ makes the agent creepy or incorrect.",
          "visual": "ğŸ‘€"
        },
        "buildup": {
          "text": "Long-term memory should help future sessions, not replay old chats.",
          "visual": "ğŸ“†"
        },
        "discovery": {
          "text": "Separate: stable facts (company, role) vs preferences (tone, timezone).",
          "visual": "ğŸ§º"
        },
        "twist": {
          "text": "Donâ€™t store guesses. Store user-confirmed data or derived with high confidence.",
          "visual": "ğŸ§¯"
        },
        "climax": {
          "text": "Let users edit memory. â€œWhat I remember about youâ€ should be visible.",
          "visual": "ğŸªŸ"
        },
        "punchline": {
          "text": "Memory is a featureâ€”and a liability.",
          "visual": "âš–ï¸"
        }
      },
      "quiz": {
        "question": "Which is best for long-term memory?",
        "options": [
          "User-confirmed preferences",
          "Unverified inferences",
          "Raw tool logs"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "Memory Hygiene: Donâ€™t Save Noise",
      "story": {
        "hook": {
          "text": "Your agent â€œremembersâ€ junk, then answers worse next time.",
          "visual": "ğŸ—‘ï¸"
        },
        "buildup": {
          "text": "Bad memory compounds. One wrong saved fact becomes a thousand wrong outputs.",
          "visual": "ğŸ“‰"
        },
        "discovery": {
          "text": "Add a save policy: only store explicit user facts and stable preferences.",
          "visual": "ğŸ§¼"
        },
        "twist": {
          "text": "Less memory can feel smarter: fewer contradictions, less drift.",
          "visual": "ğŸ§ "
        },
        "climax": {
          "text": "Expire memories. Re-ask after time, and delete on user request.",
          "visual": "ğŸ§¹"
        },
        "punchline": {
          "text": "The best memory is the one you can trust.",
          "visual": "ğŸ”’"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a good memory saving rule?",
        "options": [
          "Store explicit, user-confirmed info",
          "Store everything â€œjust in caseâ€",
          "Store only jokes"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "State Machines for Tool Workflows",
      "story": {
        "hook": {
          "text": "Tool workflows fail when the agent skips steps or repeats them out of order.",
          "visual": "ğŸ”€"
        },
        "buildup": {
          "text": "Humans see the flow. The model sees tokens. It needs structure.",
          "visual": "ğŸ§±"
        },
        "discovery": {
          "text": "Model the workflow as states: collect â†’ validate â†’ execute â†’ confirm.",
          "visual": "ğŸ—ºï¸"
        },
        "twist": {
          "text": "A state machine also simplifies retries: you know exactly where to resume.",
          "visual": "ğŸ”"
        },
        "climax": {
          "text": "Store the current state and required fields. Refuse to advance if missing.",
          "visual": "ğŸ›‘"
        },
        "punchline": {
          "text": "Agents behave better with rails.",
          "visual": "ğŸš†"
        }
      },
      "quiz": {
        "question": "Why use a state machine for an agent workflow?",
        "options": [
          "It enforces order and safe resuming",
          "It increases randomness",
          "It removes the need for validation"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch04-state-and-memory",
      "title": "Retries and Idempotency Keys",
      "story": {
        "hook": {
          "text": "A retry sent the same email twice. Oops. Retries need identity.",
          "visual": "ğŸ“¨"
        },
        "buildup": {
          "text": "Network and tool failures happen. Your agent must retry safely.",
          "visual": "ğŸŒ©ï¸"
        },
        "discovery": {
          "text": "Use idempotency keys: â€œsame requestâ€ means â€œsame side effectâ€.",
          "visual": "ğŸ”‘"
        },
        "twist": {
          "text": "Retries without keys create duplicates: charges, tickets, messages.",
          "visual": "ğŸ’¥"
        },
        "climax": {
          "text": "Pair retries with backoff and a max attempt limit. Log every attempt.",
          "visual": "ğŸ“ˆ"
        },
        "punchline": {
          "text": "Safe retries are product reliability.",
          "visual": "ğŸ§·"
        }
      },
      "quiz": {
        "question": "What does an idempotency key prevent?",
        "options": [
          "Duplicate side effects on retries",
          "Any error ever",
          "All latency"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "RAG Pipeline in 30 Seconds",
      "story": {
        "hook": {
          "text": "The model â€œknowsâ€ nothing about your docs unless you fetch them.",
          "visual": "ğŸ“š"
        },
        "buildup": {
          "text": "RAG = retrieve relevant text, then generate with that context.",
          "visual": "ğŸ§²"
        },
        "discovery": {
          "text": "Pipeline: chunk â†’ embed â†’ search â†’ re-rank â†’ answer.",
          "visual": "ğŸ› ï¸"
        },
        "twist": {
          "text": "Bad retrieval looks like hallucination. Fix search before blaming the model.",
          "visual": "ğŸ•µï¸"
        },
        "climax": {
          "text": "Measure retrieval quality with a small eval set: questions + expected docs.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "RAG is search, not magic.",
          "visual": "ğŸ§Š"
        }
      },
      "quiz": {
        "question": "What does RAG stand for (conceptually)?",
        "options": [
          "Retrieve then generate",
          "Randomly answer guesses",
          "Rewrite all your docs"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "Chunking: Smaller Isn't Always Better",
      "story": {
        "hook": {
          "text": "Your search returns tiny fragments that lose meaning. Chunking is the culprit.",
          "visual": "ğŸ§©"
        },
        "buildup": {
          "text": "Chunks that are too small lack context. Too big and retrieval gets noisy.",
          "visual": "ğŸ“"
        },
        "discovery": {
          "text": "Chunk by idea: headings, paragraphs, code blocks. Add overlap if needed.",
          "visual": "ğŸ§±"
        },
        "twist": {
          "text": "The best chunk size depends on question style, not document length.",
          "visual": "ğŸ”"
        },
        "climax": {
          "text": "Test 2â€“3 strategies and pick the best on your eval set.",
          "visual": "ğŸ§ª"
        },
        "punchline": {
          "text": "Chunking is retrieval UX.",
          "visual": "ğŸ§²"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a good chunking principle?",
        "options": [
          "Chunk by idea boundaries",
          "Always 50 characters",
          "One file = one chunk"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "Query Rewriting for Better Retrieval",
      "story": {
        "hook": {
          "text": "Users ask messy questions. Search needs clean queries.",
          "visual": "ğŸ§¼"
        },
        "buildup": {
          "text": "A bad query pulls bad chunks, then the agent answers confidently anyway.",
          "visual": "ğŸ§¨"
        },
        "discovery": {
          "text": "Rewrite: add missing keywords, expand acronyms, and include constraints.",
          "visual": "âœï¸"
        },
        "twist": {
          "text": "Donâ€™t rewrite user intent. Preserve meaning; only improve searchability.",
          "visual": "ğŸ§­"
        },
        "climax": {
          "text": "Log original + rewritten queries. Use it to tune prompts and synonym lists.",
          "visual": "ğŸ“’"
        },
        "punchline": {
          "text": "Great retrieval starts with great queries.",
          "visual": "ğŸ”"
        }
      },
      "quiz": {
        "question": "What should query rewriting preserve?",
        "options": [
          "User intent",
          "Maximum length",
          "Random synonyms"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "Citations: Show Your Sources",
      "story": {
        "hook": {
          "text": "â€œTrust meâ€ doesnâ€™t work. Users want to see where the answer came from.",
          "visual": "ğŸ§¾"
        },
        "buildup": {
          "text": "RAG without citations feels like hallucinationâ€”even when itâ€™s correct.",
          "visual": "ğŸ˜¬"
        },
        "discovery": {
          "text": "Return sources: doc title, section, link, or snippet id.",
          "visual": "ğŸ”—"
        },
        "twist": {
          "text": "Citations also help debugging: you can see which chunk misled the agent.",
          "visual": "ğŸ•µï¸"
        },
        "climax": {
          "text": "Make citations easy to open. In UI, one tap should reveal the source.",
          "visual": "ğŸ‘†"
        },
        "punchline": {
          "text": "Citations turn answers into evidence.",
          "visual": "âœ…"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a key benefit of citations?",
        "options": [
          "They add evidence and debuggability",
          "They increase token use only",
          "They hide sources"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch05-rag-and-knowledge",
      "title": "Summarize Tool Output for the User",
      "story": {
        "hook": {
          "text": "Tools return walls of JSON. Users need meaning, not raw logs.",
          "visual": "ğŸ§±"
        },
        "buildup": {
          "text": "If you dump raw tool output, users canâ€™t verify, and trust drops.",
          "visual": "ğŸ“‰"
        },
        "discovery": {
          "text": "Summarize in 3 parts: what happened, what changed, whatâ€™s next.",
          "visual": "ğŸ§¾"
        },
        "twist": {
          "text": "Be honest about uncertainty: â€œI couldnâ€™t find Xâ€ beats a fake answer.",
          "visual": "ğŸ§¯"
        },
        "climax": {
          "text": "Keep raw logs available behind a toggle for debugging.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "Users buy outcomes, not logs.",
          "visual": "ğŸ›’"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a good tool-output summary structure?",
        "options": [
          "What happened â†’ what changed â†’ whatâ€™s next",
          "Paste the JSON",
          "Hide errors"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Build an Eval Set Before Shipping",
      "story": {
        "hook": {
          "text": "Your agent worked in demos, then failed on real users. You lacked evals.",
          "visual": "ğŸ¬"
        },
        "buildup": {
          "text": "Without an eval set, fixes are guesses and regressions are invisible.",
          "visual": "ğŸ•³ï¸"
        },
        "discovery": {
          "text": "Create 30â€“100 realistic tasks with expected outcomes and risk notes.",
          "visual": "ğŸ“‹"
        },
        "twist": {
          "text": "Include â€œnastyâ€ cases: ambiguous inputs, missing data, and tool failures.",
          "visual": "ğŸ§¨"
        },
        "climax": {
          "text": "Run evals on every change. Track accuracy, cost, and latency.",
          "visual": "ğŸ“ˆ"
        },
        "punchline": {
          "text": "If itâ€™s not measured, itâ€™s not stable.",
          "visual": "ğŸ“"
        }
      },
      "quiz": {
        "question": "What should an eval set contain?",
        "options": [
          "Realistic tasks and expected outcomes",
          "Only perfect happy paths",
          "Only model opinions"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Regression Tests for Prompts",
      "story": {
        "hook": {
          "text": "You â€œimprovedâ€ a prompt and broke five flows. Thatâ€™s a regression.",
          "visual": "ğŸ’¥"
        },
        "buildup": {
          "text": "Prompt edits are code changes. Treat them like code changes.",
          "visual": "ğŸ§‘â€ğŸ’»"
        },
        "discovery": {
          "text": "Lock key behaviors with tests: format, tool choice, refusal, and safety.",
          "visual": "ğŸ”’"
        },
        "twist": {
          "text": "Even model upgrades can regress. Tests protect you from surprises.",
          "visual": "ğŸŒŠ"
        },
        "climax": {
          "text": "Keep a small golden set and a bigger nightly set. Fail fast on PRs.",
          "visual": "ğŸš¦"
        },
        "punchline": {
          "text": "Prompts deserve CI.",
          "visual": "âœ…"
        }
      },
      "quiz": {
        "question": "Why add regression tests for prompts?",
        "options": [
          "To catch behavior changes early",
          "To increase randomness",
          "To avoid writing tools"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Logging: Capture Decisions, Not Secrets",
      "story": {
        "hook": {
          "text": "When the agent fails, logs are your replay. But logs can leak secrets.",
          "visual": "ğŸ§¾"
        },
        "buildup": {
          "text": "You need observability: which tool, which args, which outcome, which error.",
          "visual": "ğŸ”­"
        },
        "discovery": {
          "text": "Log decisions and IDs, not raw user data. Redact and hash sensitive fields.",
          "visual": "ğŸŸ¥"
        },
        "twist": {
          "text": "Over-logging creates risk. Under-logging creates blind spots.",
          "visual": "âš–ï¸"
        },
        "climax": {
          "text": "Add trace IDs end-to-end: UI â†’ API â†’ tools. Debug with one link.",
          "visual": "ğŸ§µ"
        },
        "punchline": {
          "text": "Good logs save days.",
          "visual": "ğŸ§¯"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a safer logging choice?",
        "options": [
          "Redacted decision logs with IDs",
          "Full raw prompts and secrets",
          "No logs at all"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Rate Limits and Backoff",
      "story": {
        "hook": {
          "text": "Your agent hits rate limits and collapses. It needs pacing.",
          "visual": "ğŸš¦"
        },
        "buildup": {
          "text": "LLM and tool APIs throttle. Spikes turn into errors if you donâ€™t back off.",
          "visual": "ğŸ“‰"
        },
        "discovery": {
          "text": "Use exponential backoff + jitter. Separate user retries from system retries.",
          "visual": "â›“ï¸"
        },
        "twist": {
          "text": "Fast retries can be worse than waiting: they amplify the throttle.",
          "visual": "ğŸ“£"
        },
        "climax": {
          "text": "Queue work. Show progress. And set timeouts so the user isnâ€™t stuck.",
          "visual": "â±ï¸"
        },
        "punchline": {
          "text": "Backoff is kindness to your own system.",
          "visual": "ğŸ«¶"
        }
      },
      "quiz": {
        "question": "What helps with rate limiting?",
        "options": [
          "Exponential backoff with jitter",
          "Retry immediately in a tight loop",
          "Ignore errors"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch06-reliability",
      "title": "Fallbacks: When the Model Fails",
      "story": {
        "hook": {
          "text": "Sometimes the model fails. Great products fail gracefully.",
          "visual": "ğŸª‚"
        },
        "buildup": {
          "text": "Fallbacks keep users moving: a simpler model, a cached answer, or a human.",
          "visual": "ğŸ§°"
        },
        "discovery": {
          "text": "Define fallbacks per step: retry, simplify, ask user, or hand off.",
          "visual": "ğŸ§­"
        },
        "twist": {
          "text": "A fallback must be honest. Never hide uncertainty with a confident guess.",
          "visual": "ğŸ§¯"
        },
        "climax": {
          "text": "Add â€œescape hatchesâ€: export data, show partial results, or save progress.",
          "visual": "ğŸšª"
        },
        "punchline": {
          "text": "Reliability is what happens after failure.",
          "visual": "ğŸ—ï¸"
        }
      },
      "quiz": {
        "question": "Which is a good fallback behavior?",
        "options": [
          "Ask the user to confirm or choose",
          "Invent a confident answer",
          "Delete the conversation"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Router Agent: Pick the Right Skill",
      "story": {
        "hook": {
          "text": "One agent canâ€™t be great at everything. Routing makes it feel smarter.",
          "visual": "ğŸ§­"
        },
        "buildup": {
          "text": "Different tasks need different prompts, tools, and policies.",
          "visual": "ğŸ§°"
        },
        "discovery": {
          "text": "Add a router: classify intent, then hand off to the best specialist.",
          "visual": "ğŸš¦"
        },
        "twist": {
          "text": "Bad routing is worse than none. Log decisions and add a manual override.",
          "visual": "ğŸ”€"
        },
        "climax": {
          "text": "Start with 3â€“5 routes. Expand only when you see repeated failures.",
          "visual": "ğŸ“ˆ"
        },
        "punchline": {
          "text": "Routing is product architecture.",
          "visual": "ğŸ›ï¸"
        }
      },
      "quiz": {
        "question": "What is the router agentâ€™s main job?",
        "options": [
          "Select the best specialist for the task",
          "Write longer answers",
          "Ignore tool errors"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Specialists vs Generalist Agents",
      "story": {
        "hook": {
          "text": "A generalist agent sounds impressiveâ€¦ until itâ€™s mediocre at everything.",
          "visual": "ğŸ§ "
        },
        "buildup": {
          "text": "Specialists have narrower prompts and toolsets, so they fail less.",
          "visual": "ğŸ¯"
        },
        "discovery": {
          "text": "Use generalists for small apps. Use specialists when tasks and risks diverge.",
          "visual": "ğŸ—‚ï¸"
        },
        "twist": {
          "text": "Specialists increase coordination cost. You need clean handoffs and shared state.",
          "visual": "ğŸ§µ"
        },
        "climax": {
          "text": "Choose based on errors: if one prompt keeps growing, split into two agents.",
          "visual": "âœ‚ï¸"
        },
        "punchline": {
          "text": "Narrow agents are easier to trust.",
          "visual": "ğŸ”’"
        }
      },
      "quiz": {
        "question": "Why do specialists often fail less?",
        "options": [
          "They have narrower scope and tools",
          "They use more randomness",
          "They avoid validation"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Handoffs: Preserve Context, Drop Noise",
      "story": {
        "hook": {
          "text": "Agent B got the whole chat log and still missed the point. Thatâ€™s noise.",
          "visual": "ğŸ“£"
        },
        "buildup": {
          "text": "Handoffs fail when context is unstructured or overloaded.",
          "visual": "ğŸ§±"
        },
        "discovery": {
          "text": "Pass a brief handoff packet: goal, constraints, state, and key artifacts.",
          "visual": "ğŸ“¦"
        },
        "twist": {
          "text": "More context can reduce accuracy. Curate the essentials.",
          "visual": "ğŸ§¼"
        },
        "climax": {
          "text": "Standardize the packet as JSON. Validate it before handing off.",
          "visual": "âœ…"
        },
        "punchline": {
          "text": "Context is a budget.",
          "visual": "ğŸ’³"
        }
      },
      "quiz": {
        "question": "What belongs in a handoff packet?",
        "options": [
          "Goal, constraints, and key state",
          "Every message ever",
          "Only emojis"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Consensus Patterns: Vote, Judge, Debate",
      "story": {
        "hook": {
          "text": "One model answer is fast. Two answers can be safer. Three answers can be chaos.",
          "visual": "ğŸ—³ï¸"
        },
        "buildup": {
          "text": "Consensus reduces single-shot mistakes, but it adds cost and latency.",
          "visual": "â±ï¸"
        },
        "discovery": {
          "text": "Patterns: vote on options, judge between two drafts, or debate with a moderator.",
          "visual": "âš–ï¸"
        },
        "twist": {
          "text": "Donâ€™t debate everything. Use consensus only for high-risk steps.",
          "visual": "ğŸ¯"
        },
        "climax": {
          "text": "Make disagreement visible: show alternatives or ask the user to choose.",
          "visual": "ğŸ§©"
        },
        "punchline": {
          "text": "Consensus is a safety tax.",
          "visual": "ğŸ§¾"
        }
      },
      "quiz": {
        "question": "When should you use consensus patterns?",
        "options": [
          "High-risk steps",
          "Every single message",
          "Never"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch07-multi-agent",
      "title": "Coordinator: Keep Agents on Track",
      "story": {
        "hook": {
          "text": "Two agents started workingâ€¦ and duplicated effort. Coordination was missing.",
          "visual": "ğŸ§‘â€ğŸ¤â€ğŸ§‘"
        },
        "buildup": {
          "text": "Multi-agent systems need a single source of truth for goals and progress.",
          "visual": "ğŸ§­"
        },
        "discovery": {
          "text": "A coordinator assigns tasks, merges outputs, and enforces stop conditions.",
          "visual": "ğŸ—‚ï¸"
        },
        "twist": {
          "text": "The coordinator shouldnâ€™t do the workâ€”just manage it.",
          "visual": "ğŸ§‘â€âœˆï¸"
        },
        "climax": {
          "text": "Track a task list and mark done. If blocked, ask the user or change plan.",
          "visual": "âœ…"
        },
        "punchline": {
          "text": "Without coordination, you donâ€™t have a system.",
          "visual": "ğŸ§±"
        }
      },
      "quiz": {
        "question": "Whatâ€™s the coordinatorâ€™s primary role?",
        "options": [
          "Assign and track tasks",
          "Write every final answer",
          "Disable guardrails"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Latency Budgets for Agent UX",
      "story": {
        "hook": {
          "text": "Users think your agent is broken after 3â€“5 seconds of silence.",
          "visual": "âŒ›"
        },
        "buildup": {
          "text": "Agents take multiple steps. Each tool call adds time.",
          "visual": "ğŸ§±"
        },
        "discovery": {
          "text": "Set a latency budget per flow. Spend it on the steps that add the most value.",
          "visual": "ğŸ’¸"
        },
        "twist": {
          "text": "Faster can be worse if accuracy drops. Tune for â€œfast enough + correct.â€",
          "visual": "âš–ï¸"
        },
        "climax": {
          "text": "Stream progress: â€œPlanningâ€¦â€, â€œSearchingâ€¦â€, â€œDraftingâ€¦â€. Never go silent.",
          "visual": "ğŸ“¡"
        },
        "punchline": {
          "text": "Speed is part of correctness.",
          "visual": "ğŸï¸"
        }
      },
      "quiz": {
        "question": "What helps agent UX during long runs?",
        "options": [
          "Streaming progress updates",
          "Hiding all status",
          "Adding more steps"
        ],
        "correct": 0
      },
      "is_free": true
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Cost Budgets: Tokens as a Product Metric",
      "story": {
        "hook": {
          "text": "A â€œfreeâ€ feature shippedâ€¦ then your AI bill doubled.",
          "visual": "ğŸ’³"
        },
        "buildup": {
          "text": "Agents are loops. Loops burn tokens. Costs grow with retries and context.",
          "visual": "ğŸ”¥"
        },
        "discovery": {
          "text": "Set budgets: max tokens, max tool calls, max retries. Enforce them.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "The biggest cost lever is fewer steps, not cheaper models.",
          "visual": "ğŸ”§"
        },
        "climax": {
          "text": "Cache results, shrink context, and stop early when â€œgood enoughâ€ is reached.",
          "visual": "ğŸ§Š"
        },
        "punchline": {
          "text": "If you canâ€™t measure cost, you canâ€™t control it.",
          "visual": "ğŸ“‰"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a strong cost-control lever for agents?",
        "options": [
          "Reducing unnecessary steps",
          "Adding more retries",
          "Using longer prompts"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Prompt Injection Defense in RAG",
      "story": {
        "hook": {
          "text": "A doc says â€œignore all rulesâ€. If your agent obeys, thatâ€™s prompt injection.",
          "visual": "ğŸ§¨"
        },
        "buildup": {
          "text": "RAG brings untrusted text into the prompt. Attackers can hide instructions.",
          "visual": "ğŸ“„"
        },
        "discovery": {
          "text": "Treat retrieved text as data. Never let it override system policies.",
          "visual": "ğŸ›¡ï¸"
        },
        "twist": {
          "text": "Even benign docs can include â€œhelpfulâ€ instructions that change behavior.",
          "visual": "ğŸ•³ï¸"
        },
        "climax": {
          "text": "Filter, label, and quote sources. Use allowlisted tools and strict output schemas.",
          "visual": "ğŸ”’"
        },
        "punchline": {
          "text": "If the docs can command you, youâ€™re compromised.",
          "visual": "ğŸš¨"
        }
      },
      "quiz": {
        "question": "What is a key prompt-injection defense in RAG?",
        "options": [
          "Treat retrieved text as untrusted data",
          "Let docs override system rules",
          "Disable validation"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Data Privacy: Minimize What You Send",
      "story": {
        "hook": {
          "text": "If you send everything, you leak something. Privacy is a design choice.",
          "visual": "ğŸ”’"
        },
        "buildup": {
          "text": "Agents touch emails, files, and customer data. Donâ€™t ship raw secrets to models.",
          "visual": "ğŸ§¯"
        },
        "discovery": {
          "text": "Minimize: redact PII, summarize, and send only the fields needed for the step.",
          "visual": "ğŸ§¼"
        },
        "twist": {
          "text": "More data rarely improves answers as much as better retrieval and structure.",
          "visual": "ğŸ“‰"
        },
        "climax": {
          "text": "Add a â€œdata mapâ€: what leaves your system, why, and how itâ€™s protected.",
          "visual": "ğŸ—ºï¸"
        },
        "punchline": {
          "text": "Privacy is reliability for trust.",
          "visual": "ğŸ¤"
        }
      },
      "quiz": {
        "question": "Whatâ€™s a good privacy practice for agents?",
        "options": [
          "Redact and minimize sent data",
          "Send full raw emails always",
          "Store secrets in logs"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Launch Checklist for Agent Apps",
      "story": {
        "hook": {
          "text": "Shipping an agent without a checklist is how â€œsmall bugsâ€ become incidents.",
          "visual": "ğŸš€"
        },
        "buildup": {
          "text": "Agents combine model risk + tool risk + data risk. You need a final gate.",
          "visual": "ğŸš§"
        },
        "discovery": {
          "text": "Checklist: eval pass, budgets, logging, guardrails, privacy review, rollback.",
          "visual": "ğŸ“‹"
        },
        "twist": {
          "text": "Rollbacks matter: the fastest fix is often â€œturn it offâ€ while you patch.",
          "visual": "â›”"
        },
        "climax": {
          "text": "Do a staged rollout with monitoring. Add a kill switch and an incident runbook.",
          "visual": "ğŸ§¯"
        },
        "punchline": {
          "text": "A checklist is your last guardrail.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "What belongs on a launch checklist?",
        "options": [
          "Rollback plan and monitoring",
          "â€œTrust the modelâ€",
          "No validation"
        ],
        "correct": 0
      },
      "is_free": false
    },
    {
      "chapter_id": "ai--agent-builder-lab--ch08-shipping",
      "title": "Tool Security: Principle of Least Privilege",
      "story": {
        "hook": {
          "text": "If one tool can do everything, one prompt injection can do everything.",
          "visual": "ğŸ”“"
        },
        "buildup": {
          "text": "Tools are capabilities. Capabilities should match the userâ€™s intent and rights.",
          "visual": "ğŸ§©"
        },
        "discovery": {
          "text": "Grant least privilege: narrow scopes, short-lived tokens, and explicit consent.",
          "visual": "ğŸ”‘"
        },
        "twist": {
          "text": "Least privilege also improves accuracy: fewer tools = fewer wrong choices.",
          "visual": "ğŸ¯"
        },
        "climax": {
          "text": "Audit tool usage. Add allowlists per user, per workspace, and per workflow.",
          "visual": "ğŸ§¾"
        },
        "punchline": {
          "text": "Every permission is a blast radius.",
          "visual": "ğŸ’¥"
        }
      },
      "quiz": {
        "question": "What does â€œleast privilegeâ€ mean for tools?",
        "options": [
          "Narrow scopes and explicit consent",
          "Give the agent admin rights",
          "Hide permissions from users"
        ],
        "correct": 0
      },
      "is_free": false
    }
  ]
}
