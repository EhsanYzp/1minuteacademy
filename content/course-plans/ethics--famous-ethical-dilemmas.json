{
  "categoryId": "ethics",
  "subject": "Ethics",
  "courseId": "ethics--famous-ethical-dilemmas",
  "courseTitle": "Famous Ethical Dilemmas",
  "emoji": "ğŸ¤”",
  "color": "#E11D48",
  "requireAuthoredStory": true,
  "chapters": [
    { "id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments", "title": "Classic Thought Experiments", "position": 1 },
    { "id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices", "title": "Historical Moral Choices", "position": 2 },
    { "id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals", "title": "Scientific Ethics Scandals", "position": 3 },
    { "id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas", "title": "Political & Legal Dilemmas", "position": 4 },
    { "id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas", "title": "Modern Technology Dilemmas", "position": 5 },
    { "id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles", "title": "Everyday Moral Puzzles", "position": 6 }
  ],
  "topics": [
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments",
      "title": "The Trolley Problem",
      "difficulty": "Beginner",
      "story": {
        "hook": { "text": "A trolley is about to kill five people. You can pull a lever to divert itâ€”but it will kill one person instead.", "visual": "ğŸšƒ" },
        "buildup": { "text": "Philosopher Philippa Foot invented this dilemma in 1967 to test whether outcomes or actions matter more.", "visual": "ğŸ§ " },
        "discovery": { "text": "Most people pull the lever. Five lives saved for one lost feels like simple math.", "visual": "ğŸ”¢" },
        "twist": { "text": "Now change it: you must push a man off a bridge to stop the trolley. Same math. Most people refuse.", "visual": "ğŸŒ‰" },
        "climax": { "text": "The difference reveals something deepâ€”we judge actions by how they feel, not just by their results.", "visual": "ğŸ’¡" },
        "punchline": { "text": "Same outcome, different action. That's why ethics is hard.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "What does the trolley problem reveal about how people make moral judgments?",
        "options": [
          "People always choose to save the most lives regardless of the method",
          "People judge actions by how they feel, not just by their outcomes",
          "People refuse to make any choice when lives are at stake"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments",
      "title": "The Prisoner's Dilemma",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "Two criminals are arrested. If both stay silent, they go free. But betraying the other is so tempting.", "visual": "ğŸ”’" },
        "buildup": { "text": "Each prisoner faces a choice: cooperate with their partner or betray them for a lighter sentence.", "visual": "ğŸ¤" },
        "discovery": { "text": "The rational move is always to betray. But if both betray, both get worse outcomes than if both cooperated.", "visual": "ğŸ“Š" },
        "twist": { "text": "In repeated games, the winning strategy is 'tit for tat'â€”cooperate first, then mirror what the other does.", "visual": "ğŸª" },
        "climax": { "text": "The dilemma shows why trust is fragile: selfishness is rational, but mutual cooperation beats mutual betrayal.", "visual": "ğŸ¤²" },
        "punchline": { "text": "Trust pays offâ€”but only if the other person trusts back.", "visual": "ğŸ”—" }
      },
      "quiz": {
        "question": "In repeated prisoner's dilemma games, what strategy tends to win?",
        "options": [
          "Always betrayâ€”maximize your own advantage every round",
          "Always cooperateâ€”trust unconditionally no matter what",
          "Tit for tatâ€”cooperate first, then mirror the other player's last move"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments",
      "title": "Heinz Dilemma (Kohlberg)",
      "difficulty": "Beginner",
      "story": {
        "hook": { "text": "A man's wife is dying. The only drug that could save her costs $2,000. He has $1,000. Should he steal it?", "visual": "ğŸ’Š" },
        "buildup": { "text": "Lawrence Kohlberg used this story to study how people reason about right and wrong at different ages.", "visual": "ğŸ“š" },
        "discovery": { "text": "Kohlberg didn't care about the answer. He cared about the reasoningâ€”why you thought stealing was right or wrong.", "visual": "ğŸ§©" },
        "twist": { "text": "A child says 'stealing is always wrong.' An adult says 'life outweighs property.' Both can be right.", "visual": "ğŸ‘¶" },
        "climax": { "text": "Kohlberg mapped six stages of moral developmentâ€”from obedience to universal principles. Most stop at stage 4.", "visual": "ğŸ“ˆ" },
        "punchline": { "text": "The answer doesn't matter. How you think about it does.", "visual": "ğŸ’­" }
      },
      "quiz": {
        "question": "What was Kohlberg studying with the Heinz dilemma?",
        "options": [
          "The reasoning process behind moral judgments, not the answers themselves",
          "Whether most people would steal to save a life",
          "Whether children are more ethical than adults"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments",
      "title": "The Experience Machine (Nozick)",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "Imagine a machine that gives you any experience you wantâ€”perfect happiness, forever. Would you plug in?", "visual": "ğŸ”Œ" },
        "buildup": { "text": "Robert Nozick posed this thought experiment in 1974 to challenge the idea that happiness is all that matters.", "visual": "ğŸ“–" },
        "discovery": { "text": "Most people refuse. They want real achievements, real relationshipsâ€”not perfect simulations.", "visual": "ğŸ”ï¸" },
        "twist": { "text": "But if happiness is the ultimate good, refusing the machine is irrational. You're choosing less happiness.", "visual": "ğŸ¤¯" },
        "climax": { "text": "Nozick proved something important: we value authenticity and reality, not just how we feel.", "visual": "ğŸ”‘" },
        "punchline": { "text": "Perfect fake happiness isn't enough. Reality matters to us.", "visual": "ğŸŒ" }
      },
      "quiz": {
        "question": "What did Nozick's experience machine thought experiment demonstrate?",
        "options": [
          "People would choose simulated happiness over reality if given the chance",
          "Happiness is the only thing that matters in a good life",
          "People value authenticity and reality, not just the feeling of happiness"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch01-classic-thought-experiments",
      "title": "The Violinist Argument (Thomson)",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "You wake up connected to a famous violinist. Unhook yourself and he dies. Stay connected nine months, he lives.", "visual": "ğŸ»" },
        "buildup": { "text": "Judith Jarvis Thomson created this scenario in 1971 to argue about bodily autonomy and abortion rights.", "visual": "ğŸ“" },
        "discovery": { "text": "Her point: even if the violinist has a right to life, that doesn't give him a right to use your body.", "visual": "ğŸ›¡ï¸" },
        "twist": { "text": "Critics say pregnancy isn't like kidnappingâ€”most people chose the risk. Thomson says that changes nothing.", "visual": "ğŸ”„" },
        "climax": { "text": "The argument separated two questions: whether a fetus has rights and whether those rights override yours.", "visual": "âš–ï¸" },
        "punchline": { "text": "A right to life isn't a right to someone else's body.", "visual": "âœ‹" }
      },
      "quiz": {
        "question": "What was Thomson's key argument in the violinist thought experiment?",
        "options": [
          "A person's right to life always overrides another person's bodily autonomy",
          "No one has a right to life if their survival depends on another person",
          "Having a right to life does not automatically grant a right to use someone else's body"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices",
      "title": "Truman's Atomic Bomb Decision",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "Harry Truman had to choose: invade Japan and lose a million soldiers, or drop a bomb that kills civilians.", "visual": "ğŸ’£" },
        "buildup": { "text": "Advisors told Truman the invasion of Japan could last years and cost hundreds of thousands of American lives.", "visual": "ğŸ“‹" },
        "discovery": { "text": "On August 6, 1945, the bomb fell on Hiroshima. Three days later, Nagasaki. Japan surrendered within a week.", "visual": "â˜ï¸" },
        "twist": { "text": "Truman never publicly expressed regret. But evidence shows Japan was already seeking peace through Moscow.", "visual": "ğŸ“¨" },
        "climax": { "text": "The dilemma endures: can killing 200,000 civilians be justified if it prevents an even bloodier invasion?", "visual": "â“" },
        "punchline": { "text": "The math of mass death doesn't simplify ethics. It complicates it.", "visual": "ğŸ”¢" }
      },
      "quiz": {
        "question": "What complicates the utilitarian justification for Truman's decision?",
        "options": [
          "Evidence suggests Japan was already seeking peace before the bombs were dropped",
          "The bombs failed to force Japan's surrender and the invasion proceeded anyway",
          "Truman was never informed about the civilian population in Hiroshima"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices",
      "title": "Oppenheimer's Moral Crisis",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "After the first nuclear test, Oppenheimer quoted scripture: 'Now I am become Death, destroyer of worlds.'", "visual": "â˜¢ï¸" },
        "buildup": { "text": "J. Robert Oppenheimer led the Manhattan Project that built the atomic bomb. He was a heroâ€”briefly.", "visual": "ğŸ”¬" },
        "discovery": { "text": "After Hiroshima, Oppenheimer lobbied against the hydrogen bomb, calling it a weapon of genocide.", "visual": "ğŸš«" },
        "twist": { "text": "The government stripped his security clearance. The man who built the bomb was punished for opposing bigger ones.", "visual": "ğŸªª" },
        "climax": { "text": "Oppenheimer's tragedy: you can't un-invent a weapon, and creating one doesn't give you power to control it.", "visual": "ğŸ”“" },
        "punchline": { "text": "He built the bomb, then begged the world not to use it.", "visual": "ğŸ™" }
      },
      "quiz": {
        "question": "Why did the U.S. government strip Oppenheimer's security clearance?",
        "options": [
          "He was caught sharing nuclear secrets with the Soviet Union",
          "He opposed the development of the even more powerful hydrogen bomb",
          "He publicly criticized President Truman's decision to drop the bomb"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices",
      "title": "Oskar Schindler's List",
      "difficulty": "Beginner",
      "story": {
        "hook": { "text": "Oskar Schindler was a Nazi Party member, a war profiteer, and a drunk. He saved 1,200 Jewish lives.", "visual": "ğŸ“‹" },
        "buildup": { "text": "Schindler ran a factory using Jewish slave labor during the Holocaust. He started for profit, not morality.", "visual": "ğŸ­" },
        "discovery": { "text": "As he witnessed the horrors, something shifted. He began bribing officials and faking records to save workers.", "visual": "ğŸ’°" },
        "twist": { "text": "He spent his entire fortune on bribes. After the war, the man who saved 1,200 lives died broke and forgotten.", "visual": "ğŸ“‰" },
        "climax": { "text": "Schindler proves that moral transformation is possibleâ€”even inside a monster's uniform.", "visual": "ğŸ¦‹" },
        "punchline": { "text": "A flawed man in an evil system chose good. That's enough.", "visual": "âœ¨" }
      },
      "quiz": {
        "question": "What makes Oskar Schindler's story ethically significant?",
        "options": [
          "He started as a profit-seeking Nazi member but transformed morally, sacrificing everything to save lives",
          "He was a lifelong humanitarian who always opposed the Nazi regime",
          "He was forced by Allied intelligence to protect Jewish workers as a spy"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices",
      "title": "Stanford Prison Experiment Ethics",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "In 1971, college students pretended to be guards for six days. They became genuinely cruel.", "visual": "ğŸ”’" },
        "buildup": { "text": "Philip Zimbardo's Stanford Prison Experiment assigned random students as guards or prisoners.", "visual": "ğŸ›ï¸" },
        "discovery": { "text": "Guards stripped prisoners naked, forced them into closets, and broke them psychologicallyâ€”in under a week.", "visual": "ğŸ˜±" },
        "twist": { "text": "Zimbardo himself got so absorbed in his role as 'superintendent' that he let the abuse continue.", "visual": "ğŸ‘¤" },
        "climax": { "text": "The experiment proved power corruptsâ€”but it was itself deeply unethical. The subjects weren't protected.", "visual": "ğŸš¨" },
        "punchline": { "text": "A study about abuse became abusive. Irony isn't strong enough.", "visual": "ğŸ”„" }
      },
      "quiz": {
        "question": "What ethical failure occurred during the Stanford Prison Experiment itself?",
        "options": [
          "The results were fabricated and none of the abuse actually occurred",
          "Participants were not told it was an experiment and believed they were real prisoners",
          "The researcher became absorbed in his role and failed to protect participants from real psychological harm"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch02-historical-moral-choices",
      "title": "The Milgram Obedience Shock",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "65% of ordinary people delivered what they believed were fatal electric shocksâ€”because a man in a lab coat told them.", "visual": "âš¡" },
        "buildup": { "text": "Stanley Milgram wanted to understand how Holocaust perpetrators justified 'just following orders.'", "visual": "ğŸ“‹" },
        "discovery": { "text": "Participants thought they were shocking a learner for wrong answers. The screams were fake, the obedience real.", "visual": "ğŸ­" },
        "twist": { "text": "Many subjects were visibly distressed but kept going. Authority overrode their own moral judgment.", "visual": "ğŸ˜°" },
        "climax": { "text": "Milgram showed that evil doesn't require evil peopleâ€”just ordinary people and a convincing authority.", "visual": "ğŸ§‘â€ğŸ”¬" },
        "punchline": { "text": "Ordinary people, extraordinary cruelty. Just add authority.", "visual": "ğŸªª" }
      },
      "quiz": {
        "question": "What was the most disturbing finding of the Milgram experiment?",
        "options": [
          "Only psychopaths were willing to deliver shocks to the learner",
          "Participants enjoyed the experiment and volunteered to increase the voltage",
          "65% of ordinary people obeyed authority even when they believed they were causing lethal harm"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals",
      "title": "Tuskegee Syphilis Study",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "For 40 years, the U.S. government watched 399 Black men die of syphilisâ€”and never told them a cure existed.", "visual": "ğŸ’‰" },
        "buildup": { "text": "The Tuskegee Study began in 1932 to observe untreated syphilis in African American men in Alabama.", "visual": "ğŸ“Š" },
        "discovery": { "text": "When penicillin became available in 1947, researchers deliberately withheld it from the participants.", "visual": "ğŸ’Š" },
        "twist": { "text": "The men were told they were being treated. They were actually getting placebos while scientists took notes.", "visual": "ğŸ“" },
        "climax": { "text": "The study wasn't exposed until 1972. It destroyed Black Americans' trust in medicineâ€”a wound still open today.", "visual": "ğŸ’”" },
        "punchline": { "text": "They called it science. It was racism wearing a lab coat.", "visual": "ğŸ§ª" }
      },
      "quiz": {
        "question": "What happened when penicillin became available as a cure for syphilis during the Tuskegee Study?",
        "options": [
          "Researchers deliberately withheld the cure and continued observing the untreated men",
          "The study ended immediately and all participants were treated",
          "Participants were offered the choice between treatment and continued observation"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals",
      "title": "Thalidomide Tragedy",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "A sleeping pill marketed as 'completely safe' for pregnant women caused 10,000 babies to be born without limbs.", "visual": "ğŸ’Š" },
        "buildup": { "text": "Thalidomide was sold in 46 countries in the late 1950s. It treated morning sickness beautifully.", "visual": "ğŸŒ" },
        "discovery": { "text": "The drug hadn't been tested on pregnant animals. One FDA reviewer in the U.S. blocked itâ€”saving thousands.", "visual": "ğŸ›¡ï¸" },
        "twist": { "text": "The company knew about nerve damage reports for a year before pulling the drug. Profits came first.", "visual": "ğŸ’°" },
        "climax": { "text": "Thalidomide created modern drug regulation. Every safety test you take for granted exists because of it.", "visual": "ğŸ“‹" },
        "punchline": { "text": "10,000 children paid for one shortcut. Now we test drugs properly.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "What lasting impact did the thalidomide tragedy have?",
        "options": [
          "It led to the global ban on all pharmaceutical advertising",
          "It created the modern drug safety regulation and testing requirements we use today",
          "It had no lasting impactâ€”similar tragedies continued at the same rate"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals",
      "title": "CRISPR Babies Scandal",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "In 2018, a Chinese scientist edited the DNA of twin baby girls. He didn't cure a diseaseâ€”he experimented.", "visual": "ğŸ§¬" },
        "buildup": { "text": "He Jiankui used CRISPR to modify embryos, claiming he was making them resistant to HIV.", "visual": "ğŸ”¬" },
        "discovery": { "text": "The scientific community was horrified. The edits were unnecessary, untested, and potentially harmful.", "visual": "ğŸ˜±" },
        "twist": { "text": "He didn't just edit the twins' DNA. Those changes will pass to their children and grandchildrenâ€”forever.", "visual": "â™¾ï¸" },
        "climax": { "text": "He was sentenced to three years in prison. But the genie is out of the bottleâ€”someone proved it's possible.", "visual": "ğŸ§" },
        "punchline": { "text": "He edited two lives and every generation after. No undo button.", "visual": "âï¸" }
      },
      "quiz": {
        "question": "Why was He Jiankui's CRISPR experiment especially alarming to scientists?",
        "options": [
          "CRISPR technology had never been successfully used on any organism before",
          "He proved that gene editing always causes fatal mutations in human embryos",
          "The genetic changes were heritableâ€”they would pass to the twins' descendants permanently"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals",
      "title": "Facebook Mood Experiment",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "In 2014, Facebook secretly manipulated 700,000 users' news feeds to see if it could change their emotions.", "visual": "ğŸ“±" },
        "buildup": { "text": "Researchers showed some users more negative posts and others more positive postsâ€”without their knowledge.", "visual": "ğŸ˜Š" },
        "discovery": { "text": "It worked. People shown negative content posted more negatively. Facebook proved it could shift moods at scale.", "visual": "ğŸ“‰" },
        "twist": { "text": "Facebook argued users consented by agreeing to the Terms of Service. Nobody reads the Terms of Service.", "visual": "ğŸ“œ" },
        "climax": { "text": "The experiment raised a chilling question: if a platform can manipulate your feelings, is that a form of control?", "visual": "ğŸ®" },
        "punchline": { "text": "They didn't ask permission. They already had your 'consent.'", "visual": "âœ…" }
      },
      "quiz": {
        "question": "How did Facebook justify its emotional manipulation experiment?",
        "options": [
          "They argued users had consented through the Terms of Service agreement",
          "They claimed the experiment was too small to have any real impact on users",
          "They received explicit informed consent from all 700,000 participants"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch03-scientific-ethics-scandals",
      "title": "Theranos Fraud",
      "difficulty": "Beginner",
      "story": {
        "hook": { "text": "Elizabeth Holmes promised a machine that could run 200 blood tests from a single drop. It was a lie.", "visual": "ğŸ©¸" },
        "buildup": { "text": "Theranos raised $700 million and was valued at $9 billion. Holmes was on magazine covers everywhere.", "visual": "ğŸ“°" },
        "discovery": { "text": "The technology never worked. Theranos secretly ran most tests on normal machines from other companies.", "visual": "ğŸ–¥ï¸" },
        "twist": { "text": "Patients received wrong diagnosesâ€”some were told they had cancer when they didn't. Real lives were harmed.", "visual": "ğŸ˜¢" },
        "climax": { "text": "Holmes was convicted of fraud in 2022. The dream of disrupting healthcare became a cautionary tale.", "visual": "âš–ï¸" },
        "punchline": { "text": "Fake it till you make it doesn't work in medicine.", "visual": "ğŸš«" }
      },
      "quiz": {
        "question": "What real harm did Theranos's fraud cause beyond financial losses?",
        "options": [
          "It caused a nationwide blood shortage by diverting supplies",
          "Patients received incorrect medical diagnoses that affected their treatment",
          "It prevented other legitimate blood-testing companies from receiving funding"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas",
      "title": "Snowden's Leak Dilemma",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "Edward Snowden revealed that the U.S. government was spying on every American's phone calls. Hero or traitor?", "visual": "ğŸ“" },
        "buildup": { "text": "In 2013, Snowden leaked classified NSA documents showing mass surveillance of ordinary citizens.", "visual": "ğŸ“‚" },
        "discovery": { "text": "He broke the law to expose lawbreaking. The government was violating the Fourth Amendment at massive scale.", "visual": "ğŸ“œ" },
        "twist": { "text": "Snowden fled to Russiaâ€”an irony that critics use against him. The whistleblower lives under an autocracy.", "visual": "ğŸ‡·ğŸ‡º" },
        "climax": { "text": "His dilemma was simple but impossible: obey the law and let abuses continue, or break it and become a fugitive.", "visual": "ğŸšª" },
        "punchline": { "text": "He chose truth over safety. The debate over that choice rages on.", "visual": "ğŸ”¥" }
      },
      "quiz": {
        "question": "What was the core ethical dilemma Snowden faced?",
        "options": [
          "Whether to obey the law and allow unconstitutional surveillance, or break it to expose the abuse",
          "Whether to sell classified documents to foreign governments or the media",
          "Whether to report the surveillance through official channels or resign quietly"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas",
      "title": "Death Penalty for Juveniles",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "In 1944, the U.S. executed George Stinney Jr. He was 14 years old, Black, and almost certainly innocent.", "visual": "â›“ï¸" },
        "buildup": { "text": "For decades, the U.S. allowed the death penalty for crimes committed by minors.", "visual": "âš–ï¸" },
        "discovery": { "text": "In 2005, the Supreme Court banned juvenile executions in Roper v. Simmons, citing brain development science.", "visual": "ğŸ§ " },
        "twist": { "text": "The Court said teenagers lack the maturity for full moral responsibilityâ€”yet we still try some as adults.", "visual": "ğŸ›ï¸" },
        "climax": { "text": "The question lingers: if a 16-year-old's brain isn't fully formed, can any punishment truly be 'deserved'?", "visual": "â“" },
        "punchline": { "text": "We say kids can't vote or drink. But we tried them for their lives.", "visual": "ğŸ—³ï¸" }
      },
      "quiz": {
        "question": "On what basis did the Supreme Court ban juvenile executions in Roper v. Simmons?",
        "options": [
          "The Eighth Amendment's ban on cruel and unusual punishment",
          "Scientific evidence that teenagers' brains lack full maturity for moral responsibility",
          "International pressure from the United Nations Human Rights Council"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas",
      "title": "Torture and the Ticking Bomb",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "A terrorist planted a nuclear bomb in a city. You caught him. He won't talk. Is torture justified?", "visual": "ğŸ’£" },
        "buildup": { "text": "The ticking bomb scenario argues that torture can be moral when millions of lives are at stake.", "visual": "â°" },
        "discovery": { "text": "Defenders say extreme situations justify extreme measures. One person's pain versus a city's survival.", "visual": "ğŸ™ï¸" },
        "twist": { "text": "The scenario is designed to make torture seem logical. In reality, torture produces unreliable information.", "visual": "ğŸ¤¥" },
        "climax": { "text": "If you allow torture once, you've created a legal precedent. The exception becomes the rule.", "visual": "ğŸ“" },
        "punchline": { "text": "The hypothetical is simple. Real torture never is.", "visual": "ğŸŒ«ï¸" }
      },
      "quiz": {
        "question": "What is the main practical objection to the ticking bomb torture argument?",
        "options": [
          "Torture is too expensive and time-consuming to be effective under time pressure",
          "Most terrorists are trained to resist torture indefinitely",
          "In reality, torture produces unreliable information and creates dangerous legal precedents"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas",
      "title": "Gerrymandering Ethics",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "In North Carolina, Democrats won 50% of votes but only 3 of 13 congressional seats. The map was rigged.", "visual": "ğŸ—ºï¸" },
        "buildup": { "text": "Gerrymandering redraws electoral districts so one party wins more seats than their vote share deserves.", "visual": "âœ‚ï¸" },
        "discovery": { "text": "Both parties do it. The party in power draws maps that lock in their advantage for a decade at a time.", "visual": "ğŸ”’" },
        "twist": { "text": "The Supreme Court ruled in 2019 that partisan gerrymandering is a political issue courts can't fix.", "visual": "ğŸ›ï¸" },
        "climax": { "text": "Voters are supposed to choose politicians. Gerrymandering lets politicians choose their voters instead.", "visual": "ğŸ”„" },
        "punchline": { "text": "When politicians draw maps, democracy bends to power.", "visual": "ğŸ“" }
      },
      "quiz": {
        "question": "What did the Supreme Court rule about partisan gerrymandering in 2019?",
        "options": [
          "It ruled that partisan gerrymandering is a political question that courts cannot resolve",
          "It declared all partisan gerrymandering unconstitutional",
          "It mandated that independent commissions must draw all district maps"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch04-political-and-legal-dilemmas",
      "title": "Jury Nullification Debate",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "A jury finds a man guilty of a crime they think shouldn't be a law. They vote 'not guilty' anyway.", "visual": "ğŸ§‘â€âš–ï¸" },
        "buildup": { "text": "Jury nullification means jurors acquit despite clear evidence of guilt because they oppose the law itself.", "visual": "ğŸ“œ" },
        "discovery": { "text": "It has a noble history: northern juries refused to convict people who helped escaped slaves before the Civil War.", "visual": "â›“ï¸" },
        "twist": { "text": "But it has a dark side too. All-white juries in the South nullified to acquit murderers of Black citizens.", "visual": "ğŸšï¸" },
        "climax": { "text": "Nullification is both democracy's safety valve and its backdoor for injustice. Same power, opposite outcomes.", "visual": "ğŸ”€" },
        "punchline": { "text": "The same power that freed slaves also freed their killers.", "visual": "âš–ï¸" }
      },
      "quiz": {
        "question": "Why is jury nullification considered ethically complex?",
        "options": [
          "It has never been used successfully in any real court case",
          "It can be used both to protect justice and to perpetuate injustice, depending on the jury",
          "It is explicitly prohibited by the U.S. Constitution"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
      "title": "Self-Driving Trolley Problem",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "A self-driving car must choose: swerve and kill the passenger, or go straight and kill the pedestrian.", "visual": "ğŸš—" },
        "buildup": { "text": "The classic trolley problem is no longer hypothetical. Engineers must program these decisions into cars.", "visual": "ğŸ’»" },
        "discovery": { "text": "MIT's Moral Machine asked millions of people to choose. Preferences varied wildly by culture and country.", "visual": "ğŸŒ" },
        "twist": { "text": "Everyone wants self-driving cars that protect pedestriansâ€”but nobody wants to ride in one that sacrifices them.", "visual": "ğŸ¤·" },
        "climax": { "text": "We're asking engineers to encode morality into algorithms. Philosophy never solved thisâ€”why would code?", "visual": "ğŸ§‘â€ğŸ’»" },
        "punchline": { "text": "Philosophers debated for centuries. Now programmers have a deadline.", "visual": "â³" }
      },
      "quiz": {
        "question": "What did MIT's Moral Machine study reveal about self-driving car ethics?",
        "options": [
          "There is universal global agreement on how self-driving cars should handle moral dilemmas",
          "Most people prefer self-driving cars that always protect the passenger at any cost",
          "People's moral preferences varied significantly by culture and country"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
      "title": "Social Media Addiction by Design",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "Instagram's own research found it worsens body image in teenage girls. They hid the report.", "visual": "ğŸ“±" },
        "buildup": { "text": "Social media platforms use variable reward schedulesâ€”the same psychology that makes slot machines addictive.", "visual": "ğŸ°" },
        "discovery": { "text": "Every pull-to-refresh, notification ping, and infinite scroll is engineered to keep you coming back.", "visual": "ğŸ””" },
        "twist": { "text": "Tech executives limit their own children's screen time. They know what they built.", "visual": "ğŸ‘¨â€ğŸ‘§" },
        "climax": { "text": "The question isn't if social media is addictive. It's whether deliberately designing addiction is ethical.", "visual": "ğŸ§ª" },
        "punchline": { "text": "They built the trap, then warned their kids to avoid it.", "visual": "ğŸª¤" }
      },
      "quiz": {
        "question": "What psychological mechanism do social media platforms exploit to keep users engaged?",
        "options": [
          "Variable reward schedulesâ€”the same psychology behind slot machine addiction",
          "Rational cost-benefit analysis that helps users make informed choices",
          "Educational content algorithms that encourage productive learning habits"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
      "title": "Facial Recognition in Public",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "London police used facial recognition at a protest. It flagged 104 people. 102 were false matches.", "visual": "ğŸ“¸" },
        "buildup": { "text": "Facial recognition can identify anyone from a camera feedâ€”shoplifters, terrorists, or peaceful protestors.", "visual": "ğŸ‘ï¸" },
        "discovery": { "text": "The technology is up to 100 times more likely to misidentify Black and Asian faces than white ones.", "visual": "ğŸ“Š" },
        "twist": { "text": "China uses it to track Uyghur Muslims. Russia uses it to identify protesters. The tool is neutral; intent isn't.", "visual": "ğŸŒ" },
        "climax": { "text": "Once you allow cameras to identify everyone everywhere, anonymity in public spaces disappears forever.", "visual": "ğŸš¶" },
        "punchline": { "text": "A face is not a fingerprint. You can't leave it at home.", "visual": "ğŸ " }
      },
      "quiz": {
        "question": "What is a documented bias in facial recognition technology?",
        "options": [
          "It is equally accurate across all racial and ethnic groups",
          "It is up to 100 times more likely to misidentify Black and Asian faces than white ones",
          "It can only identify people who have been previously photographed by police"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
      "title": "DNA Database Privacy",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "Police caught the Golden State Killer using his cousin's DNA from a genealogy website. Great detective work?", "visual": "ğŸ§¬" },
        "buildup": { "text": "The cousin never consented to a police search. They just wanted to find their ancestry.", "visual": "ğŸŒ³" },
        "discovery": { "text": "When you upload DNA, you expose not just yourself but every blood relativeâ€”without their knowledge or consent.", "visual": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦" },
        "twist": { "text": "The same tool that catches serial killers could identify dissidents, screen employees, or deny insurance.", "visual": "ğŸ”" },
        "climax": { "text": "Your DNA is the most personal data you have. Once it's in a database, you can never take it back.", "visual": "ğŸ—„ï¸" },
        "punchline": { "text": "Your cousin uploaded their DNA. Now police have yours too.", "visual": "ğŸ”—" }
      },
      "quiz": {
        "question": "Why is using genealogy DNA databases for police investigations ethically controversial?",
        "options": [
          "DNA evidence is unreliable and frequently leads to wrongful convictions",
          "Police must obtain a warrant before accessing any DNA database",
          "Uploading your DNA exposes all blood relatives without their knowledge or consent"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch05-modern-technology-dilemmas",
      "title": "AI Hiring Bias",
      "difficulty": "Beginner",
      "story": {
        "hook": { "text": "Amazon built an AI to screen job applicants. It taught itself that women were less qualified than men.", "visual": "ğŸ¤–" },
        "buildup": { "text": "The AI was trained on ten years of rÃ©sumÃ©sâ€”mostly from men, because tech was dominated by men.", "visual": "ğŸ“„" },
        "discovery": { "text": "The algorithm learned to penalize rÃ©sumÃ©s containing the word 'women's,' like 'women's chess club.'", "visual": "â™Ÿï¸" },
        "twist": { "text": "Amazon scrapped the tool, but other companies use similar AI hiring systemsâ€”often without checking for bias.", "visual": "ğŸ¢" },
        "climax": { "text": "AI doesn't eliminate human bias. It scales itâ€”making discrimination faster, cheaper, and harder to see.", "visual": "ğŸ“ˆ" },
        "punchline": { "text": "Biased data in, biased decisions out. AI just automates it.", "visual": "ğŸ”„" }
      },
      "quiz": {
        "question": "Why did Amazon's AI hiring tool discriminate against women?",
        "options": [
          "It was trained on ten years of male-dominated rÃ©sumÃ© data and learned to replicate that bias",
          "The programmers deliberately coded it to prefer male candidates",
          "Women submitted fewer applications so the AI had less data about them"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles",
      "title": "Lying to Spare Feelings",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "Your friend asks if their terrible painting is good. You know the truth will crush them. Do you lie?", "visual": "ğŸ¨" },
        "buildup": { "text": "Kant said lying is always wrongâ€”even to spare feelings. The truth is a duty regardless of consequences.", "visual": "ğŸ“" },
        "discovery": { "text": "Utilitarians disagree: if a small lie prevents real suffering and causes no harm, it's the kind thing to do.", "visual": "ğŸ˜Š" },
        "twist": { "text": "But lies compound. Your friend enters a contest, loses badly, and finds out everyone lied. Now the hurt is worse.", "visual": "ğŸ“‰" },
        "climax": { "text": "The real question isn't truth or kindness. It's whether you're lying for them or for your own comfort.", "visual": "ğŸª" },
        "punchline": { "text": "Most 'kind' lies protect the liar, not the listener.", "visual": "ğŸ­" }
      },
      "quiz": {
        "question": "What is Kant's position on lying to spare someone's feelings?",
        "options": [
          "Small lies are acceptable when they prevent suffering",
          "Lying is always wrong, regardless of consequencesâ€”truth is a duty",
          "Lying is permissible if both parties agree to the deception"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles",
      "title": "Returning Excess Change",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "text": "A cashier gives you $20 too much in change. You notice in the parking lot. Do you go back?", "visual": "ğŸ’µ" },
        "buildup": { "text": "It's not your money. But the effort of returning it seems disproportionate to the amount.", "visual": "ğŸ¤”" },
        "discovery": { "text": "The cashier might have to cover the shortage from their own paycheck. Your gain is their direct loss.", "visual": "ğŸ‘©â€ğŸ’¼" },
        "twist": { "text": "Now change the scenario: a billion-dollar bank overcharges you $20. Do you call to return it?", "visual": "ğŸ¦" },
        "climax": { "text": "We judge the ethics of keeping money by who loses itâ€”but the principle should be the same.", "visual": "âš–ï¸" },
        "punchline": { "text": "Integrity shouldn't depend on who's watching or who pays.", "visual": "ğŸ‘ï¸" }
      },
      "quiz": {
        "question": "What does the excess change scenario reveal about how people make moral decisions?",
        "options": [
          "People consistently apply the same moral principles regardless of context",
          "People always return money because honesty is a universal human instinct",
          "People tend to judge the ethics of keeping money based on who loses it, not on principle"
        ],
        "correct": 2
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles",
      "title": "Bystander Intervention Duty",
      "difficulty": "Premium",
      "story": {
        "hook": { "text": "In 1964, Kitty Genovese was murdered while 38 neighbors reportedly watched and did nothing.", "visual": "ğŸŒƒ" },
        "buildup": { "text": "The bystander effect means the more people who witness an emergency, the less likely anyone helps.", "visual": "ğŸ‘¥" },
        "discovery": { "text": "Psychologists found that responsibility diffuses in crowds. Everyone assumes someone else will act.", "visual": "ğŸ§ " },
        "twist": { "text": "Most 'Good Samaritan' laws protect helpers from liability. Yet bystanders still freeze. Fear beats law.", "visual": "â„ï¸" },
        "climax": { "text": "The moral question is simple: if you can help at little cost to yourself, do you have a duty to act?", "visual": "ğŸ¤²" },
        "punchline": { "text": "Thirty-eight people, one victim. Everyone waited for someone else.", "visual": "â³" }
      },
      "quiz": {
        "question": "What is the bystander effect?",
        "options": [
          "The more witnesses to an emergency, the less likely any individual is to intervene",
          "People are more likely to help when they are in large groups",
          "Bystanders who intervene are usually held legally responsible for the outcome"
        ],
        "correct": 0
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles",
      "title": "Charity vs Self-Interest",
      "difficulty": "Premium",
      "story": {
        "hook": { "text": "Peter Singer says if you buy a $5 coffee while a child dies from a $5 vaccine, you chose coffee over a life.", "visual": "â˜•" },
        "buildup": { "text": "Singer's 'drowning child' argument: if you'd save a drowning child, you should send money to save distant ones.", "visual": "ğŸŒŠ" },
        "discovery": { "text": "Distance shouldn't matter morally. A child dying in front of you and one dying overseas are equally real.", "visual": "ğŸŒ" },
        "twist": { "text": "But follow this logic to its end: you should give everything until you're as poor as the poorest person.", "visual": "ğŸ’¸" },
        "climax": { "text": "Singer practices what he preachesâ€”he gives 40% of his income to charity. Most ethicists give much less.", "visual": "ğŸ“Š" },
        "punchline": { "text": "Your coffee or a child's life? The math is uncomfortable.", "visual": "ğŸ”¢" }
      },
      "quiz": {
        "question": "What is the core of Peter Singer's 'drowning child' argument?",
        "options": [
          "Charity should be legally required and enforced by governments",
          "If you would save a dying child nearby, moral consistency requires helping distant ones too",
          "People should only donate to causes where they can personally verify the impact"
        ],
        "correct": 1
      }
    },
    {
      "chapter_id": "ethics--famous-ethical-dilemmas--ch06-everyday-moral-puzzles",
      "title": "Cultural Gift-Giving Ethics",
      "difficulty": "Advanced",
      "story": {
        "hook": { "text": "In Japan, refusing a gift is deeply rude. In some Western offices, accepting one is a bribe. Who's right?", "visual": "ğŸ" },
        "buildup": { "text": "Gift-giving ethics vary wildly across cultures. What one society calls respect, another calls corruption.", "visual": "ğŸŒ" },
        "discovery": { "text": "The Foreign Corrupt Practices Act can punish Americans for cultural gift-giving normal in other countries.", "visual": "âš–ï¸" },
        "twist": { "text": "But cultural relativism has limits. When a 'gift' is worth $50,000, calling it tradition is a stretch.", "visual": "ğŸ’" },
        "climax": { "text": "The ethics depend on intent, value, and contextâ€”not on any single culture's rules.", "visual": "ğŸ§­" },
        "punchline": { "text": "One culture's courtesy is another's crime. Context is everything.", "visual": "ğŸŒ" }
      },
      "quiz": {
        "question": "Why can cultural gift-giving create ethical conflicts in international business?",
        "options": [
          "All gift-giving is considered bribery under international trade law",
          "What one culture sees as respectful custom, another may see as corruption or bribery",
          "Gift-giving is only ethical when the gifts are under $10 in value"
        ],
        "correct": 1
      }
    }
  ]
}
