{
  "categoryId": "data",
  "subject": "Data",
  "courseId": "data--misleading-data-and-statistical-traps",
  "courseTitle": "Misleading Data and Statistical Traps",
  "emoji": "ğŸ­",
  "color": "#E74C3C",
  "requireAuthoredStory": true,
  "chapters": [
    {
      "id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "title": "Lies with Numbers",
      "position": 1
    },
    {
      "id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "title": "Visual Deception",
      "position": 2
    },
    {
      "id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "title": "Logical Traps",
      "position": 3
    },
    {
      "id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "title": "Research Gone Wrong",
      "position": 4
    },
    {
      "id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "title": "Media and Manipulation",
      "position": 5
    },
    {
      "id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "title": "Defenses and Critical Thinking",
      "position": 6
    }
  ],
  "topics": [
    {
      "title": "How to Lie with Statistics: The Book That Started It All",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "In 1954, Darrell Huff wrote a tiny book teaching people how to deceive with numbers. It became a bestseller.",
          "visual": "ğŸ“š"
        },
        "buildup": {
          "text": "How to Lie with Statistics exposed tricks advertisers, politicians, and businesses use to mislead the public.",
          "visual": "ğŸ­"
        },
        "discovery": {
          "text": "Huff showed that the same data can tell completely different stories depending on how it's presented.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "Ironically, the tobacco industry later hired Huff to cast doubt on smoking-cancer links using his own techniques.",
          "visual": "ğŸš¬"
        },
        "climax": {
          "text": "The book remains the most widely read statistics book ever â€” 70 years later, every trick still works.",
          "visual": "ğŸ“–"
        },
        "punchline": {
          "text": "The tricks are old. The victims are new.",
          "visual": "âš ï¸"
        }
      },
      "quiz": {
        "question": "What happened with the author of 'How to Lie with Statistics'?",
        "options": [
          "He became a professor",
          "The tobacco industry hired him to mislead with data",
          "He banned statistical misuse"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Loaded Question: Bias Before Data Exists",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "'Do you support cutting wasteful government spending?' 90% say yes. The data is real. The question is rigged.",
          "visual": "ğŸ“‹"
        },
        "buildup": {
          "text": "Loaded questions use emotional or biased wording that pushes respondents toward a predetermined answer.",
          "visual": "ğŸ¯"
        },
        "discovery": {
          "text": "Simply rephrasing 'spending cuts' as 'reducing public services' drops agreement from 90% to 40%.",
          "visual": "ğŸ“‰"
        },
        "twist": {
          "text": "Pollsters know this. Political surveys are often designed to generate the results the commissioner wants.",
          "visual": "ğŸ›ï¸"
        },
        "climax": {
          "text": "The most powerful way to lie with data is to rig the question before collecting a single answer.",
          "visual": "ğŸ”§"
        },
        "punchline": {
          "text": "Control the question and you control the answer.",
          "visual": "ğŸ­"
        }
      },
      "quiz": {
        "question": "How do loaded questions bias survey results?",
        "options": [
          "By making surveys longer",
          "By using emotional wording that pushes respondents toward certain answers",
          "By excluding some demographics"
        ],
        "correct": 1
      }
    },
    {
      "title": "Relative Risk vs. Absolute Risk",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "'This drug reduces heart attack risk by 50%!' Sounds amazing â€” until you learn the actual numbers.",
          "visual": "ğŸ’Š"
        },
        "buildup": {
          "text": "The risk went from 2 in 1,000 to 1 in 1,000. Relatively, that's 50%. Absolutely, that's 0.1%.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Relative risk amplifies perception. Absolute risk gives the actual magnitude. Both are mathematically correct.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "Drug companies consistently use relative risk in marketing because it sounds more impressive.",
          "visual": "ğŸ’°"
        },
        "climax": {
          "text": "Knowing to ask 'what's the absolute difference?' is one of the most valuable data literacy skills.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "A 50% reduction can mean almost nothing in absolute terms.",
          "visual": "ğŸ¤"
        }
      },
      "quiz": {
        "question": "Why do drug companies prefer reporting relative risk?",
        "options": [
          "It's more scientifically accurate",
          "It makes small benefits sound much larger",
          "Regulators require it"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Missing Denominator Trick",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "'1,000 people were injured by vending machines last year!' Scary.",
          "visual": "ğŸ­"
        },
        "buildup": {
          "text": "The missing denominator trick presents a numerator â€” the count â€” without the base that gives it meaning.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Without context, any number can sound alarming. '50,000 bridge accidents' means nothing without total crossings.",
          "visual": "ğŸŒ‰"
        },
        "twist": {
          "text": "News headlines exploit this constantly. 'Deaths from X rose by 200!' Often that's from 3 to 9.",
          "visual": "ğŸ“°"
        },
        "climax": {
          "text": "Always demand the denominator. Without it, a statistic is designed to trigger emotion, not understanding.",
          "visual": "ğŸ§ "
        },
        "punchline": {
          "text": "A number without context is just a scare tactic.",
          "visual": "ğŸ˜±"
        }
      },
      "quiz": {
        "question": "What is the 'missing denominator' trick?",
        "options": [
          "Dividing by zero",
          "Presenting a count without the base that gives it context",
          "Hiding the data source"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Texas Sharpshooter Fallacy",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch01-lies-with-numbers",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "A Texan fires at a barn, then paints a bullseye around the tightest cluster of bullet holes. Perfect aim!",
          "visual": "ğŸ¯"
        },
        "buildup": {
          "text": "The Texas Sharpshooter Fallacy is finding a pattern in random data and claiming you predicted it.",
          "visual": "ğŸ”"
        },
        "discovery": {
          "text": "With enough data points, clusters always appear by chance. Finding them after the fact proves nothing.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "Cancer cluster investigations often fall into this trap â€” any map of random points will have clusters.",
          "visual": "ğŸ—ºï¸"
        },
        "climax": {
          "text": "The fallacy is why scientists must state their hypothesis before looking at data, not after.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "Paint the target first. Then shoot.",
          "visual": "ğŸ¹"
        }
      },
      "quiz": {
        "question": "What is the Texas Sharpshooter Fallacy?",
        "options": [
          "Being a bad shot",
          "Finding patterns in random data after the fact and claiming prediction",
          "Using Texas as a data sample"
        ],
        "correct": 1
      }
    },
    {
      "title": "Manipulating Chart Scales",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "Two charts show the same data. One looks like a gentle slope. The other looks like Mount Everest.",
          "visual": "ğŸ”ï¸"
        },
        "buildup": {
          "text": "By changing the Y-axis scale, compressing or stretching the chart, identical data tells opposite stories.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "A Y-axis from 0 to 100 makes small changes invisible. A Y-axis from 98 to 102 makes them look enormous.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "There's no universal rule for 'correct' scale. Context determines whether truncation is honest or deceptive.",
          "visual": "ğŸ¤”"
        },
        "climax": {
          "text": "Always check the axis before trusting any chart. The scale is where most visual lies hide.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "Same data, different scale, different story.",
          "visual": "ğŸ“ˆ"
        }
      },
      "quiz": {
        "question": "Where do most visual lies in charts hide?",
        "options": [
          "In the title",
          "In the axis scales and ranges",
          "In the color choices"
        ],
        "correct": 1
      }
    },
    {
      "title": "Distorted Proportions: Area and Volume Tricks",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "A chart doubles the height of a money bag icon to show 'doubled spending.' But the visual area quadruples.",
          "visual": "ğŸ’°"
        },
        "buildup": {
          "text": "When you scale a 2D icon by height, its area grows by the square. A 3D icon grows by the cube.",
          "visual": "ğŸ“"
        },
        "discovery": {
          "text": "Our eyes perceive area, not height. So doubling height makes something look four times larger.",
          "visual": "ğŸ‘ï¸"
        },
        "twist": {
          "text": "Infographics use this trick constantly â€” especially with bubble charts, pictograms, and icon arrays.",
          "visual": "ğŸ«§"
        },
        "climax": {
          "text": "The fix is simple: scale by area, not height. But most chart creators don't know the difference.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "Double the height, quadruple the lie.",
          "visual": "ğŸ“Š"
        }
      },
      "quiz": {
        "question": "When you double the height of a 2D icon, by how much does its visual area increase?",
        "options": [
          "It doubles",
          "It quadruples",
          "It stays the same"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Spaghetti Chart Problem",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "A chart with 15 overlapping colored lines looks like a bowl of spaghetti. Nobody can read anything.",
          "visual": "ğŸ"
        },
        "buildup": {
          "text": "Overloading a chart with too many data series makes it technically complete but practically useless.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "The deception is unintentional but real: viewers give up trying to read it and accept whatever narrative is offered.",
          "visual": "ğŸ¤·"
        },
        "twist": {
          "text": "Complexity can be a weapon. Present overwhelming data and people defer to your interpretation.",
          "visual": "ğŸ§ "
        },
        "climax": {
          "text": "Clarity is a design choice. Every unreadable chart is a missed opportunity â€” or a deliberate obfuscation.",
          "visual": "ğŸ’¡"
        },
        "punchline": {
          "text": "If you can't read the chart, that might be the point.",
          "visual": "ğŸ­"
        }
      },
      "quiz": {
        "question": "Why can overly complex charts be deceptive?",
        "options": [
          "They crash computers",
          "Viewers give up and accept the presented narrative uncritically",
          "They use too much color"
        ],
        "correct": 1
      }
    },
    {
      "title": "Cumulative vs. Daily: The Shape-Shifting Chart",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "During COVID, cumulative case charts always went up. Daily case charts showed waves. Same data, different feel.",
          "visual": "ğŸ“ˆ"
        },
        "buildup": {
          "text": "Cumulative charts add each day's value to the total â€” they can never go down, only flatten.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Daily charts show the rate of change. Cumulative charts show the total. Each answers different questions.",
          "visual": "ğŸ”¢"
        },
        "twist": {
          "text": "Media outlets switched between them depending on which told the more alarming story at the time.",
          "visual": "ğŸ“º"
        },
        "climax": {
          "text": "Knowing the difference between cumulative and rate-based charts prevents being misled by shape alone.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "A chart that can never go down always looks scary.",
          "visual": "ğŸ˜±"
        }
      },
      "quiz": {
        "question": "Why do cumulative charts always go up?",
        "options": [
          "Because data always increases",
          "Each day's value is added to the total, which can never decrease",
          "They only show positive data"
        ],
        "correct": 1
      }
    },
    {
      "title": "Map Projections That Distort Data",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch02-visual-deception",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "On a Mercator map, Greenland looks the same size as Africa. Africa is actually 14 times larger.",
          "visual": "ğŸ—ºï¸"
        },
        "buildup": {
          "text": "Every map projection distorts reality â€” some stretch area, others distort shape or direction.",
          "visual": "ğŸŒ"
        },
        "discovery": {
          "text": "When data is overlaid on distorted maps, the visual relationships between regions become misleading.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "The Mercator projection was designed for navigation, not for displaying data. Yet it's the default everywhere.",
          "visual": "ğŸ§­"
        },
        "climax": {
          "text": "Choosing the right projection is a data decision. The wrong one can make small countries' data invisible.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "Every map lies. The question is how much.",
          "visual": "ğŸ—ºï¸"
        }
      },
      "quiz": {
        "question": "How much larger is Africa than Greenland in reality?",
        "options": [
          "About 3 times",
          "About 14 times",
          "They're roughly the same size"
        ],
        "correct": 1
      }
    },
    {
      "title": "Correlation Traps: Spurious Relationships",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "US spending on science correlates with suicides by hanging at r = 0.998. Should we defund science?",
          "visual": "ğŸ”¬"
        },
        "buildup": {
          "text": "Spurious correlations occur when two unrelated variables happen to move together by coincidence.",
          "visual": "ğŸ“ˆ"
        },
        "discovery": {
          "text": "With millions of data series available, you can always find something that correlates with anything.",
          "visual": "ğŸ²"
        },
        "twist": {
          "text": "Tyler Vigen's website lists hundreds of absurd correlations â€” all statistically strong, all meaningless.",
          "visual": "ğŸ˜‚"
        },
        "climax": {
          "text": "Statistical significance without theoretical reasoning is just pattern-matching noise.",
          "visual": "ğŸ”Š"
        },
        "punchline": {
          "text": "Correlations are cheap. Explanations are expensive.",
          "visual": "ğŸ’°"
        }
      },
      "quiz": {
        "question": "What makes a correlation 'spurious'?",
        "options": [
          "It's statistically weak",
          "Two unrelated variables coincidentally move together",
          "It involves too few data points"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Prosecutor's Fallacy",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "DNA evidence matches the defendant with a 1-in-a-million probability. Guilty? Not necessarily.",
          "visual": "ğŸ§¬"
        },
        "buildup": {
          "text": "The prosecutor's fallacy confuses 'the probability of the evidence given innocence' with 'the probability of innocence.",
          "visual": "âš–ï¸"
        },
        "discovery": {
          "text": "In a country of 60 million, a 1-in-a-million match means 60 people match. The defendant is just one of them.",
          "visual": "ğŸ‘¥"
        },
        "twist": {
          "text": "This fallacy has contributed to wrongful convictions. Statistics misunderstood in court can ruin innocent lives.",
          "visual": "ğŸ›ï¸"
        },
        "climax": {
          "text": "Conditional probability is one of the hardest concepts for humans â€” and courts â€” to apply correctly.",
          "visual": "ğŸ§ "
        },
        "punchline": {
          "text": "A rare match isn't proof. It's just a starting point.",
          "visual": "ğŸ”"
        }
      },
      "quiz": {
        "question": "What does the prosecutor's fallacy confuse?",
        "options": [
          "Guilt and innocence",
          "The probability of evidence given innocence vs. innocence given evidence",
          "DNA accuracy rates"
        ],
        "correct": 1
      }
    },
    {
      "title": "Anchoring: The First Number Wins",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "A store prices a jacket at $500, then 'slashes' it to $200. You feel like you saved $300. You probably overpaid.",
          "visual": "ğŸ·ï¸"
        },
        "buildup": {
          "text": "Anchoring bias means the first number you see disproportionately influences your judgment of all that follow.",
          "visual": "âš“"
        },
        "discovery": {
          "text": "Kahneman and Tversky showed that even random numbers â€” like a spun wheel â€” anchor subsequent estimates.",
          "visual": "ğŸ¡"
        },
        "twist": {
          "text": "Negotiators, advertisers, and fundraisers all exploit anchoring. The 'suggested donation' box is an anchor.",
          "visual": "ğŸ’°"
        },
        "climax": {
          "text": "Being aware of anchoring doesn't eliminate its effect. Even experts fall for it when they're not careful.",
          "visual": "ğŸ§ "
        },
        "punchline": {
          "text": "The first number you hear sets the range for all that follow.",
          "visual": "ğŸ”¢"
        }
      },
      "quiz": {
        "question": "What is anchoring bias?",
        "options": [
          "Preferring anchored boats",
          "The first number seen disproportionately influences subsequent judgments",
          "Being anchored to one data source"
        ],
        "correct": 1
      }
    },
    {
      "title": "Goodhart's Law: When a Measure Becomes a Target",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "A hospital is graded on patient wait times. Solution? Staff triages patients in the parking lot before they 'arrive.'",
          "visual": "ğŸ¥"
        },
        "buildup": {
          "text": "Goodhart's Law: when a measure becomes a target, it ceases to be a good measure.",
          "visual": "ğŸ¯"
        },
        "discovery": {
          "text": "People optimize for the metric, not the goal. Test scores rise but learning doesn't. Crime drops but reporting stops.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "Social media engagement metrics caused platforms to optimize for outrage â€” the most engaging emotion.",
          "visual": "ğŸ˜¡"
        },
        "climax": {
          "text": "Every organization that ties incentives to metrics eventually corrupts those metrics.",
          "visual": "ğŸ’”"
        },
        "punchline": {
          "text": "Measure something and people will game it.",
          "visual": "ğŸ®"
        }
      },
      "quiz": {
        "question": "What does Goodhart's Law state?",
        "options": [
          "Good measures are always good targets",
          "When a measure becomes a target, it ceases to be a good measure",
          "All metrics are unreliable"
        ],
        "correct": 1
      }
    },
    {
      "title": "The McNamara Fallacy: Counting What's Easy, Not What Matters",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch03-logical-traps",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "During Vietnam, Defense Secretary McNamara measured success by enemy body counts. The US was 'winning' â€” until it lost.",
          "visual": "âš”ï¸"
        },
        "buildup": {
          "text": "The McNamara Fallacy is relying solely on measurable metrics while ignoring what's hard to quantify.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Body counts were easy to track. Morale, political support, and territorial control were not â€” and they decided the war.",
          "visual": "ğŸ—ºï¸"
        },
        "twist": {
          "text": "Modern organizations repeat this: measuring clicks instead of learning, revenue instead of customer happiness.",
          "visual": "ğŸ’»"
        },
        "climax": {
          "text": "Not everything that counts can be counted. Not everything that can be counted counts.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "Measuring the wrong thing is worse than measuring nothing.",
          "visual": "ğŸ¯"
        }
      },
      "quiz": {
        "question": "What is the McNamara Fallacy?",
        "options": [
          "Measuring only what's easy to quantify while ignoring what actually matters",
          "Using military data in business",
          "Counting too many variables"
        ],
        "correct": 0
      }
    },
    {
      "title": "p-Hacking: Torturing Data Until It Confesses",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "A researcher tests 20 hypotheses. One gives p < 0.05. They report only that one as their 'finding.'",
          "visual": "ğŸ”¬"
        },
        "buildup": {
          "text": "p-hacking means trying many analyses until one produces a statistically significant result â€” by sheer chance.",
          "visual": "ğŸ°"
        },
        "discovery": {
          "text": "With 20 tests at the 5% level, you expect one false positive. p-hacking guarantees you'll find it.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "It's not always intentional. Researchers explore data, find a pattern, and convince themselves it was the plan.",
          "visual": "ğŸ§ "
        },
        "climax": {
          "text": "p-hacking is a major cause of the replication crisis â€” published findings that can't be reproduced.",
          "visual": "ğŸ“°"
        },
        "punchline": {
          "text": "Torture the data long enough and it'll confess to anything.",
          "visual": "âš ï¸"
        }
      },
      "quiz": {
        "question": "What is p-hacking?",
        "options": [
          "Hacking p-values in computers",
          "Testing many hypotheses until one gives significant results by chance",
          "Using very small p-values"
        ],
        "correct": 1
      }
    },
    {
      "title": "Publication Bias: The File Drawer Problem",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "Journals love publishing positive results. Negative results go in a drawer. The literature gets distorted.",
          "visual": "ğŸ—„ï¸"
        },
        "buildup": {
          "text": "Publication bias means studies that find effects get published; studies that find nothing don't.",
          "visual": "ğŸ“°"
        },
        "discovery": {
          "text": "This creates a systematic overestimate of effects. We only see the hits, never the misses.",
          "visual": "ğŸ¯"
        },
        "twist": {
          "text": "A drug might fail in 19 trials and succeed in 1. Only the success gets published â€” making it look effective.",
          "visual": "ğŸ’Š"
        },
        "climax": {
          "text": "Pre-registration â€” declaring your study plan before running it â€” is the main solution gaining traction.",
          "visual": "ğŸ“‹"
        },
        "punchline": {
          "text": "What's not published shapes knowledge as much as what is.",
          "visual": "ğŸ“š"
        }
      },
      "quiz": {
        "question": "What is the file drawer problem?",
        "options": [
          "Not enough storage space",
          "Studies with null results go unpublished, distorting the literature",
          "Filing data incorrectly"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Wakefield Fraud: Fake Data, Real Harm",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "In 1998, a doctor published a study linking vaccines to autism. It was based on 12 children â€” and was fabricated.",
          "visual": "ğŸ’‰"
        },
        "buildup": {
          "text": "Andrew Wakefield's Lancet paper claimed the MMR vaccine caused autism, sparking a global vaccine panic.",
          "visual": "ğŸ˜°"
        },
        "discovery": {
          "text": "Investigative journalists found Wakefield had manipulated data and had undisclosed financial conflicts.",
          "visual": "ğŸ”"
        },
        "twist": {
          "text": "The Lancet retracted the paper in 2010. But by then, millions of parents had refused vaccines for their children.",
          "visual": "ğŸ“°"
        },
        "climax": {
          "text": "Measles outbreaks returned. Children died from a preventable disease because of one fraudulent study.",
          "visual": "ğŸ¥"
        },
        "punchline": {
          "text": "One fake paper killed more people than most real diseases.",
          "visual": "ğŸ’€"
        }
      },
      "quiz": {
        "question": "What happened to Wakefield's vaccine-autism paper?",
        "options": [
          "It was confirmed by larger studies",
          "It was retracted after data fabrication was discovered",
          "It won a Nobel Prize"
        ],
        "correct": 1
      }
    },
    {
      "title": "HARKing: Hypothesizing After Results Are Known",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "A researcher finds an unexpected pattern and writes the paper as if they predicted it all along.",
          "visual": "ğŸ”®"
        },
        "buildup": {
          "text": "HARKing â€” Hypothesizing After Results are Known â€” makes exploratory findings look like confirmed predictions.",
          "visual": "ğŸ“"
        },
        "discovery": {
          "text": "It inflates confidence in findings that were actually discovered by accident, not by design.",
          "visual": "ğŸ²"
        },
        "twist": {
          "text": "HARKing is incredibly common because journals reward 'clean' narratives over honest ones.",
          "visual": "ğŸ“°"
        },
        "climax": {
          "text": "Pre-registration forces researchers to declare hypotheses before seeing data â€” the antidote to HARKing.",
          "visual": "ğŸ“‹"
        },
        "punchline": {
          "text": "Predicting the past is easy. It just isn't science.",
          "visual": "ğŸ”¬"
        }
      },
      "quiz": {
        "question": "What is HARKing?",
        "options": [
          "Hypothesizing after results are known â€” pretending you predicted findings",
          "A type of statistical test",
          "Harsh criticism of research"
        ],
        "correct": 0
      }
    },
    {
      "title": "Overfitting: When Models Learn Noise",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch04-research-gone-wrong",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "A stock prediction model achieves 99% accuracy on past data. It loses money the very first day of trading.",
          "visual": "ğŸ“‰"
        },
        "buildup": {
          "text": "Overfitting occurs when a model memorizes the training data instead of learning the underlying patterns.",
          "visual": "ğŸ§ "
        },
        "discovery": {
          "text": "An overfit model captures every random fluctuation as if it's meaningful â€” then fails on new data.",
          "visual": "ğŸ²"
        },
        "twist": {
          "text": "The more complex a model, the easier it overfits. Simplicity often beats sophistication in prediction.",
          "visual": "âœ‚ï¸"
        },
        "climax": {
          "text": "Overfitting is the reason 'past performance doesn't guarantee future results' â€” in investing and in science.",
          "visual": "âš ï¸"
        },
        "punchline": {
          "text": "A model that memorizes yesterday can't predict tomorrow.",
          "visual": "ğŸ“…"
        }
      },
      "quiz": {
        "question": "What is overfitting?",
        "options": [
          "Making a model too simple",
          "A model memorizing noise in training data and failing on new data",
          "Using too much data"
        ],
        "correct": 1
      }
    },
    {
      "title": "Sensational Headlines and Buried Context",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "Headline: 'Coffee Causes Cancer!' Paragraph 12: 'In rats. At doses equivalent to 100 cups per day.'",
          "visual": "â˜•"
        },
        "buildup": {
          "text": "News headlines optimize for clicks, not accuracy. Important context is often buried deep in the article.",
          "visual": "ğŸ“°"
        },
        "discovery": {
          "text": "Most people read only headlines. The gap between headline and reality is where misinformation lives.",
          "visual": "ğŸ“±"
        },
        "twist": {
          "text": "Even quality newspapers write misleading headlines â€” because editors, not scientists, write them.",
          "visual": "âœï¸"
        },
        "climax": {
          "text": "Reading past the headline is the simplest, most effective data literacy skill you can practice.",
          "visual": "ğŸ“–"
        },
        "punchline": {
          "text": "The headline is the ad. The article is the product.",
          "visual": "ğŸ·ï¸"
        }
      },
      "quiz": {
        "question": "Why are news headlines about data often misleading?",
        "options": [
          "Journalists don't understand data",
          "Headlines optimize for clicks, burying context deep in the article",
          "Editors deliberately lie"
        ],
        "correct": 1
      }
    },
    {
      "title": "How Propaganda Uses Statistics",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "The Soviet Union reported 100% employment, 100% literacy, and 100% voter turnout. All were technically 'true.'",
          "visual": "ğŸ‡·ğŸ‡º"
        },
        "buildup": {
          "text": "Authoritarian regimes use real-sounding statistics to create an illusion of prosperity and legitimacy.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "They manipulate definitions: 'employed' includes forced labor. 'Literate' means signing your name.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "Modern propaganda is subtler. Cherry-picked economic data and rigged surveys serve the same purpose.",
          "visual": "ğŸ­"
        },
        "climax": {
          "text": "Statistics without independent verification can be weapons of control, not tools of understanding.",
          "visual": "âš”ï¸"
        },
        "punchline": {
          "text": "Numbers from power are power's numbers.",
          "visual": "ğŸ›ï¸"
        }
      },
      "quiz": {
        "question": "How do authoritarian regimes misuse statistics?",
        "options": [
          "They avoid all numbers",
          "They manipulate definitions to make bad data look impressive",
          "They only use foreign data"
        ],
        "correct": 1
      }
    },
    {
      "title": "Astroturfing: Fake Grassroots Data",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "A petition with 100,000 signatures demands policy change. But 90,000 signatures came from the same IP addresses.",
          "visual": "ğŸ“"
        },
        "buildup": {
          "text": "Astroturfing creates the illusion of organic public support using manufactured data.",
          "visual": "ğŸŒ±"
        },
        "discovery": {
          "text": "Named for artificial grass, astroturfing simulates grassroots movements to influence public opinion and policy.",
          "visual": "ğŸŸï¸"
        },
        "twist": {
          "text": "Social media makes astroturfing easier than ever â€” bots can generate thousands of 'genuine' opinions overnight.",
          "visual": "ğŸ¤–"
        },
        "climax": {
          "text": "Detecting astroturfing requires checking data provenance: where did these numbers actually come from?",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "Real grass has roots. Astroturf has an agenda.",
          "visual": "ğŸ­"
        }
      },
      "quiz": {
        "question": "What is astroturfing?",
        "options": [
          "Installing artificial grass",
          "Creating fake grassroots support using manufactured data and bots",
          "A type of data cleaning"
        ],
        "correct": 1
      }
    },
    {
      "title": "Deepfake Data: AI-Generated Misinformation",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "text": "An AI can generate a fake dataset with realistic statistical properties that passes automated quality checks.",
          "visual": "ğŸ¤–"
        },
        "buildup": {
          "text": "Deepfake data goes beyond images and video â€” entire research datasets can now be fabricated by AI.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Some fabricated papers use AI-generated data that is statistically plausible but never came from real experiments.",
          "visual": "ğŸ”¬"
        },
        "twist": {
          "text": "Detecting fake data is an arms race: as detection improves, generation gets more sophisticated.",
          "visual": "âš”ï¸"
        },
        "climax": {
          "text": "The trust model of science â€” assuming data is real unless proven otherwise â€” may need a fundamental overhaul.",
          "visual": "ğŸ›ï¸"
        },
        "punchline": {
          "text": "When fake data looks real, truth needs new defenses.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "What is deepfake data?",
        "options": [
          "Data stored deep in servers",
          "AI-generated fake datasets that appear statistically realistic",
          "Deeply analyzed data"
        ],
        "correct": 1
      }
    },
    {
      "title": "Truthful Data, Deceptive Framing",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch05-media-and-manipulation",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "'9 out of 10 dentists recommend our toothpaste.' True â€” if you ask 10 dentists employed by the company.",
          "visual": "ğŸ¦·"
        },
        "buildup": {
          "text": "The most dangerous data deceptions use real numbers presented in misleading contexts.",
          "visual": "ğŸ“Š"
        },
        "discovery": {
          "text": "Framing effects mean the same fact feels different depending on emphasis: '90% survival' vs. '10% death rate.'",
          "visual": "ğŸ–¼ï¸"
        },
        "twist": {
          "text": "No law requires full context. Advertisers legally use true but misleading statistics every day.",
          "visual": "âš–ï¸"
        },
        "climax": {
          "text": "The hardest deception to spot is the one that's technically correct but deliberately incomplete.",
          "visual": "ğŸ”"
        },
        "punchline": {
          "text": "True data, false impression. The cleverest lie of all.",
          "visual": "ğŸ­"
        }
      },
      "quiz": {
        "question": "What makes 'truthful but deceptive' framing so dangerous?",
        "options": [
          "It breaks the law",
          "The data is technically correct, making it hard to challenge",
          "It only works on uneducated people"
        ],
        "correct": 1
      }
    },
    {
      "title": "The CRAAP Test: Evaluating Data Sources",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "text": "Librarians created an acronym for evaluating sources. It's called CRAAP â€” and it's surprisingly effective.",
          "visual": "ğŸ“š"
        },
        "buildup": {
          "text": "CRAAP stands for Currency, Relevance, Authority, Accuracy, and Purpose â€” five checks for any data source.",
          "visual": "âœ…"
        },
        "discovery": {
          "text": "Is the data current? Is it relevant to your question? Who published it? Can it be verified? What's the motive?",
          "visual": "ğŸ”"
        },
        "twist": {
          "text": "Most viral data claims fail at least two of these five checks. Running CRAAP takes seconds.",
          "visual": "â±ï¸"
        },
        "climax": {
          "text": "Teaching CRAAP to students, journalists, and voters would dramatically reduce misinformation's spread.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "Five questions. That's all it takes to spot bad data.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "What does the 'A' in CRAAP stand for?",
        "options": [
          "Algorithms",
          "Authority and Accuracy (both A's represent different criteria)",
          "Analysis"
        ],
        "correct": 1
      }
    },
    {
      "title": "Steel-Manning: Understanding the Other Side's Data",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "difficulty": "Premium",
      "story": {
        "hook": {
          "text": "Instead of attacking the weakest version of an argument, what if you addressed the strongest?",
          "visual": "ğŸ›¡ï¸"
        },
        "buildup": {
          "text": "Steel-manning means rebuilding your opponent's data argument in its strongest form before countering it.",
          "visual": "âš”ï¸"
        },
        "discovery": {
          "text": "It forces you to genuinely understand the other side's data â€” which often reveals legitimate points you missed.",
          "visual": "ğŸ’¡"
        },
        "twist": {
          "text": "Most data debates are straw-man fights: both sides attack caricatures of the other's numbers.",
          "visual": "ğŸ‘¤"
        },
        "climax": {
          "text": "Steel-manning produces better analysis, more honest conclusions, and earns far more credibility.",
          "visual": "ğŸ¤"
        },
        "punchline": {
          "text": "Defeat the strongest argument, not the weakest straw man.",
          "visual": "ğŸ†"
        }
      },
      "quiz": {
        "question": "What does steel-manning an argument mean?",
        "options": [
          "Attacking the weakest version",
          "Addressing the strongest version of the opposing argument",
          "Ignoring the argument entirely"
        ],
        "correct": 1
      }
    },
    {
      "title": "Pre-Mortems: Finding Data Flaws Before They Matter",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "difficulty": "Premium",
      "story": {
        "hook": {
          "text": "Before launching a data project, imagine it failed spectacularly. Now figure out why.",
          "visual": "ğŸ’¥"
        },
        "buildup": {
          "text": "A pre-mortem asks: 'Assume this analysis is completely wrong. What went wrong?' before the work begins.",
          "visual": "ğŸ”"
        },
        "discovery": {
          "text": "Psychologist Gary Klein showed pre-mortems increase flaw detection by 30% compared to standard reviews.",
          "visual": "ğŸ“Š"
        },
        "twist": {
          "text": "Post-mortems happen after the damage. Pre-mortems prevent it â€” but few organizations bother.",
          "visual": "ğŸ¥"
        },
        "climax": {
          "text": "In data analysis, the best time to find errors is before you stake your reputation on the results.",
          "visual": "â°"
        },
        "punchline": {
          "text": "Imagine failure first. Prevent it second.",
          "visual": "ğŸ›¡ï¸"
        }
      },
      "quiz": {
        "question": "What is a pre-mortem in data analysis?",
        "options": [
          "Reviewing data after a project fails",
          "Imagining failure before starting to identify potential flaws",
          "Testing data on dead projects"
        ],
        "correct": 1
      }
    },
    {
      "title": "Numeracy: The Skill That Makes Data Literacy Possible",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "A study found that only 22% of adults can correctly calculate a 15% tip on a restaurant bill.",
          "visual": "ğŸ½ï¸"
        },
        "buildup": {
          "text": "Numeracy â€” comfort with basic mathematical concepts â€” is the foundation that data literacy is built on.",
          "visual": "ğŸ”¢"
        },
        "discovery": {
          "text": "Without numeracy, you can't evaluate percentages, ratios, probabilities, or sample sizes.",
          "visual": "ğŸ“"
        },
        "twist": {
          "text": "Innumeracy isn't embarrassing to most people.",
          "visual": "ğŸ¤·"
        },
        "climax": {
          "text": "Improving numeracy doesn't require calculus â€” just comfort with fractions, percentages, and basic probability.",
          "visual": "ğŸ“"
        },
        "punchline": {
          "text": "You can't spot data lies if you can't do basic math.",
          "visual": "ğŸ§®"
        }
      },
      "quiz": {
        "question": "Why is innumeracy a serious problem for data literacy?",
        "options": [
          "It makes computers slower",
          "People can't evaluate percentages, probabilities, and sample sizes",
          "It only affects scientists"
        ],
        "correct": 1
      }
    },
    {
      "title": "The Data-Literate Citizen",
      "chapter_id": "data--misleading-data-and-statistical-traps--ch06-defenses-and-critical-thinking",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "text": "Every election, budget, and health crisis comes wrapped in data. Democracy depends on citizens who can read it.",
          "visual": "ğŸ—³ï¸"
        },
        "buildup": {
          "text": "A data-literate citizen asks: What's the source? How was it collected? What's missing? Who benefits?",
          "visual": "â“"
        },
        "discovery": {
          "text": "These four questions expose 90% of statistical manipulation without requiring any advanced math.",
          "visual": "ğŸ”"
        },
        "twist": {
          "text": "Politicians and media count on innumeracy. A data-literate public would transform democratic accountability.",
          "visual": "ğŸ›ï¸"
        },
        "climax": {
          "text": "Data literacy isn't about becoming a statistician. It's about becoming harder to fool.",
          "visual": "ğŸ›¡ï¸"
        },
        "punchline": {
          "text": "Democracy needs citizens who can read the numbers, not just the headlines.",
          "visual": "ğŸ“°"
        }
      },
      "quiz": {
        "question": "What four questions should a data-literate citizen ask?",
        "options": [
          "Who, what, when, where",
          "Source, collection method, what's missing, who benefits",
          "Is it big, small, old, new"
        ],
        "correct": 1
      }
    }
  ]
}
