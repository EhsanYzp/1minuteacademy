{
  "categoryId": "ai",
  "subject": "AI",
  "courseId": "ai--ai-for-developers",
  "courseTitle": "AI for Developers",
  "emoji": "ğŸ’»",
  "color": "#EF4444",
  "requireAuthoredStory": true,
  "chapters": [
    {
      "id": "ai--ai-for-developers--ch01-getting-started",
      "title": "Getting Started",
      "position": 1
    },
    {
      "id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "APIs & SDKs",
      "position": 2
    },
    {
      "id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "Coding with AI",
      "position": 3
    },
    {
      "id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Integrating AI Features",
      "position": 4
    },
    {
      "id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Performance & Cost",
      "position": 5
    },
    {
      "id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "Shipping AI Apps",
      "position": 6
    }
  ],
  "topics": [
    {
      "id": "ai--ai-for-developers--t01-why-devs-need-ai",
      "chapter_id": "ai--ai-for-developers--ch01-getting-started",
      "title": "Why Devs Need AI",
      "description": "Why every developer should learn to build with AI today.",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "visual": "ğŸ“‹",
          "text": "A developer's backlog has 200 tickets. Their AI-powered teammate closes 50 overnight."
        },
        "buildup": {
          "visual": "ğŸŒŠ",
          "text": "AI isn't replacing developers â€” it's becoming the most powerful tool in their belt."
        },
        "discovery": {
          "visual": "ğŸ”‘",
          "text": "Devs who learn to integrate AI APIs, automate workflows, and build smart features have an exponential advantage."
        },
        "twist": {
          "visual": "ğŸ¤¹",
          "text": "You don't need a PhD in machine learning â€” most AI dev work is API calls, prompt design, and good engineering."
        },
        "climax": {
          "visual": "ğŸš€",
          "text": "Companies now expect devs to ship AI-native features. The gap between 'knows AI' and 'doesn't' is widening fast."
        },
        "punchline": {
          "visual": "ğŸ’¡",
          "text": "The best time to learn AI as a dev was yesterday. The second best time is right now."
        }
      },
      "quiz": {
        "question": "What is the main reason developers should learn AI?",
        "options": [
          "To replace data scientists",
          "To build smarter features with exponential leverage",
          "To avoid writing any code",
          "To become prompt-only engineers"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t02-ai-landscape-for-devs",
      "chapter_id": "ai--ai-for-developers--ch01-getting-started",
      "title": "AI Landscape for Devs",
      "description": "A practical map of the AI ecosystem that matters for software developers.",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "visual": "ğŸ—ºï¸",
          "text": "There are 10,000+ AI tools. A developer only needs to understand about 5 categories."
        },
        "buildup": {
          "visual": "ğŸ“Š",
          "text": "The landscape splits into foundation models, inference APIs, embedding services, orchestration frameworks, and deployment platforms."
        },
        "discovery": {
          "visual": "ğŸ§©",
          "text": "Foundation models (GPT, Claude, Gemini) are the engines. APIs are the steering wheel. Frameworks like LangChain and LlamaIndex are the chassis."
        },
        "twist": {
          "visual": "ğŸ”„",
          "text": "The landscape shifts monthly. The skill that matters isn't memorising tools â€” it's understanding the patterns they all share."
        },
        "climax": {
          "visual": "ğŸ¯",
          "text": "Pick one model provider, one framework, and one deployment target. You can build 90% of AI features with just those three."
        },
        "punchline": {
          "visual": "ğŸ§­",
          "text": "Knowing the map means you won't get lost when the next shiny tool drops."
        }
      },
      "quiz": {
        "question": "Which is NOT one of the main AI ecosystem categories for developers?",
        "options": [
          "Foundation models",
          "Inference APIs",
          "Quantum processors",
          "Orchestration frameworks"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t03-setting-up-your-ai-dev-env",
      "chapter_id": "ai--ai-for-developers--ch01-getting-started",
      "title": "Setting Up Your AI Dev Env",
      "description": "Configure your local environment for AI development in minutes.",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "visual": "ğŸ› ï¸",
          "text": "A developer spends 3 days setting up an AI project. Their colleague does it in 10 minutes with the right template."
        },
        "buildup": {
          "visual": "ğŸ“¦",
          "text": "You need an API key, a client library, environment variables, and a way to manage secrets. That's the whole checklist."
        },
        "discovery": {
          "visual": "âš¡",
          "text": "Store keys in .env files, use official SDKs (openai, anthropic, google-generativeai), and set up a simple test script that proves your connection works."
        },
        "twist": {
          "visual": "ğŸ”",
          "text": "The #1 beginner mistake? Committing API keys to Git. Use .gitignore and secret managers from day one."
        },
        "climax": {
          "visual": "âœ…",
          "text": "With your env set up â€” key loaded, SDK installed, test passing â€” you're ready to build anything."
        },
        "punchline": {
          "visual": "ğŸ",
          "text": "A clean dev environment is the launchpad. Don't skip it."
        }
      },
      "quiz": {
        "question": "What is the most critical security step when setting up an AI dev environment?",
        "options": [
          "Using the latest Node.js version",
          "Installing TypeScript",
          "Never committing API keys to version control",
          "Using a monorepo structure"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t04-calling-your-first-ai-api",
      "chapter_id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "Calling Your First AI API",
      "description": "Make your first API call to a large language model and get a response.",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "visual": "ğŸ“",
          "text": "One HTTP request. One JSON body. One response that can write poetry, code, or business plans."
        },
        "buildup": {
          "visual": "ğŸ“",
          "text": "Every AI API call follows the same shape: endpoint URL, authentication header, messages array, and model parameters."
        },
        "discovery": {
          "visual": "ğŸ’¬",
          "text": "Send a messages array with a system prompt and a user message. The model returns a completion with the assistant's response."
        },
        "twist": {
          "visual": "â±ï¸",
          "text": "API calls aren't instant â€” they can take 1-30 seconds depending on the model and prompt length. Always handle timeouts."
        },
        "climax": {
          "visual": "ğŸ‰",
          "text": "Your first successful API response feels like magic. You've just given your app a brain."
        },
        "punchline": {
          "visual": "ğŸ§±",
          "text": "Every AI product in the world started with one API call. You just made yours."
        }
      },
      "quiz": {
        "question": "What is the typical structure of an LLM API request?",
        "options": [
          "A single text string",
          "An image and a caption",
          "A messages array with system and user messages",
          "A SQL query"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t05-streaming-responses",
      "chapter_id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "Streaming Responses",
      "description": "Stream AI responses token-by-token for a faster, more interactive UX.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸŒŠ",
          "text": "Users stare at a blank screen for 8 seconds waiting for a response. Streaming shows the first word in 200ms."
        },
        "buildup": {
          "visual": "ğŸ”¤",
          "text": "Without streaming, the API generates the full response, then sends it all at once. Streaming sends each token as it's produced."
        },
        "discovery": {
          "visual": "ğŸ“¡",
          "text": "Set stream: true in your API call. The response becomes a Server-Sent Events stream. Read chunks in a loop and append them to the UI."
        },
        "twist": {
          "visual": "ğŸ§®",
          "text": "Streaming makes token counting trickier â€” you won't know the total tokens until the stream ends. Track usage in the final chunk."
        },
        "climax": {
          "visual": "âœ¨",
          "text": "With streaming, your app feels alive. Text appears word by word, just like ChatGPT. Users perceive it as 10x faster."
        },
        "punchline": {
          "visual": "âš¡",
          "text": "Perceived speed IS speed. Stream everything."
        }
      },
      "quiz": {
        "question": "What is the main benefit of streaming AI responses?",
        "options": [
          "Lower API costs",
          "More accurate responses",
          "Faster perceived response time for users",
          "Smaller payload size"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t06-handling-errors-and-retries",
      "chapter_id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "Handling Errors & Retries",
      "description": "Build resilient AI integrations with proper error handling and retry logic.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ’¥",
          "text": "A production AI feature crashes at 2 AM because the API returned a 429 and nobody handled it."
        },
        "buildup": {
          "visual": "ğŸš¦",
          "text": "AI APIs fail in predictable ways: rate limits (429), server errors (500), context too long (400), and content filtered (403)."
        },
        "discovery": {
          "visual": "ğŸ”",
          "text": "Implement exponential backoff for retries: wait 1s, 2s, 4s, 8s. Add jitter to avoid thundering herd. Set a max retry count."
        },
        "twist": {
          "visual": "ğŸ­",
          "text": "Some errors shouldn't be retried â€” a content policy violation will fail every time. Classify errors as transient vs permanent."
        },
        "climax": {
          "visual": "ğŸ›¡ï¸",
          "text": "With proper error handling, your AI feature gracefully degrades instead of crashing. Users see a helpful fallback, not an error page."
        },
        "punchline": {
          "visual": "ğŸ—ï¸",
          "text": "Robust error handling separates prototypes from production."
        }
      },
      "quiz": {
        "question": "Which HTTP status code typically indicates an API rate limit?",
        "options": [
          "200",
          "404",
          "429",
          "500"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t07-ai-assisted-coding",
      "chapter_id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "AI-Assisted Coding",
      "description": "Use AI code assistants to write, debug, and refactor code faster.",
      "difficulty": "Beginner",
      "story": {
        "hook": {
          "visual": "ğŸ¤–",
          "text": "A developer types a comment describing a function. The AI writes the entire implementation in 2 seconds."
        },
        "buildup": {
          "visual": "âŒ¨ï¸",
          "text": "AI coding assistants like Copilot, Cursor, and Cody sit in your editor, predicting and generating code as you type."
        },
        "discovery": {
          "visual": "ğŸ¯",
          "text": "The trick is context: good comments, clear variable names, and open related files give the AI much better suggestions."
        },
        "twist": {
          "visual": "âš ï¸",
          "text": "AI-generated code isn't always correct. It can introduce subtle bugs, use deprecated APIs, or hallucinate nonexistent libraries."
        },
        "climax": {
          "visual": "ğŸï¸",
          "text": "Used well, AI assistants 2-3x your coding speed on boilerplate, tests, and well-defined patterns."
        },
        "punchline": {
          "visual": "ğŸ§‘â€âœˆï¸",
          "text": "AI is the copilot. You're still the pilot."
        }
      },
      "quiz": {
        "question": "What helps AI coding assistants give better suggestions?",
        "options": [
          "Writing code in a single large file",
          "Using obscure variable names",
          "Providing clear comments and context",
          "Disabling all linting rules"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t08-ai-for-debugging",
      "chapter_id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "AI for Debugging",
      "description": "Leverage AI to find, explain, and fix bugs in your codebase.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ›",
          "text": "A bug has eluded the team for 3 days. A developer pastes the error and code into an AI chat. Fixed in 2 minutes."
        },
        "buildup": {
          "visual": "ğŸ”",
          "text": "AI excels at pattern-matching across millions of codebases it was trained on. It's seen your bug before â€” thousands of times."
        },
        "discovery": {
          "visual": "ğŸ“‹",
          "text": "Give the AI the error message, the relevant code, and what you expected. The more context you provide, the better the diagnosis."
        },
        "twist": {
          "visual": "ğŸª¤",
          "text": "AI can confidently suggest the wrong fix. Always understand WHY the fix works before applying it, or you'll create new bugs."
        },
        "climax": {
          "visual": "ğŸ¯",
          "text": "AI debugging shines for error messages, type mismatches, async issues, and off-by-one errors â€” the patterns it knows best."
        },
        "punchline": {
          "visual": "ğŸ©º",
          "text": "Think of AI as a second pair of eyes that never gets tired and has read every Stack Overflow post."
        }
      },
      "quiz": {
        "question": "What should you always do before applying an AI-suggested bug fix?",
        "options": [
          "Run it in production immediately",
          "Understand why the fix works",
          "Delete the original code first",
          "Ask for three alternative fixes"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t09-generating-tests-with-ai",
      "chapter_id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "Generating Tests with AI",
      "description": "Use AI to generate comprehensive test suites for your code.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ§ª",
          "text": "A developer asks AI to write tests for their function. It generates 12 test cases including edge cases they never considered."
        },
        "buildup": {
          "visual": "âœï¸",
          "text": "AI is remarkably good at test generation because tests follow predictable patterns: arrange, act, assert."
        },
        "discovery": {
          "visual": "ğŸ“",
          "text": "Give AI your function signature, types, and a brief description. Ask for happy path, edge cases, and error cases separately for thorough coverage."
        },
        "twist": {
          "visual": "ğŸ¤”",
          "text": "AI-generated tests can have a dangerous flaw: they test what the code DOES, not what it SHOULD do. Review assertions carefully."
        },
        "climax": {
          "visual": "ğŸ“Š",
          "text": "Combining AI-generated tests with human-reviewed assertions gives you high coverage fast without sacrificing correctness."
        },
        "punchline": {
          "visual": "ğŸ†",
          "text": "The best test suite is the one that actually gets written. AI removes the excuse."
        }
      },
      "quiz": {
        "question": "What is a common flaw in AI-generated tests?",
        "options": [
          "They use the wrong testing framework",
          "They test what code does instead of what it should do",
          "They always fail on the first run",
          "They can only test synchronous code"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t10-adding-chat-to-your-app",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Adding Chat to Your App",
      "description": "Build a conversational AI chat interface in your application.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ’¬",
          "text": "A SaaS app adds a chat widget. Support tickets drop 40% in the first week."
        },
        "buildup": {
          "visual": "ğŸ—ï¸",
          "text": "A chat feature needs: a messages array (conversation history), a system prompt (personality/rules), a UI component, and an API route."
        },
        "discovery": {
          "visual": "ğŸ”—",
          "text": "Maintain the full conversation in state. Send the entire messages array on each request so the model has context. Trim old messages when you approach the context limit."
        },
        "twist": {
          "visual": "ğŸ’°",
          "text": "Every message in the history costs tokens. A 50-message conversation can cost 10x a single request. Implement conversation summarisation or sliding windows."
        },
        "climax": {
          "visual": "ğŸ¨",
          "text": "Stream the response into the UI, add typing indicators, and handle errors gracefully. The result feels like a native chat experience."
        },
        "punchline": {
          "visual": "ğŸ—£ï¸",
          "text": "Chat is the most natural interface. Now your app can talk back."
        }
      },
      "quiz": {
        "question": "Why should you send the full conversation history with each API request?",
        "options": [
          "To increase API costs",
          "To give the model context for coherent responses",
          "To slow down the response time",
          "To bypass rate limits"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t11-structured-output",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Structured Output",
      "description": "Get AI to return reliable JSON, not unpredictable free text.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ“¦",
          "text": "A developer parses AI output with regex. It works 80% of the time. The other 20% crashes the app."
        },
        "buildup": {
          "visual": "ğŸ²",
          "text": "LLMs naturally return free text. But apps need structured data â€” JSON objects, arrays, specific fields with specific types."
        },
        "discovery": {
          "visual": "ğŸ“",
          "text": "Use JSON mode, function calling, or response_format with a JSON schema. The model is forced to return valid, parseable JSON matching your schema."
        },
        "twist": {
          "visual": "ğŸ§©",
          "text": "Even with JSON mode, values can be wrong â€” the structure is guaranteed, but the content still depends on prompt quality."
        },
        "climax": {
          "visual": "âœ…",
          "text": "With structured output, you can pipe AI responses directly into your data layer. No regex, no parsing hacks, no 2 AM crashes."
        },
        "punchline": {
          "visual": "ğŸ”§",
          "text": "Don't ask the model nicely for JSON. Force it."
        }
      },
      "quiz": {
        "question": "What is the most reliable way to get JSON from an LLM?",
        "options": [
          "Asking politely in the prompt",
          "Using regex to extract JSON from text",
          "Using JSON mode or function calling with a schema",
          "Wrapping the response in try-catch"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t12-semantic-search-in-apps",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Semantic Search in Apps",
      "description": "Add meaning-based search to your app using embeddings.",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "visual": "ğŸ”",
          "text": "A user searches 'how to fix login issues' and gets zero results. The docs say 'authentication troubleshooting.' Keyword search fails."
        },
        "buildup": {
          "visual": "ğŸ“",
          "text": "Semantic search uses embeddings â€” numerical vectors that capture meaning. Similar meanings produce vectors that are close together."
        },
        "discovery": {
          "visual": "ğŸ§®",
          "text": "Embed your content at index time, store vectors in a vector database (Pinecone, Supabase pgvector, Weaviate), then embed the query and find nearest neighbours."
        },
        "twist": {
          "visual": "âš–ï¸",
          "text": "Semantic search finds conceptually similar content but can miss exact matches. The best systems combine semantic and keyword search (hybrid search)."
        },
        "climax": {
          "visual": "ğŸ¯",
          "text": "With semantic search, users find what they mean, not just what they type. Search satisfaction scores jump dramatically."
        },
        "punchline": {
          "visual": "ğŸ§ ",
          "text": "Search that understands intent is search that actually works."
        }
      },
      "quiz": {
        "question": "What is the advantage of hybrid search over pure semantic search?",
        "options": [
          "It's cheaper to run",
          "It combines meaning-based and exact keyword matching",
          "It doesn't require embeddings",
          "It works without a database"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t13-managing-token-costs",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Managing Token Costs",
      "description": "Keep AI API costs under control as your app scales.",
      "difficulty": "Intermediate",
      "story": {
        "hook": {
          "visual": "ğŸ’¸",
          "text": "A startup launches with GPT-4 for everything. First month's bill: $12,000. Their entire runway is 3 months."
        },
        "buildup": {
          "visual": "ğŸ§®",
          "text": "Every token costs money. Input tokens (your prompt + context) and output tokens (the response) are billed separately, with output often 3-4x more expensive."
        },
        "discovery": {
          "visual": "ğŸ“‰",
          "text": "Cost levers: use smaller models for simple tasks, cache frequent responses, shorten system prompts, limit max_tokens, and batch requests where possible."
        },
        "twist": {
          "visual": "ğŸ”€",
          "text": "Model routing â€” sending easy queries to cheap models and hard queries to expensive ones â€” can cut costs 60-80% with minimal quality loss."
        },
        "climax": {
          "visual": "ğŸ“Š",
          "text": "With monitoring dashboards, per-user budgets, and smart routing, you can scale to millions of requests without breaking the bank."
        },
        "punchline": {
          "visual": "ğŸ’°",
          "text": "The cheapest token is the one you never send."
        }
      },
      "quiz": {
        "question": "What is model routing?",
        "options": [
          "Sending all requests to the newest model",
          "Directing easy queries to cheap models and hard queries to expensive ones",
          "Routing requests through a VPN",
          "Splitting one prompt across multiple models"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t14-caching-ai-responses",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Caching AI Responses",
      "description": "Cache AI responses to reduce latency and costs dramatically.",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "visual": "ğŸ—„ï¸",
          "text": "An app makes the exact same API call 1,000 times a day. Each call costs $0.03. That's $30/day for the same answer."
        },
        "buildup": {
          "visual": "ğŸ”‘",
          "text": "If the same input produces the same output, cache it. Use the prompt hash as the cache key and set a TTL based on how fresh the data needs to be."
        },
        "discovery": {
          "visual": "ğŸ§ ",
          "text": "Semantic caching goes further: use embeddings to find similar (not just identical) queries and return cached responses. A 95% similar question probably has the same answer."
        },
        "twist": {
          "visual": "â°",
          "text": "Caching non-deterministic outputs is tricky. Set temperature to 0 for cacheable calls, or cache the first response and accept slight variation."
        },
        "climax": {
          "visual": "âš¡",
          "text": "With caching, repeated queries return in milliseconds instead of seconds, and your API bill drops by 50-90%."
        },
        "punchline": {
          "visual": "â™»ï¸",
          "text": "Don't ask twice what you already know."
        }
      },
      "quiz": {
        "question": "What does semantic caching use to match similar queries?",
        "options": [
          "Exact string matching",
          "Regular expressions",
          "Embeddings to find similarity",
          "Query length comparison"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t15-latency-optimization",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Latency Optimization",
      "description": "Reduce AI response times to keep your app feeling snappy.",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "visual": "ğŸŒ",
          "text": "An AI feature takes 12 seconds to respond. 60% of users abandon before seeing the result."
        },
        "buildup": {
          "visual": "â±ï¸",
          "text": "AI latency comes from: network round-trip, queue wait time, time-to-first-token, and total generation time."
        },
        "discovery": {
          "visual": "ğŸ”§",
          "text": "Optimise each layer: use edge deployments to cut network time, smaller models for faster generation, shorter prompts for less processing, and streaming for perceived speed."
        },
        "twist": {
          "visual": "ğŸ­",
          "text": "Sometimes the best optimisation is architectural: pre-compute likely responses, run AI tasks in the background, or show a useful UI while the AI thinks."
        },
        "climax": {
          "visual": "ğŸï¸",
          "text": "A well-optimised AI feature responds in under 2 seconds. Users don't even notice there's AI behind it."
        },
        "punchline": {
          "visual": "âš¡",
          "text": "Speed isn't a feature. It's the feature."
        }
      },
      "quiz": {
        "question": "Which is NOT a common source of AI response latency?",
        "options": [
          "Network round-trip time",
          "Token generation time",
          "Database schema design",
          "Queue wait time"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t16-testing-ai-features",
      "chapter_id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "Testing AI Features",
      "description": "Build test strategies for non-deterministic AI-powered features.",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "visual": "ğŸ°",
          "text": "A unit test checks if the AI returns 'Hello, World!' The AI returns 'Hi there, World!' Test fails. Is the feature broken?"
        },
        "buildup": {
          "visual": "ğŸ¤·",
          "text": "Traditional tests expect exact outputs. AI outputs are non-deterministic â€” the same input can produce different valid outputs every time."
        },
        "discovery": {
          "visual": "ğŸ“‹",
          "text": "Test AI features with assertions on structure (valid JSON?), constraints (within token limit?), and semantic correctness (does it mention the right topic?) instead of exact matches."
        },
        "twist": {
          "visual": "ğŸ’¡",
          "text": "Use LLM-as-judge for complex evaluations: have a second AI grade the first AI's output against a rubric. It's surprisingly effective."
        },
        "climax": {
          "visual": "ğŸ§©",
          "text": "Combine deterministic tests (API mocks, structure validation) with statistical tests (pass rate over N runs) for reliable AI test suites."
        },
        "punchline": {
          "visual": "ğŸ¯",
          "text": "You can't test AI like normal code. But you absolutely can test it."
        }
      },
      "quiz": {
        "question": "How should you test non-deterministic AI outputs?",
        "options": [
          "Check for exact string matches",
          "Only test in production",
          "Assert on structure, constraints, and semantic correctness",
          "Skip testing entirely"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t17-deploying-ai-features",
      "chapter_id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "Deploying AI Features",
      "description": "Ship AI features to production with confidence and observability.",
      "difficulty": "Advanced",
      "story": {
        "hook": {
          "visual": "ğŸš¢",
          "text": "A team deploys an AI chatbot to 100,000 users. Within an hour, it's giving medical advice it shouldn't."
        },
        "buildup": {
          "visual": "ğŸ”’",
          "text": "AI deployments need extra guardrails: content filters, rate limits, output validation, and monitoring that traditional features don't require."
        },
        "discovery": {
          "visual": "ğŸš¦",
          "text": "Deploy with feature flags and gradual rollout. Start with 1% of users, monitor outputs, check for harmful content, then scale up."
        },
        "twist": {
          "visual": "ğŸ“Š",
          "text": "Log every AI interaction (input + output). You need this data for debugging, improving prompts, and proving compliance. But anonymise PII first."
        },
        "climax": {
          "visual": "ğŸ›¡ï¸",
          "text": "With guardrails, monitoring, gradual rollout, and logging, your AI feature is production-ready â€” not just demo-ready."
        },
        "punchline": {
          "visual": "ğŸ",
          "text": "Shipping AI is easy. Shipping AI responsibly takes engineering."
        }
      },
      "quiz": {
        "question": "What should you do before deploying an AI feature to all users?",
        "options": [
          "Remove all rate limits",
          "Deploy to 100% immediately for maximum feedback",
          "Use feature flags and gradual rollout with monitoring",
          "Disable logging to save costs"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t18-ai-dev-career-path",
      "chapter_id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "AI Dev Career Path",
      "description": "Chart your career growth as an AI-savvy developer.",
      "difficulty": "Premium",
      "story": {
        "hook": {
          "visual": "ğŸ“ˆ",
          "text": "AI engineer job postings increased 300% in one year. The salary premium? 30-50% over equivalent non-AI roles."
        },
        "buildup": {
          "visual": "ğŸ—ºï¸",
          "text": "The AI dev career ladder: AI-curious developer â†’ AI-integrated developer â†’ AI engineer â†’ AI architect. Each level multiplies your impact."
        },
        "discovery": {
          "visual": "ğŸ§±",
          "text": "Build a portfolio of AI-powered projects. Contribute to open-source AI tools. Write about what you learn. The field is young enough that builders stand out."
        },
        "twist": {
          "visual": "ğŸ”„",
          "text": "The tools will change every 6 months. The fundamentals â€” APIs, prompt engineering, evaluation, system design â€” will last for years."
        },
        "climax": {
          "visual": "ğŸŒŸ",
          "text": "The developers who thrive aren't the ones who know every tool. They're the ones who ship AI-powered products that solve real problems."
        },
        "punchline": {
          "visual": "ğŸš€",
          "text": "The AI dev gold rush is now. Build, ship, and learn in public."
        }
      },
      "quiz": {
        "question": "What is the most durable AI developer skill?",
        "options": [
          "Mastering one specific AI framework",
          "Memorising model parameter counts",
          "Understanding fundamentals like APIs, prompts, and evaluation",
          "Using only the latest tools"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t19-api-key-management",
      "chapter_id": "ai--ai-for-developers--ch01-getting-started",
      "title": "API Key Management",
      "description": "Secure storage and rotation of AI service API keys.",
      "difficulty": "Beginner",
      "story": {
        "hook": { "visual": "ğŸ”‘", "text": "A developer pushes code to GitHub. Buried in the commit: their OpenAI API key. Within hours, bots scrape it and rack up $2,000 in charges." },
        "buildup": { "visual": "ğŸ”", "text": "API keys are the passwords to AI services. They authenticate your app, track your usage, and bill your account. If someone else gets your key, they spend your money." },
        "discovery": { "visual": "ğŸ’¡", "text": "Store keys in environment variables (.env files), never in source code. Use .gitignore to exclude .env. In production, use secret managers (AWS Secrets Manager, Vault, Vercel env vars)." },
        "twist": { "visual": "âš¡", "text": "Rotate keys regularly. If a key might be compromised, revoke it immediately from the provider's dashboard. Set up billing alerts so you catch abuse early." },
        "climax": { "visual": "ğŸ", "text": "Good key hygiene: .env for local dev, secret manager for production, billing alerts for safety, and rotation schedules for peace of mind." },
        "punchline": { "visual": "ğŸ¬", "text": "Treat API keys like passwords. Because that's exactly what they are." }
      },
      "quiz": {
        "question": "Where should you store API keys in a production application?",
        "options": [
          "Hardcoded in the source code",
          "In a README file",
          "In a secret manager or environment variables",
          "In a public configuration file"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t20-choosing-a-model-provider",
      "chapter_id": "ai--ai-for-developers--ch01-getting-started",
      "title": "Choosing a Model Provider",
      "description": "How to pick between OpenAI, Anthropic, Google, and open-source options.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸª", "text": "OpenAI, Anthropic, Google, Mistral, Cohere, AWS Bedrock â€” there are 15+ model providers. Which one should you start with?" },
        "buildup": { "visual": "ğŸ“Š", "text": "Factors: model quality for your task, API reliability, pricing, rate limits, data privacy policies, and regional availability." },
        "discovery": { "visual": "ğŸ’¡", "text": "Start with one provider, build an abstraction layer, and benchmark. OpenAI has the largest ecosystem, Anthropic excels at safety and long context, Google offers tight cloud integration." },
        "twist": { "visual": "âš¡", "text": "Don't choose based on benchmarks alone â€” real-world performance varies by task. A model that leads on coding might lag on creative writing. Test on YOUR use case." },
        "climax": { "visual": "ğŸ", "text": "The best strategy: abstract your model calls behind an interface, pick the cheapest provider that meets your quality bar, and make switching a config change." },
        "punchline": { "visual": "ğŸ¬", "text": "Pick one to start. Build to switch. Benchmark to decide." }
      },
      "quiz": {
        "question": "What is the best way to choose a model provider?",
        "options": [
          "Always pick the cheapest option",
          "Only use the most popular provider",
          "Test on your specific use case and build an abstraction layer for easy switching",
          "Choose based solely on public benchmarks"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t21-understanding-rate-limits",
      "chapter_id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "Understanding Rate Limits",
      "description": "How API rate limits work and how to design around them.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸš¦", "text": "Your app hits 100 concurrent users. Suddenly, every API call returns 429 Too Many Requests. Your whole AI feature goes down." },
        "buildup": { "visual": "ğŸ“", "text": "Rate limits restrict how many requests you can make per minute/hour. Providers set limits per API key, per model, and per endpoint. New accounts often get low limits." },
        "discovery": { "visual": "ğŸ’¡", "text": "Check your provider's rate limit headers (x-ratelimit-remaining, x-ratelimit-reset). Implement a token bucket or sliding window on your side. Queue requests when approaching the limit." },
        "twist": { "visual": "âš¡", "text": "Rate limits aren't just per-request â€” many providers also limit tokens per minute (TPM). A single large prompt can consume most of your TPM budget." },
        "climax": { "visual": "ğŸ", "text": "Design for rate limits from day one: request queuing, backoff, caching for repeated queries, and alerts when you hit 80% of your limit." },
        "punchline": { "visual": "ğŸ¬", "text": "Rate limits are a wall. Build a queue, not a battering ram." }
      },
      "quiz": {
        "question": "What are the two types of rate limits most AI providers enforce?",
        "options": [
          "Requests per second and data size per request",
          "Requests per minute and tokens per minute",
          "CPU usage and memory usage",
          "Upload speed and download speed"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t22-model-versioning",
      "chapter_id": "ai--ai-for-developers--ch02-apis-and-sdks",
      "title": "Model Versioning",
      "description": "Pinning model versions to prevent unexpected behavior changes.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ“Œ", "text": "Your app uses 'gpt-4.' One day, outputs change subtly â€” tone shifts, format breaks, quality dips. OpenAI updated the model behind the alias. You didn't change anything." },
        "buildup": { "visual": "ğŸ”„", "text": "Model aliases like 'gpt-4' point to the latest version. When the provider updates, your app gets the new model automatically â€” without warning or consent." },
        "discovery": { "visual": "ğŸ’¡", "text": "Pin to specific versions: 'gpt-4-0613' instead of 'gpt-4.' This ensures your app behaves identically until YOU decide to upgrade. Test new versions before switching." },
        "twist": { "visual": "âš¡", "text": "Pinned versions eventually get deprecated. Budget time for periodic upgrades: run evals on the new version, compare scores, update if acceptable, and note the change in your changelog." },
        "climax": { "visual": "ğŸ", "text": "Version pinning + eval-driven upgrades = stability. You control when changes happen, and you prove each upgrade is safe before shipping." },
        "punchline": { "visual": "ğŸ¬", "text": "Never let a model update surprise you. Pin it, test it, upgrade deliberately." }
      },
      "quiz": {
        "question": "Why should you pin to specific model versions in production?",
        "options": [
          "To get automatic improvements for free",
          "To prevent unexpected behavior changes when the provider updates the model",
          "Because aliases are more expensive",
          "To use older, less capable models"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t23-code-review-with-ai",
      "chapter_id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "Code Review with AI",
      "description": "Using AI to review pull requests and catch issues before humans do.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ‘ï¸", "text": "A pull request has 47 changed files. The human reviewer skims it and approves. The AI reviewer catches a SQL injection vulnerability in file 38." },
        "buildup": { "visual": "ğŸ“", "text": "AI code review tools scan diffs for bugs, security issues, style violations, and logical errors. They don't replace human reviewers â€” they augment them with tireless pattern matching." },
        "discovery": { "visual": "ğŸ’¡", "text": "Feed the AI the diff, the PR description, and relevant code context. Ask it to check for: bugs, security issues, performance problems, and adherence to coding standards." },
        "twist": { "visual": "âš¡", "text": "AI reviewers generate false positives â€” they'll flag correct code as suspicious. Teams must calibrate sensitivity and train developers to evaluate AI suggestions critically, not blindly accept them." },
        "climax": { "visual": "ğŸ", "text": "The sweet spot: AI catches mechanical issues (unused imports, potential null pointers, missing error handling) while humans focus on architecture and design decisions." },
        "punchline": { "visual": "ğŸ¬", "text": "Let AI handle the tedious checks. Free human reviewers for the thinking work." }
      },
      "quiz": {
        "question": "What is the ideal division of labor between AI and human code reviewers?",
        "options": [
          "AI handles everything, humans approve blindly",
          "AI catches mechanical issues, humans focus on architecture and design",
          "Humans catch bugs, AI reviews design",
          "Only one reviewer type is needed"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t24-documentation-with-ai",
      "chapter_id": "ai--ai-for-developers--ch03-coding-with-ai",
      "title": "Documentation with AI",
      "description": "Generate and maintain documentation using AI assistance.",
      "difficulty": "Beginner",
      "story": {
        "hook": { "visual": "ğŸ“„", "text": "The codebase has zero documentation. A developer pastes the module into an AI and gets comprehensive JSDoc comments, a README, and an API reference in 10 minutes." },
        "buildup": { "visual": "âœï¸", "text": "AI excels at documentation because it can read code structure, infer purpose from naming conventions, and produce consistent, well-formatted docs." },
        "discovery": { "visual": "ğŸ’¡", "text": "Use AI for: inline comments, function docstrings, README generation, API documentation, and changelog entries. Give it the code plus any existing docs for best results." },
        "twist": { "visual": "âš¡", "text": "AI-generated docs can describe what the code does but miss WHY it does it. Business context, design decisions, and trade-offs still need human input." },
        "climax": { "visual": "ğŸ", "text": "The best workflow: AI generates the first draft, human adds context and corrections, and CI validates that docs stay in sync with code changes." },
        "punchline": { "visual": "ğŸ¬", "text": "The best documentation is the documentation that exists. AI removes the blank page problem." }
      },
      "quiz": {
        "question": "What aspect of documentation does AI struggle with most?",
        "options": [
          "Formatting and structure",
          "Describing function parameters",
          "Explaining WHY design decisions were made (business context)",
          "Generating markdown syntax"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t25-embeddings-for-devs",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Embeddings for Devs",
      "description": "A practical guide to using embedding APIs in your applications.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ§®", "text": "You want to find similar products, detect duplicate support tickets, or cluster user feedback. All three problems have the same solution: embeddings." },
        "buildup": { "visual": "ğŸ“", "text": "An embedding API takes text and returns a vector of numbers. Similar texts produce similar vectors. You can then use cosine similarity to find matches." },
        "discovery": { "visual": "ğŸ’¡", "text": "The workflow: (1) Call the embedding API with your text, (2) Store the vector in a database, (3) When querying, embed the query, (4) Find nearest neighbors. That's it." },
        "twist": { "visual": "âš¡", "text": "Embeddings are task-sensitive. An embedding model trained for search may not work well for classification. Choose a model that matches your use case, or use a general-purpose model." },
        "climax": { "visual": "ğŸ", "text": "Embeddings unlock a whole category of features: similarity search, recommendation, clustering, anomaly detection â€” all with the same simple API." },
        "punchline": { "visual": "ğŸ¬", "text": "Embeddings turn text into numbers you can compute on. That's the bridge between language and math." }
      },
      "quiz": {
        "question": "What is the basic workflow for using embeddings in an app?",
        "options": [
          "Train a model, deploy it, fine-tune it",
          "Embed text, store vectors, embed query, find nearest neighbors",
          "Parse text with regex, store in SQL, query with LIKE",
          "Send text to an LLM and ask for similar items"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t26-content-generation",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Content Generation",
      "description": "Building AI-powered content creation features for your users.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "âœ¨", "text": "An e-commerce app adds 'Generate product description.' Sellers create listings 5x faster. Conversion rates increase 15% because descriptions are more consistent and compelling." },
        "buildup": { "visual": "ğŸ“", "text": "Content generation features let users create text with AI assistance: product descriptions, email drafts, social media posts, summaries, or reports." },
        "discovery": { "visual": "ğŸ’¡", "text": "The key is constraints: don't give users a blank AI canvas. Provide templates, tone options, length limits, and required fields. 'Generate a product description: professional tone, 100 words, mention key features.'" },
        "twist": { "visual": "âš¡", "text": "Users will edit AI-generated content â€” make that easy. Provide 'regenerate,' 'make shorter,' 'change tone' buttons. The first draft is a starting point, not the final product." },
        "climax": { "visual": "ğŸ", "text": "Great content generation features feel like a superpower: the user provides the facts, the AI provides the polish. Together, they're faster than either alone." },
        "punchline": { "visual": "ğŸ¬", "text": "Don't make users write from scratch. Give them a smart first draft." }
      },
      "quiz": {
        "question": "What makes a content generation feature more useful?",
        "options": [
          "Letting the AI generate anything without constraints",
          "Providing templates, tone options, and length limits as guardrails",
          "Only generating one version with no option to regenerate",
          "Requiring users to write the content themselves first"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t27-classification-features",
      "chapter_id": "ai--ai-for-developers--ch04-integrating-ai-features",
      "title": "Classification Features",
      "description": "Using AI to categorise, tag, and route content automatically.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ·ï¸", "text": "A support team manually tags 500 tickets per day. An AI classifier does it in seconds with 94% accuracy â€” and never takes a lunch break." },
        "buildup": { "visual": "ğŸ“Š", "text": "Classification is one of the most reliable AI features: given text, assign it to one or more categories. Sentiment analysis, topic tagging, intent detection, and priority scoring are all classification." },
        "discovery": { "visual": "ğŸ’¡", "text": "Use structured output with a constrained set of categories. Prompt: 'Classify this support ticket into exactly one category: billing, technical, account, other. Respond with JSON.'" },
        "twist": { "visual": "âš¡", "text": "For high-volume classification, LLMs may be overkill. A fine-tuned small model or even a traditional ML classifier can be 100x cheaper and 10x faster for well-defined categories." },
        "climax": { "visual": "ğŸ", "text": "Start with an LLM classifier (fast to build), measure accuracy, then graduate to a specialised model if volume justifies the investment." },
        "punchline": { "visual": "ğŸ¬", "text": "Classification is AI's most reliable trick. Start here if you're adding your first AI feature." }
      },
      "quiz": {
        "question": "When might you replace an LLM classifier with a smaller model?",
        "options": [
          "Never â€” LLMs are always better",
          "When classification volume is high and categories are well-defined",
          "When you need more creative classifications",
          "When accuracy doesn't matter"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t28-prompt-management",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Prompt Management",
      "description": "Versioning, testing, and managing prompts like production code.",
      "difficulty": "Advanced",
      "story": {
        "hook": { "visual": "ğŸ“¦", "text": "A developer changes one word in the system prompt. Quality drops 20%. No one notices for a week because the prompt isn't versioned and there's no diff to review." },
        "buildup": { "visual": "ğŸ”§", "text": "Prompts are code. They affect behavior, quality, and cost. But most teams store them as string literals buried in application code with no versioning or review process." },
        "discovery": { "visual": "ğŸ’¡", "text": "Manage prompts like config: store in dedicated files or a prompt management tool, version control them, require code review for changes, and run evals before deploying prompt updates." },
        "twist": { "visual": "âš¡", "text": "Advanced teams separate prompt deployment from code deployment. Change the prompt without redeploying the app. A/B test prompts in production with feature flags." },
        "climax": { "visual": "ğŸ", "text": "Prompt management stack: version-controlled prompt files â†’ CI eval pipeline â†’ feature-flagged deployment â†’ production monitoring. Treat prompts with the same rigor as code." },
        "punchline": { "visual": "ğŸ¬", "text": "Prompts are the most influential code in your AI app. Manage them like it." }
      },
      "quiz": {
        "question": "How should production prompts be managed?",
        "options": [
          "As hardcoded strings changed directly in production",
          "Version controlled with code review and eval testing before deployment",
          "Stored in comments within the code",
          "Changed without any testing"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t29-model-routing",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Model Routing",
      "description": "Sending each request to the right model based on complexity.",
      "difficulty": "Advanced",
      "story": {
        "hook": { "visual": "ğŸ”€", "text": "60% of your requests are simple: 'What's the refund policy?' You send them all to GPT-4. That's like using a Ferrari for grocery runs." },
        "buildup": { "visual": "ğŸ“Š", "text": "Model routing classifies each request by complexity and sends it to the appropriate model. Simple â†’ cheap/fast model. Complex â†’ expensive/powerful model." },
        "discovery": { "visual": "ğŸ’¡", "text": "Build a lightweight classifier (even rules-based) that categorises requests. Short, factual questions â†’ GPT-4o-mini. Complex reasoning tasks â†’ Claude Opus. The router adds milliseconds but saves dollars." },
        "twist": { "visual": "âš¡", "text": "The router itself can be an LLM â€” use a tiny model to classify the request before routing. The meta-cost of routing is usually <5% of the savings." },
        "climax": { "visual": "ğŸ", "text": "Teams using model routing report 60-80% cost reduction with <5% quality loss. The key is good classification and continuous monitoring of quality per route." },
        "punchline": { "visual": "ğŸ¬", "text": "Match the model to the task. Not every question needs your most powerful (expensive) model." }
      },
      "quiz": {
        "question": "What is the typical cost impact of implementing model routing?",
        "options": [
          "Costs increase by 50%",
          "No change in costs",
          "60-80% cost reduction with minimal quality loss",
          "Costs decrease but quality drops dramatically"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t30-feature-flags-for-ai",
      "chapter_id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "Feature Flags for AI",
      "description": "Using feature flags to safely roll out and control AI features.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸš©", "text": "You deploy an AI summariser to all users. It works great â€” except for Japanese text, which it mangles. No way to turn it off for Japanese users without a full rollback." },
        "buildup": { "visual": "ğŸšï¸", "text": "Feature flags let you control who sees an AI feature without code deploys. Turn it on for 5% of users, specific regions, or specific user segments." },
        "discovery": { "visual": "ğŸ’¡", "text": "Use flags for: gradual rollout (1% â†’ 10% â†’ 50% â†’ 100%), A/B testing (prompt A vs prompt B), kill switches (disable instantly if quality drops), and user targeting." },
        "twist": { "visual": "âš¡", "text": "AI features need flags more than traditional features because AI quality can degrade in ways that are hard to predict. A kill switch gives you a safety net for every deploy." },
        "climax": { "visual": "ğŸ", "text": "Every AI feature should launch behind a flag. This gives you instant rollback, gradual rollout, and production experimentation â€” all without code changes." },
        "punchline": { "visual": "ğŸ¬", "text": "Ship AI behind flags. It's the difference between 'deploy and pray' and 'deploy and control.'" }
      },
      "quiz": {
        "question": "Why are feature flags especially important for AI features?",
        "options": [
          "AI features never need updating",
          "AI quality can degrade unpredictably, and flags provide instant kill switches",
          "Feature flags make AI features faster",
          "They are not important for AI features"
        ],
        "correct": 1
      }
    },
    {
      "id": "ai--ai-for-developers--t31-logging-ai-interactions",
      "chapter_id": "ai--ai-for-developers--ch06-shipping-ai-apps",
      "title": "Logging AI Interactions",
      "description": "Recording prompts, responses, and metadata for debugging and improvement.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ“Š", "text": "A user reports: 'Your AI gave me wrong information.' You check the logs. There are no logs. You have no idea what the AI said or why." },
        "buildup": { "visual": "ğŸ“", "text": "AI logging means recording: the input prompt, the model's response, the model version, latency, token count, cost, and any user feedback (thumbs up/down)." },
        "discovery": { "visual": "ğŸ’¡", "text": "Log at the API boundary: wrap your LLM client in a logger that captures every request and response. Store in a searchable system (Datadog, BigQuery, or a dedicated tool like Langfuse)." },
        "twist": { "visual": "âš¡", "text": "PII in prompts is a legal risk. Scrub personal information before logging, or use separate secure storage for PII-containing logs with appropriate access controls." },
        "climax": { "visual": "ğŸ", "text": "Good logs enable: debugging individual issues, measuring quality trends, building eval datasets from real usage, and proving compliance to regulators." },
        "punchline": { "visual": "ğŸ¬", "text": "If you didn't log it, it didn't happen. Log every AI interaction." }
      },
      "quiz": {
        "question": "What must you be careful about when logging AI interactions?",
        "options": [
          "Logging too few interactions",
          "Using too much disk space",
          "Personal information (PII) in prompts must be scrubbed or secured",
          "Log file formatting"
        ],
        "correct": 2
      }
    },
    {
      "id": "ai--ai-for-developers--t32-monitoring-ai-costs",
      "chapter_id": "ai--ai-for-developers--ch05-performance-and-cost",
      "title": "Monitoring AI Costs",
      "description": "Building dashboards and alerts to track AI spending in real time.",
      "difficulty": "Intermediate",
      "story": {
        "hook": { "visual": "ğŸ“Š", "text": "End of month: your AI API bill is $8,400. Budget was $2,000. Nobody tracked spending because 'we'll monitor it later.'" },
        "buildup": { "visual": "ğŸ’°", "text": "AI costs are unpredictable: they scale with usage, vary by model, and depend on prompt length. Without monitoring, a traffic spike or a runaway feature can blow your budget overnight." },
        "discovery": { "visual": "ğŸ’¡", "text": "Track cost per request, per feature, per user, and per day. Build dashboards that show spending trends. Set alerts at 50%, 80%, and 100% of monthly budget." },
        "twist": { "visual": "âš¡", "text": "Set per-user spending caps to prevent abuse. One power user sending 10,000 requests shouldn't drain your entire API budget. Rate limit per user, not just globally." },
        "climax": { "visual": "ğŸ", "text": "A cost monitoring stack: per-request logging â†’ daily aggregation â†’ dashboards â†’ alerts â†’ per-user caps â†’ auto-throttle when budget is exhausted." },
        "punchline": { "visual": "ğŸ¬", "text": "You can't manage what you don't measure. Track every dollar your AI spends." }
      },
      "quiz": {
        "question": "What should trigger an alert in AI cost monitoring?",
        "options": [
          "Any single API call",
          "Spending reaching 50%, 80%, or 100% of the monthly budget",
          "Every model upgrade",
          "Only when the bill arrives"
        ],
        "correct": 1
      }
    }
  ]
}
